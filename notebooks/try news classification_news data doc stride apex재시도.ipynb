{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import re\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
    "from torch import Tensor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path.append(module_path+'/examples/')\n",
    "fund_dir = Path('/home/advice/notebook/jms/우리은행')\n",
    "from run_classifier_spm import *\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from  pytorch_pretrained_bert import modeling\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('a/b')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Path('a')\n",
    "b = Path('b')\n",
    "\n",
    "a/b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "today = str(today).replace('-', '')\n",
    "output_dir = fund_dir/'output_dir'/today\n",
    "output_dir.mkdir(exist_ok = 'True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = fund_dir/\"extract_kobert\"\n",
    "\n",
    "vocab_file = '/home/advice/notebook/jms/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece'\n",
    "\n",
    "bert_config_file = model_dir / \"kobert_config.json\"\n",
    "init_checkpoint = model_dir / \"kobert_model.bin\"\n",
    "bert_model = 'kobert'\n",
    "data_path = fund_dir/\"data/\"\n",
    "\n",
    "train_file = \"news_tr.txt\"\n",
    "eval_file = \"news_te.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_file\": train_file,\n",
    "    'eval_file':eval_file,\n",
    "    \"data_dir\": data_path,\n",
    "    \"task_name\": \"news\",##'nsmc'\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": model_dir,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"tokenizer\": vocab_file,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"doc_stride\": 128,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 32,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_train_epochs\": 1.0,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": True,\n",
    "    'fp16_opt_level':'O1',\n",
    "    \"loss_scale\": 128,\n",
    "    \"logging_steps\":100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            #loss_fct = BCEWithLogitsLoss()\n",
    "            #loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None, doc_span_index = None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.labels = labels\n",
    "        self.doc_span_index = doc_span_index\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    def __init__(self,guid, input_ids, input_mask, segment_ids, label_ids, doc_span_index):\n",
    "        self.guid = guid\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.doc_span_index = doc_span_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "\n",
    "    def get_train_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_test_examples(self):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_tsv(input_file, cls = \"\\t\", quotechar=None):\n",
    "    reader = csv.reader(input_file.open('r'), delimiter=cls, quotechar=None)\n",
    "    lines = [line for line in reader]\n",
    "    return lines\n",
    "\n",
    "class MultiClassTextProcessor(DataProcessor):\n",
    "\n",
    "    def __init__(self, data_path, train_file, test_file,labels = None, dev_file = None):\n",
    "        self.train_path = data_path/train_file\n",
    "        self.test_path = data_path/test_file\n",
    "        self.train_file = _read_tsv(data_path/train_file)\n",
    "        self.test_file = _read_tsv(data_path/test_file)\n",
    "        if dev_file!= None:\n",
    "            self.dev_path = data_path/dev_file\n",
    "            self.dev_file = _read_tsv(data_path/dev_file)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def get_train_examples(self):        \n",
    "        logger.info(\"LOOKING AT {}\".format(self.train_path))\n",
    "        return self._create_examples(self.train_file, \"train\")\n",
    "        \n",
    "    def get_dev_examples(self):\n",
    "        logger.info(\"LOOKING AT {}\".format(self.dev_path))\n",
    "        if self.dev_file!= None:\n",
    "            return self._create_examples(self.dev_file, \"dev\")\n",
    "        else:\n",
    "            raise ValueError('There is no dev file')\n",
    "    \n",
    "    def get_test_examples(self):\n",
    "        logger.info(\"LOOKING AT {}\".format(self.test_path))\n",
    "        return self._create_examples(self.test_file, \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        if self.labels == None:\n",
    "            self.labels = ['0', '1']\n",
    "        return self.labels\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[0]\n",
    "            text_b = None\n",
    "            label = line[1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, labels=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, doc_stride):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "    features_all = []\n",
    "    for (ex_index, example) in enumerate(tqdm(examples)):\n",
    "        \n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        max_tokens_for_doc = max_seq_length  - 2\n",
    "        _DocSpan = collections.namedtuple(  \n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "        doc_spans = []\n",
    "        start_offset = 0\n",
    "\n",
    "        while start_offset < len(tokens_a):\n",
    "            length = len(tokens_a) - start_offset\n",
    "            if length > max_tokens_for_doc:\n",
    "                length = max_tokens_for_doc\n",
    "            doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "            if start_offset + length == len(tokens_a):\n",
    "                break\n",
    "            start_offset += min(length, doc_stride)\n",
    "\n",
    "        for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "            features = []\n",
    "            tokens = []\n",
    "            segment_ids = [0]*max_seq_length\n",
    "            tokens.append(\"[CLS]\")\n",
    "            \n",
    "            for i in range(doc_span.length):\n",
    "                split_token_index = doc_span.start + i\n",
    "                tokens.append(tokens_a[split_token_index])\n",
    "\n",
    "            tokens.append(\"[SEP]\")\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            input_mask = [1] * len(input_ids)\n",
    "            \n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            input_mask += padding\n",
    "\n",
    "            \n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "            labels_ids = []\n",
    "            for label in example.labels:\n",
    "                labels_ids.append(float(label))\n",
    "\n",
    "#         label_id = label_map[example.label]\n",
    "#chris changed\n",
    "\n",
    "            if ex_index < 10:\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"guid: %s\" % (example.guid))\n",
    "                logger.info(\"doc_span_index: %s\" % (doc_span_index))\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\n",
    "                        \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
    "\n",
    "            features.append(\n",
    "                    InputFeatures(guid = example.guid,\n",
    "                                  input_ids=input_ids,\n",
    "                                  input_mask=input_mask,\n",
    "                                  segment_ids=segment_ids,\n",
    "                                  label_ids=labels_ids, \n",
    "                                  doc_span_index = doc_span_index))\n",
    "            features_all.extend(features)## extend가 맞남... 모르겟다링~\n",
    "    return features_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    out_cpu = out.cpu().numpy()\n",
    "    labels_cpu = labels.cpu().numpy()\n",
    "    outputs = np.argmax(out_cpu, axis=1)\n",
    "    return np.sum(outputs == labels_cpu)\n",
    "\n",
    "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:14 - INFO - run_classifier_spm -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: True\n"
     ]
    }
   ],
   "source": [
    "processors = {args[\"task_name\"]: MultiClassTextProcessor}\n",
    "\n",
    "# Setup GPU parameters\n",
    "\n",
    "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "#     n_gpu = 1\n",
    "else:\n",
    "    torch.cuda.set_device(args['local_rank'])\n",
    "    device = torch.device(\"cuda\", args['local_rank'])\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = args['task_name'].lower()\n",
    "if task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "    \n",
    "if args['task_name'] =='news':\n",
    "    lab = ['0','1','2','3','4','5']\n",
    "elif args['task_name'] =='nsmc':\n",
    "    lab = ['0','1']\n",
    "\n",
    "processor = processors[task_name](data_path = args['data_dir'], \n",
    "                                  train_file = args['train_file'], \n",
    "                                  test_file = args['eval_file'], \n",
    "                                  labels = lab,\n",
    "                                 )\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:17 - INFO - tokenization_spm -   loading vocabulary file /home/advice/notebook/jms/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BERTSPMTokenizer.from_pretrained(args['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   LOOKING AT /home/advice/notebook/jms/우리은행/data/news_tr.txt\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6015bfe4205406098ba3bbe7d560dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41850.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   guid: train-1\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   tokens: [CLS] ▁김 예 솔 기자 ▁김 세 정 이 ▁김 시 후 의 ▁죽음 에 ▁관심을 ▁갖 기 ▁시작했다 ▁일 에 ▁방송된 ▁너 의 ▁노래 를 ▁들려 줘 에서는 ▁홍 이 영 ▁김 세 정 ▁이 ▁기억 을 잃 기 ▁전 ▁자신 과 ▁김 이 안 ▁김 시 후 ▁이 ▁연 관 이 ▁있다는 ▁사실을 ▁알게 됐다 ▁앞서 ▁홍 이 영 은 ▁유 제 니 ▁조 유 정 에게 ▁김 이 안 에 ▁대해 ▁물 었다 ▁유 제 니 는 개월 ▁전 ▁네 가 ▁어 시 스트 했던 ▁사람이 다 라고 ▁말했다 ▁하지만 ▁홍 이 영 은 ▁기억 하지 ▁못했다 ▁유 제 니 는 ▁어떻게 보 면 잊 어 버린 ▁게 ▁좋 을 ▁수도 ▁있다 ▁알 던 ▁사람이 ▁죽 으면 ▁기분 ▁나 쁘 지 ▁않 냐 ▁고 ▁말했다 ▁이날 ▁홍 이 영 은 ▁장 윤 ▁연 우 진 을 ▁만나 자 ▁반 갑 게 ▁인사 했다 ▁두 ▁사람은 ▁키스 ▁후 ▁처음 ▁마 주 친 ▁상황 ▁하지만 ▁장 윤 은 ▁홍 이 영 의 ▁눈 을 ▁피 하며 ▁인사 하지 ▁않았다 ▁홍 이 영 은 ▁영 찜 찜 했다 ▁홍 이 영 은 ▁장 윤 에게 ▁왜 ▁날 ▁피 하 냐 며 ▁그냥 ▁돌려 ▁말 하지 ▁않겠다 ▁장 윤 씨는 ▁원래 ▁여자 랑 ▁키스 하고 쌩 까 시 냐 ▁고 ▁물 었다 ▁홍 이 영 은 ▁장 윤 씨가 ▁나 에 ▁대해 ▁알고 ▁싶다 고 ▁하지 ▁않았 냐 ▁나는 ▁되 게 ▁단순 한 ▁사람이 라 ▁그냥 ▁그 렇 구나 라고 ▁생각한다 ▁그래서 ▁그 날 도 ▁마음 ▁가는 대로 솔 직 하게 ▁직 진 했던 거 다 라고 ▁말했다 ▁이어 ▁홍 이 영 은 ▁장 윤 에게 ▁나 ▁김 이 안 씨 ▁만난 ▁것 ▁같다 ▁그 ▁분 이 ▁내 한 했을 ▁때 ▁잠 깐 ▁어 시 스트 를 했다고 ▁하 더라 며 ▁그 ▁분 에 ▁대해 ▁알고 ▁싶어 졌다 ▁기억 해 내 고 ▁싶다 ▁고 ▁말했다 ▁장 윤 은 ▁괴 로운 ▁기억 일 ▁수도 ▁있다 끔 찍 한 ▁기억 일 ▁수도 ▁있는데 ▁괜찮 겠 냐 ▁고 ▁물 었다 ▁홍 이 영 은 ▁좋은 ▁기억 일 ▁수도 ▁있다 ▁무 섭 지 ▁않다 ▁고 ▁말했다 ▁이어 ▁홍 이 영 은 ▁이 브 닝 콜 도 ▁끝내 겠다 ▁고 ▁선언 했다 ▁사진 ▁너 의 ▁노래 를 ▁들려 줘 ▁방송 캡 쳐 [SEP]\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   input_ids: 2 1316 6957 6618 5580 1316 6579 7227 7096 1316 6705 7968 7095 4245 6896 1090 825 5561 2990 3803 6896 2274 1457 7095 1479 6116 1803 7303 6904 5108 7096 6951 1316 6579 7227 3647 1291 7088 7135 5561 4012 3909 5468 1316 7096 6812 1316 6705 7968 3647 3332 5474 7096 3864 2606 3167 5880 3187 5108 7096 6951 7086 3574 7234 5770 4162 7063 7227 6897 1316 7096 6812 6896 1685 2135 6888 3574 7234 5770 5760 5366 4012 1469 5330 3220 6705 6691 7872 2589 5782 6004 1966 4946 5108 7096 6951 7086 1291 7819 2093 3574 7234 5770 5760 3225 6364 6198 7145 6855 6325 921 4204 7088 2874 3862 3166 5842 2589 4244 7083 1282 1370 6488 7318 3146 5689 993 1966 3656 5108 7096 6951 7086 3954 7068 3332 7005 7344 7088 1933 7147 2207 5345 5400 3769 7869 1773 2587 4694 5176 4468 1907 7276 7489 2689 4946 3954 7068 7086 5108 7096 6951 7095 1535 7088 4909 7810 3769 7819 3157 5108 7096 6951 7086 3376 7387 7387 7869 5108 7096 6951 7086 3954 7068 6897 3466 1407 4909 7782 5689 6197 1189 1733 1958 7819 3148 3954 7068 6787 3537 3318 6022 4694 7788 0 5591 6705 5689 993 2135 6888 5108 7096 6951 7086 3954 7068 6786 1370 6896 1685 3168 3072 5439 4945 3156 5689 1375 1763 5400 1591 7828 2589 6003 1189 1185 6049 5496 6004 2708 1195 1185 5664 5859 1917 736 5812 6618 7342 7784 4349 7344 7872 5377 5782 6004 1966 3716 5108 7096 6951 7086 3954 7068 6897 1370 1316 7096 6812 6785 1934 905 831 1185 2468 7096 1434 7828 7879 1844 3945 5595 3220 6705 6691 6116 7870 4924 5839 6197 1185 2468 6896 1685 3168 3073 7250 1291 7848 5678 5439 3072 993 1966 3954 7068 7086 1101 6082 1291 7126 2874 3862 5646 7384 7828 1291 7126 2874 3861 1100 5405 5689 993 2135 6888 5108 7096 6951 7086 4209 1291 7126 2874 3862 2095 6570 7318 3153 993 1966 3716 5108 7096 6951 7086 3647 6432 5781 7542 5859 1367 5406 993 2758 7869 2627 1457 7095 1479 6116 1803 7303 2272 7510 7443 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   label: 5 (id = [5.0])\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/26/2019 07:35:17 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁화 염 과 ▁분노 트 럼 프 의 ▁기 행 과 ▁러시아 스캔들 ▁주요 ▁인선 ▁뒷 이 야 기 ▁등 ▁백악관 의 ▁내 막 을 ▁공개 해 ▁출 간 ▁주 일 ▁만에 ▁만 부가 ▁팔 린 ▁화제 의 ▁책 이 ▁번 역 ▁출 간 됐다 ▁저 자인 ▁마 이 클 ▁울 프 는 ▁트 럼 프 ▁행정 부 ▁전 ▁현 직 ▁관계자 ▁여 명을 ▁인터뷰 하고 ▁백악관 ▁내부 의 ▁권력 ▁투 쟁 과 ▁격 변 의 ▁국정 ▁운영 ▁현장 을 ▁자세 히 ▁조명 한다 ▁책 ▁속에 ▁보이는 ▁트 럼 프 의 ▁행보 는 ▁향후 ▁한반도 를 ▁비롯한 ▁미국의 ▁세계 ▁전략 을 가 늠 하게 ▁한다 ▁장 경 덕 옮 김 ▁은행 나무 ▁만 ▁원 ▁미 술 책을 ▁읽 다 ▁미 술 과 ▁생활 의 ▁접 점을 ▁찾아 주 고 ▁미 술 이 ▁일상 과 ▁함께 ▁하는 ▁것 임을 ▁알려 주는 ▁국내 ▁저 자가 ▁쓴 ▁미 술 ▁대중 서 ▁권 에 ▁대한 ▁서 평 에 세 이 집 ▁미 대를 ▁졸업 하고 ▁미 술 잡 지 ▁기 자로 ▁일 하다 ▁미 술 ▁전문 ▁출판 사를 ▁설립 해 년째 ▁책 을 ▁만들고 ▁있는 ▁지 은 이 가 ▁그간 ▁자신이 ▁어떤 ▁미 술 ▁책 을 ▁어떻게 ▁읽 었 는 지 에 ▁대해 ▁기록했다 ▁미 술 이란 ▁어렵 고 ▁고 상 한 ▁것 이라는 ▁편 견 을 ▁깨 고 ▁미 술 이 ▁주는 ▁기 쁨 을 ▁독자 와 ▁함께 ▁누 리는 ▁것이 ▁책 의 ▁지 향 점 이다 ▁정 민 영 ▁지 음 아트 북 스 ▁만 ▁원 ▁생존 ▁인 테 리 어 저 자는 ▁결혼 ▁후 ▁아파트 ▁장 만 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 5112 6941 5468 2469 7659 6043 7753 7095 1258 7881 5468 1881 6678 4233 3775 1786 7096 6844 5561 1815 2299 7095 1434 6149 7088 1026 7848 4568 5337 4213 7126 1946 1931 6399 4814 6133 5121 7095 4457 7096 2307 6926 4568 5337 5880 3990 7168 1907 7096 7568 3524 7753 5760 4773 6043 7753 5030 6398 4012 5049 7342 1077 3298 6209 3795 7788 2299 1446 7095 1171 4762 7198 5468 931 6355 7095 1152 3517 5062 7088 3907 7996 4170 7831 4457 2858 2389 4773 6043 7753 7095 5024 5760 5036 4970 6116 2525 2151 2802 4025 7088 5330 5764 7784 4965 3954 5424 5841 6976 5586 3605 5660 1931 3533 2149 6645 7409 3824 5782 2149 6645 5468 2717 7095 4086 7223 4446 7276 5439 2149 6645 7096 3812 5468 4983 4930 905 7137 3169 7280 1138 3990 7148 3086 2149 6645 1661 6553 1170 6896 1682 2718 7724 6896 6579 7096 7354 2149 5813 4195 7788 2149 6645 7176 7318 1258 7156 3803 7798 2149 6645 4033 4587 6500 2772 7848 5721 4457 7088 1941 3860 4297 7086 7096 5330 1187 3914 3224 2149 6645 4457 7088 3225 3824 6885 5760 7318 6896 1685 1277 2149 6645 7107 3231 5439 993 6527 7828 905 7103 4832 5414 7088 1342 5439 2149 6645 7096 4219 1258 6491 7088 1728 6983 4983 1526 6124 912 4457 7095 4297 7886 7220 7100 4092 6263 6951 4297 7089 6808 6412 6664 1931 3533 2715 3758 7618 6122 6855 7199 7150 950 5176 3131 3954 6150 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] 고 ▁미 술 이 ▁일상 과 ▁함께 ▁하는 ▁것 임을 ▁알려 주는 ▁국내 ▁저 자가 ▁쓴 ▁미 술 ▁대중 서 ▁권 에 ▁대한 ▁서 평 에 세 이 집 ▁미 대를 ▁졸업 하고 ▁미 술 잡 지 ▁기 자로 ▁일 하다 ▁미 술 ▁전문 ▁출판 사를 ▁설립 해 년째 ▁책 을 ▁만들고 ▁있는 ▁지 은 이 가 ▁그간 ▁자신이 ▁어떤 ▁미 술 ▁책 을 ▁어떻게 ▁읽 었 는 지 에 ▁대해 ▁기록했다 ▁미 술 이란 ▁어렵 고 ▁고 상 한 ▁것 이라는 ▁편 견 을 ▁깨 고 ▁미 술 이 ▁주는 ▁기 쁨 을 ▁독자 와 ▁함께 ▁누 리는 ▁것이 ▁책 의 ▁지 향 점 이다 ▁정 민 영 ▁지 음 아트 북 스 ▁만 ▁원 ▁생존 ▁인 테 리 어 저 자는 ▁결혼 ▁후 ▁아파트 ▁장 만 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 ▁법률 ▁조항 이 ▁없다 ▁법원 도 ▁공 인 이 ▁누구 인지 ▁정 의 를 ▁내리 거나 ▁그 ▁범 주 를 ▁정 하지 ▁않고 ▁있어 ▁공 인 에 ▁대한 ▁일 관 된 ▁법적 ▁판단 도 ▁없다 ▁언론 도 ▁어떤 ▁사람이 ▁공 인 이며 ▁어느 ▁정도 까지 ▁보도 해야 ▁하는 지 ▁정확한 가 이 드 라인 이 ▁존재 하지 ▁않아 ▁문제가 ▁생긴 다 ▁언론 과 ▁공 인 ▁사이에서 ▁명예 ▁훼손 ▁사 생활 ▁침해 ▁초 상 권 ▁침해 ▁관련 ▁판 례 ▁등을 ▁자세 히 ▁소개 한다 ▁이재 진 ▁지 음 ▁한 양 대학교 출 판 부 ▁만 ▁원 ▁생각 미술관 ▁그리 기 ▁시리즈 예 쁘 고 ▁쉽게 ▁그리 는 ▁방법 을 ▁알려 주는 ▁책 은 ▁많다 ▁생각 미술관 은 ▁언 어 ▁표현 이 ▁정 확 하지 ▁않은 ▁아이들 이 ▁자신 만 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 5439 2149 6645 7096 3812 5468 4983 4930 905 7137 3169 7280 1138 3990 7148 3086 2149 6645 1661 6553 1170 6896 1682 2718 7724 6896 6579 7096 7354 2149 5813 4195 7788 2149 6645 7176 7318 1258 7156 3803 7798 2149 6645 4033 4587 6500 2772 7848 5721 4457 7088 1941 3860 4297 7086 7096 5330 1187 3914 3224 2149 6645 4457 7088 3225 3824 6885 5760 7318 6896 1685 1277 2149 6645 7107 3231 5439 993 6527 7828 905 7103 4832 5414 7088 1342 5439 2149 6645 7096 4219 1258 6491 7088 1728 6983 4983 1526 6124 912 4457 7095 4297 7886 7220 7100 4092 6263 6951 4297 7089 6808 6412 6664 1931 3533 2715 3758 7618 6122 6855 7199 7150 950 5176 3131 3954 6150 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 2323 4191 7096 3273 2326 5859 1023 7119 7096 1528 7123 4092 7095 6116 1444 5378 1185 2318 7276 6116 4092 7819 3149 3868 1023 7119 6896 1682 3803 5474 5899 2328 4807 5859 3273 3244 5859 3224 2589 1023 7119 7108 3222 4099 5592 2369 7852 4930 7318 4125 5330 7096 5920 6014 7096 4193 7819 3155 2126 2711 5782 3244 5468 1023 7119 2621 2037 5188 2573 6545 4633 4501 6527 5524 4633 1083 4805 6078 1824 3907 7996 2824 7831 3737 7344 4297 7089 4955 6853 5825 7468 7688 6398 1931 3533 2705 6259 1209 5561 2973 6957 6488 5439 2924 1209 5760 2270 7088 3169 7280 4457 7086 1951 2705 6259 7086 3241 6855 4885 7096 4092 7944 7819 3162 3123 7096 3909 6150 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 2\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 ▁법률 ▁조항 이 ▁없다 ▁법원 도 ▁공 인 이 ▁누구 인지 ▁정 의 를 ▁내리 거나 ▁그 ▁범 주 를 ▁정 하지 ▁않고 ▁있어 ▁공 인 에 ▁대한 ▁일 관 된 ▁법적 ▁판단 도 ▁없다 ▁언론 도 ▁어떤 ▁사람이 ▁공 인 이며 ▁어느 ▁정도 까지 ▁보도 해야 ▁하는 지 ▁정확한 가 이 드 라인 이 ▁존재 하지 ▁않아 ▁문제가 ▁생긴 다 ▁언론 과 ▁공 인 ▁사이에서 ▁명예 ▁훼손 ▁사 생활 ▁침해 ▁초 상 권 ▁침해 ▁관련 ▁판 례 ▁등을 ▁자세 히 ▁소개 한다 ▁이재 진 ▁지 음 ▁한 양 대학교 출 판 부 ▁만 ▁원 ▁생각 미술관 ▁그리 기 ▁시리즈 예 쁘 고 ▁쉽게 ▁그리 는 ▁방법 을 ▁알려 주는 ▁책 은 ▁많다 ▁생각 미술관 은 ▁언 어 ▁표현 이 ▁정 확 하지 ▁않은 ▁아이들 이 ▁자신 만 의 엉 뚱 한 ▁생각을 ▁마음 껏 ▁그림 으로 ▁그려 ▁참 신 한 ▁사고 력을 ▁키 울 ▁수 ▁있게 ▁도와 준 다 ▁이야기를 ▁듣고 ▁떠오르 는 대로 ▁그려 보는 ▁이야기 ▁그리 기 ▁제시 된 ▁상황을 ▁보고 ▁그림 을 ▁완성 하는 ▁상황 ▁그리 기 ▁그림 을 ▁접 었다 펼 치 며 ▁노 는 ▁재미 ▁그리 기 도 형 ▁등을 ▁활용해 ▁생각 나는 ▁사 물을 ▁그리 는 ▁상 상 ▁그리 기 ▁등 ▁종 이다 ▁모 글 리 북 스 ▁각 ▁원 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 2323 4191 7096 3273 2326 5859 1023 7119 7096 1528 7123 4092 7095 6116 1444 5378 1185 2318 7276 6116 4092 7819 3149 3868 1023 7119 6896 1682 3803 5474 5899 2328 4807 5859 3273 3244 5859 3224 2589 1023 7119 7108 3222 4099 5592 2369 7852 4930 7318 4125 5330 7096 5920 6014 7096 4193 7819 3155 2126 2711 5782 3244 5468 1023 7119 2621 2037 5188 2573 6545 4633 4501 6527 5524 4633 1083 4805 6078 1824 3907 7996 2824 7831 3737 7344 4297 7089 4955 6853 5825 7468 7688 6398 1931 3533 2705 6259 1209 5561 2973 6957 6488 5439 2924 1209 5760 2270 7088 3169 7280 4457 7086 1951 2705 6259 7086 3241 6855 4885 7096 4092 7944 7819 3162 3123 7096 3909 6150 7095 6894 5987 7828 2706 1917 5609 1212 7078 1206 4427 6733 7828 2576 6065 4693 7013 2872 3855 1716 7288 5782 3715 1800 1855 5760 5812 1206 6369 3714 1209 5561 4139 5899 2692 2358 1212 7088 3460 7794 2689 1209 5561 1212 7088 4086 6888 7721 7483 6197 1476 5760 3977 1209 5561 5859 7921 1824 5147 2705 5658 2573 6242 1209 5760 2658 6527 1209 5561 1815 4197 7100 2044 5547 6122 6412 6664 773 3533 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁벤 투 ▁감독이 ▁이끄는 ▁축구 대표팀 이 ▁일 ▁오후 ▁인천공항 을 ▁통해 ▁터키 ▁이 스 탄 불 로 ▁출국 했다 ▁벤 투 ▁감독이 ▁인터뷰 하고 ▁있다 ▁벤 투 호는 ▁조 지 아 와 ▁평가 전을 ▁치른 ▁후 ▁투 르 크 메 니스 탄 과 년 ▁카 타 르 ▁월드컵 ▁아시아 지역 ▁차 예 선 ▁차 전을 ▁치른 다 ▁인천공항 ▁정 재 근 기자 ▁벤 투 ▁감독이 ▁이끄는 ▁축구 대표팀 이 ▁일 ▁오후 ▁인천공항 을 ▁통해 ▁터키 ▁이 스 탄 불 로 ▁출국 했다 ▁벤 투 ▁감독이 ▁인터뷰 하고 ▁있다 ▁벤 투 호는 ▁조 지 아 와 ▁평가 전을 ▁치른 ▁후 ▁투 르 크 메 니스 탄 과 년 ▁카 타 르 ▁월드컵 ▁아시아 지역 ▁차 예 선 ▁차 전을 ▁치른 다 ▁인천공항 ▁정 재 근 기자 ▁미국 ▁대표 ▁골프 브랜드 ▁파워 빌 트 ▁풀 세트 만원 대 ▁할인 ▁이 혜 정 ▁남편 ▁외 도로 ▁상처 ▁바람 ▁피 운 ▁직접 ▁봤 더니 ▁배우 ▁곽 진영 ▁성형 수술 ▁실패 ▁집 도 한 ▁의사 ▁자살 ▁강남 ▁예비 신 부 ▁이상 화 ▁매달 ▁받는 ▁연금 은 ▁얼마 ▁조 혜 련 ▁강호동 칠 순 에 ▁낸 천만원 ▁수 표 ▁돌려 달라 고 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 2336 7641 790 3652 4562 5823 7096 3803 3434 3791 7088 4756 4730 3647 6664 7590 6424 6079 4570 7869 2336 7641 790 3795 7788 3862 2336 7641 7926 4162 7318 6797 6983 4842 7213 4622 5176 4762 6113 7565 6190 5773 7590 5468 5712 4635 7581 6113 3548 3116 7337 4402 6957 6559 4402 7213 4622 5782 3791 4092 7191 5546 5580 2336 7641 790 3652 4562 5823 7096 3803 3434 3791 7088 4756 4730 3647 6664 7590 6424 6079 4570 7869 2336 7641 790 3795 7788 3862 2336 7641 7926 4162 7318 6797 6983 4842 7213 4622 5176 4762 6113 7565 6190 5773 7590 5468 5712 4635 7581 6113 3548 3116 7337 4402 6957 6559 4402 7213 4622 5782 3791 4092 7191 5546 5580 2150 1674 1019 6434 4803 6451 7659 4888 6588 6153 5808 4981 3647 7922 7227 1425 3468 5860 2679 2195 4909 7010 4358 2421 5838 2292 1072 7346 2800 6637 3055 4384 5859 7828 3629 3906 808 3402 6733 6398 3704 7941 1989 2224 3340 7086 3252 4162 7922 6067 823 7490 6643 6896 1454 7424 2872 7741 1733 5794 5439 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-4\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁키 움 히 어 로 즈 와 ▁롯데 ▁자 이 언 츠 의 ▁리그 ▁경기가 ▁일 ▁고 척 스카 이 돔 에서 ▁열렸다 회초 ▁사 ▁루 ▁롯데 ▁전 병 우 의 ▁루 땅 볼 때 ▁홈 으로 ▁파 고 들 던 ▁루 주 자 ▁이대호 가 ▁태 그 아웃 되고 ▁있다 ▁고 척 돔 ▁허 상 욱 기자 ▁키 움 히 어 로 즈 와 ▁롯데 ▁자 이 언 츠 의 ▁리그 ▁경기가 ▁일 ▁고 척 스카 이 돔 에서 ▁열렸다 회초 ▁사 ▁루 ▁롯데 ▁전 병 우 의 ▁루 땅 볼 때 ▁홈 으로 ▁파 고 들 던 ▁루 주 자 ▁이대호 가 ▁태 그 아웃 되고 ▁있다 ▁고 척 돔 ▁허 상 욱 기자 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 4693 7014 7996 6855 6079 7310 6983 1893 3886 7096 6865 7478 7095 1901 957 3803 993 7421 6677 7096 5869 6903 3361 7961 2573 1895 1893 4012 6361 7005 7095 1895 5964 6386 5965 5104 7078 4799 5439 5931 5842 1895 7276 7147 3660 5330 4720 5538 6803 5887 3862 993 7421 5869 5037 6527 7009 5580 4693 7014 7996 6855 6079 7310 6983 1893 3886 7096 6865 7478 7095 1901 957 3803 993 7421 6677 7096 5869 6903 3361 7961 2573 1895 1893 4012 6361 7005 7095 1895 5964 6386 5965 5104 7078 4799 5439 5931 5842 1895 7276 7147 3660 5330 4720 5538 6803 5887 3862 993 7421 5869 5037 6527 7009 5580 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-5\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] 으로부터 ▁보고 받은 ▁국방 위원장 기자 들에게 ▁밝혀 안 규 백 ▁국회 ▁국방 위원장 연합 뉴스 안 규 백 ▁국회 ▁국방 위원장 이 ▁일 ▁전날 ▁중 러 ▁군 용 기 의 ▁한국 방 공 식 별 구역 ▁카 디 즈 와 ▁영 공 ▁침 범 에 ▁대해 ▁이번 ▁사건 은 ▁의도 된 ▁중 러 의 ▁합동 훈련 으로 ▁보고 ▁있다 며 ▁이는 ▁어제 ▁국방부 가 ▁초 치 한 ▁주 한 ▁중 러 ▁무 관 들도 ▁인정 했던 ▁사실 이라고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁국방부 ▁관계자들 로부터 ▁현안 ▁보고 를 ▁받은 ▁후 기자 들과 ▁만나 ▁이같이 ▁말했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기가 ▁울 릉 도 ▁북 동 쪽 에서 ▁합류 해 ▁카 디 즈 에 ▁침 범 하고 ▁조기 경 보기 까지 ▁작동 했기 ▁때문에 상당히 ▁계획 적인 ▁행동 으로 ▁보인다 ▁고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁합 참 으로부터 ▁중국 ▁러시아 ▁군 용 기 의 ▁카 디 즈 ▁침 범 과 ▁독 도 ▁영 유 권을 ▁주장 하는 ▁일본의 ▁자 위 대 ▁군 용 기 ▁긴급 발 진 ▁사건 ▁등에 ▁관 해 ▁대 면 ▁보고 를 ▁받았다 ▁하지만 ▁이날 ▁청와대 는 ▁전날 ▁러시아 ▁차 석 ▁무 관 이 ▁우리 ▁군 에 ▁이번 ▁사태 에 ▁대해 ▁깊은 ▁유감 을 ▁표명 한다 면서 ▁기기 ▁오 작 동 으로 ▁계획 되지 ▁않은 ▁지역 에 ▁진입 한 ▁것으로 ▁생각한다 ▁고 ▁밝혔다 고 ▁공개했다 ▁안 ▁위원장 이 ▁이날 ▁군 으로부터 ▁보고 받은 ▁것과 ▁다른 ▁얘기 를 ▁비슷한 ▁시각 ▁청와대 가 ▁군 을 ▁인 용 해 ▁밝힌 ▁것이다 ▁이와 ▁관련 ▁안 ▁위원장은 ▁러시아 의 ▁기기 오 작 동 ▁내용 ▁그 것 은 ▁보고 받 지 ▁못했다 면서 ▁실수 가 ▁아니라 고 ▁본다 ▁고 ▁했다 ▁그는 ▁중 러 ▁군 용 기가 ▁합류 해서 ▁내려 왔 기 ▁때문에 ▁의도 가 ▁아니었다 는 ▁것은 ▁허 언 이라며 ▁러시아 의 ▁말 은 ▁성 립 하지 ▁않는다 ▁고 도 ▁했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기 의 ▁카 디 즈 ▁영 공 ▁침 범 ▁의도 에 ▁대해 ▁사 견 을 ▁전 제 로 ▁중 러 의 ▁군사 훈련 ▁협력 ▁시도 ▁아닌 가 ▁본다 며 ▁중국 으로서 는 ▁미 ▁중 ▁간 ▁무역 분 쟁 과 ▁미국의 ▁대 ▁대만 ▁무기 수 출 ▁등에 ▁따라 ▁액션 ▁행동 을 ▁취하고 ▁싶었 을 ▁것 이라고 ▁했다 ▁안 ▁위원장은 ▁야당 에서 ▁중 러 가 ▁한 ▁미 ▁일 ▁공 조 의 ▁빈 틈 을 ▁노 린 ▁것 이라고 ▁주장 하는 ▁것과 ▁관련해 ▁전혀 ▁사실이 ▁아니다 ▁라 면서 ▁몇 ▁주 ▁전 ▁주 한 미 군 ▁사 령 관 을 ▁만 났 을 ▁때 ▁한 ▁미 연합 훈련 ▁강 도 가 ▁얼마나 ▁세 지고 ▁빈 도 가 ▁많아 졌 는 지 ▁얘기 를 ▁들었다 ▁고 ▁했다 ▁일본 이 ▁독 도 를 ▁자 국 ▁영 토 라고 ▁주장 하며 ▁한국 ▁공 군의 ▁경고 ▁사 격 에 ▁항 의 한 ▁것에 ▁대해서는 ▁우리가 ▁실 효 적으로 ▁지배 하고 ▁우리 ▁경찰 이 ▁주 둔 하면서 ▁지키 는 ▁우리 ▁영 토 를 ▁일본 이 ▁말 할 ▁자격 과 ▁여건 이 ▁안 된다 면서 ▁일본의 ▁천 민 자본 주의 적 ▁발 상 에 ▁기 인 한 ▁착 각 이라고 ▁했다 ▁그는 ▁또 ▁의도 적 ▁계획 적 ▁침 범 이 기 ▁때문에 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 7079 2358 6293 1149 7053 5580 5936 2258 6812 5532 6314 1162 1149 7053 6938 5754 6812 5532 6314 1162 1149 7053 7096 3803 4016 4257 6037 1165 7003 5561 7095 4958 6305 5452 6730 6356 5499 4635 5947 7310 6983 3376 5452 4630 6333 6896 1685 3697 2574 7086 3622 5899 4257 6037 7095 4987 7971 7078 2358 3862 6197 3658 3238 1150 5330 4501 7483 7828 4213 7828 4257 6037 2095 5474 5933 3785 7872 2604 7102 5019 3135 3559 3656 3431 1150 1079 6080 5060 2358 6116 2232 5176 5580 5932 1933 3649 1966 3135 3559 4257 6037 1165 7003 5562 3524 6120 5859 2462 5872 7376 6903 4988 7848 4635 5947 7310 6896 4630 6333 7788 4166 5424 6368 5592 3934 7866 1849 6530 990 7206 5023 7078 2392 993 5019 3135 3559 3656 3431 4984 7398 7079 4259 1881 1165 7003 5561 7095 4635 5947 7310 4630 6333 5468 1725 5859 3376 7063 5525 4236 7794 3810 3886 7044 5808 1165 7003 5561 1312 6295 7344 2574 1820 1073 7848 1633 6198 2358 6116 2230 4946 3656 4489 5760 4016 1881 4402 6557 2095 5474 7096 3501 1165 6896 3697 2630 6896 1685 1338 3576 7088 4881 7831 6199 1262 3417 7170 5872 7078 990 5898 3162 4329 6896 4366 7828 909 2708 993 2261 5439 1029 3135 3558 7096 3656 1165 7079 2358 6293 906 1567 3219 6116 2534 2961 4489 5330 1165 7088 3758 7003 7848 2264 913 3725 1083 3135 3559 1881 7095 1262 6964 7170 5872 1449 1185 5398 7086 2358 6288 7318 2093 6199 3042 5330 3101 5439 2413 993 5019 1191 4257 6037 1165 7003 5562 4988 7850 1442 6989 5561 1849 3622 5330 3103 5760 910 5037 6865 7105 1881 7095 1958 7086 2781 6137 7819 3152 993 5859 5019 3135 3559 4257 6037 1165 7003 5561 7095 4635 5947 7310 3376 5452 4630 6333 3622 6896 1685 2573 5414 7088 4012 7234 6079 4257 6037 7095 1167 7971 5073 2971 3105 5330 2413 6197 4259 7080 5760 2149 4257 777 2114 6416 7198 5468 2151 1633 1644 2097 6629 7468 1820 1835 3202 5023 7088 4610 3074 7088 905 7102 5019 3135 3559 3209 6903 4257 6037 5330 4955 2149 3803 1023 7253 7095 2547 7671 7088 1476 6133 905 7102 4236 7794 906 1087 4062 2607 3100 1875 6199 2043 4213 4012 4213 7828 6255 5512 2573 6077 5474 7088 1931 5671 7088 1844 4955 2149 6938 7971 807 5859 5330 3253 2801 7321 2547 5859 5330 1952 7248 5760 7318 3219 6116 1811 993 5019 3809 7096 1725 5859 6116 3886 5503 3376 7628 6004 4236 7810 4958 1023 5514 955 2573 5412 6896 4992 7095 7828 908 1687 3502 3036 7965 7203 4318 7788 3501 975 7096 4213 5909 7812 4344 5760 3501 3376 7628 6116 3809 7096 1958 7836 3887 5468 3300 7096 3135 5900 6199 3810 4471 6263 7161 7284 7202 2235 6527 6896 1258 7119 7828 4420 5336 7102 5019 1191 1861 3622 7202 990 7202 4630 6333 7096 5561 1849 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-5\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁계획 적인 ▁행동 으로 ▁보인다 ▁고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁합 참 으로부터 ▁중국 ▁러시아 ▁군 용 기 의 ▁카 디 즈 ▁침 범 과 ▁독 도 ▁영 유 권을 ▁주장 하는 ▁일본의 ▁자 위 대 ▁군 용 기 ▁긴급 발 진 ▁사건 ▁등에 ▁관 해 ▁대 면 ▁보고 를 ▁받았다 ▁하지만 ▁이날 ▁청와대 는 ▁전날 ▁러시아 ▁차 석 ▁무 관 이 ▁우리 ▁군 에 ▁이번 ▁사태 에 ▁대해 ▁깊은 ▁유감 을 ▁표명 한다 면서 ▁기기 ▁오 작 동 으로 ▁계획 되지 ▁않은 ▁지역 에 ▁진입 한 ▁것으로 ▁생각한다 ▁고 ▁밝혔다 고 ▁공개했다 ▁안 ▁위원장 이 ▁이날 ▁군 으로부터 ▁보고 받은 ▁것과 ▁다른 ▁얘기 를 ▁비슷한 ▁시각 ▁청와대 가 ▁군 을 ▁인 용 해 ▁밝힌 ▁것이다 ▁이와 ▁관련 ▁안 ▁위원장은 ▁러시아 의 ▁기기 오 작 동 ▁내용 ▁그 것 은 ▁보고 받 지 ▁못했다 면서 ▁실수 가 ▁아니라 고 ▁본다 ▁고 ▁했다 ▁그는 ▁중 러 ▁군 용 기가 ▁합류 해서 ▁내려 왔 기 ▁때문에 ▁의도 가 ▁아니었다 는 ▁것은 ▁허 언 이라며 ▁러시아 의 ▁말 은 ▁성 립 하지 ▁않는다 ▁고 도 ▁했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기 의 ▁카 디 즈 ▁영 공 ▁침 범 ▁의도 에 ▁대해 ▁사 견 을 ▁전 제 로 ▁중 러 의 ▁군사 훈련 ▁협력 ▁시도 ▁아닌 가 ▁본다 며 ▁중국 으로서 는 ▁미 ▁중 ▁간 ▁무역 분 쟁 과 ▁미국의 ▁대 ▁대만 ▁무기 수 출 ▁등에 ▁따라 ▁액션 ▁행동 을 ▁취하고 ▁싶었 을 ▁것 이라고 ▁했다 ▁안 ▁위원장은 ▁야당 에서 ▁중 러 가 ▁한 ▁미 ▁일 ▁공 조 의 ▁빈 틈 을 ▁노 린 ▁것 이라고 ▁주장 하는 ▁것과 ▁관련해 ▁전혀 ▁사실이 ▁아니다 ▁라 면서 ▁몇 ▁주 ▁전 ▁주 한 미 군 ▁사 령 관 을 ▁만 났 을 ▁때 ▁한 ▁미 연합 훈련 ▁강 도 가 ▁얼마나 ▁세 지고 ▁빈 도 가 ▁많아 졌 는 지 ▁얘기 를 ▁들었다 ▁고 ▁했다 ▁일본 이 ▁독 도 를 ▁자 국 ▁영 토 라고 ▁주장 하며 ▁한국 ▁공 군의 ▁경고 ▁사 격 에 ▁항 의 한 ▁것에 ▁대해서는 ▁우리가 ▁실 효 적으로 ▁지배 하고 ▁우리 ▁경찰 이 ▁주 둔 하면서 ▁지키 는 ▁우리 ▁영 토 를 ▁일본 이 ▁말 할 ▁자격 과 ▁여건 이 ▁안 된다 면서 ▁일본의 ▁천 민 자본 주의 적 ▁발 상 에 ▁기 인 한 ▁착 각 이라고 ▁했다 ▁그는 ▁또 ▁의도 적 ▁계획 적 ▁침 범 이 기 ▁때문에 ▁메뉴 얼 에 ▁따라 ▁대응 하 되 ▁보다 ▁강 도 높 은 ▁조치 가 ▁있어야 ▁한다고 ▁생각한다 면서 ▁국방 위원장 으로서 ▁국방부 에 ▁앞으로 ▁이런 ▁일이 ▁재발 했을 때 ▁우리 ▁군 의 ▁힘을 ▁보여줄 ▁수 ▁있는 ▁강력한 ▁대응 을 ▁주문 했다 ▁고 ▁했다 ▁안 ▁위원장은 ▁군 의 ▁대응 에 ▁대해 ▁실시간 으로 ▁출 격 해 ▁적절 하게 ▁대응 하며 ▁훌륭 한 ▁임 무 를 ▁수행 했다고 ▁생각한다 면서 ▁군사 합 의 ▁이후 ▁우리 ▁군 의 ▁대비 태 세를 ▁점검 하는 ▁좋은 ▁계기가 ▁됐다 ▁고 ▁했다 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 990 7206 5023 7078 2392 993 5019 3135 3559 3656 3431 4984 7398 7079 4259 1881 1165 7003 5561 7095 4635 5947 7310 4630 6333 5468 1725 5859 3376 7063 5525 4236 7794 3810 3886 7044 5808 1165 7003 5561 1312 6295 7344 2574 1820 1073 7848 1633 6198 2358 6116 2230 4946 3656 4489 5760 4016 1881 4402 6557 2095 5474 7096 3501 1165 6896 3697 2630 6896 1685 1338 3576 7088 4881 7831 6199 1262 3417 7170 5872 7078 990 5898 3162 4329 6896 4366 7828 909 2708 993 2261 5439 1029 3135 3558 7096 3656 1165 7079 2358 6293 906 1567 3219 6116 2534 2961 4489 5330 1165 7088 3758 7003 7848 2264 913 3725 1083 3135 3559 1881 7095 1262 6964 7170 5872 1449 1185 5398 7086 2358 6288 7318 2093 6199 3042 5330 3101 5439 2413 993 5019 1191 4257 6037 1165 7003 5562 4988 7850 1442 6989 5561 1849 3622 5330 3103 5760 910 5037 6865 7105 1881 7095 1958 7086 2781 6137 7819 3152 993 5859 5019 3135 3559 4257 6037 1165 7003 5561 7095 4635 5947 7310 3376 5452 4630 6333 3622 6896 1685 2573 5414 7088 4012 7234 6079 4257 6037 7095 1167 7971 5073 2971 3105 5330 2413 6197 4259 7080 5760 2149 4257 777 2114 6416 7198 5468 2151 1633 1644 2097 6629 7468 1820 1835 3202 5023 7088 4610 3074 7088 905 7102 5019 3135 3559 3209 6903 4257 6037 5330 4955 2149 3803 1023 7253 7095 2547 7671 7088 1476 6133 905 7102 4236 7794 906 1087 4062 2607 3100 1875 6199 2043 4213 4012 4213 7828 6255 5512 2573 6077 5474 7088 1931 5671 7088 1844 4955 2149 6938 7971 807 5859 5330 3253 2801 7321 2547 5859 5330 1952 7248 5760 7318 3219 6116 1811 993 5019 3809 7096 1725 5859 6116 3886 5503 3376 7628 6004 4236 7810 4958 1023 5514 955 2573 5412 6896 4992 7095 7828 908 1687 3502 3036 7965 7203 4318 7788 3501 975 7096 4213 5909 7812 4344 5760 3501 3376 7628 6116 3809 7096 1958 7836 3887 5468 3300 7096 3135 5900 6199 3810 4471 6263 7161 7284 7202 2235 6527 6896 1258 7119 7828 4420 5336 7102 5019 1191 1861 3622 7202 990 7202 4630 6333 7096 5561 1849 2017 6870 6896 1835 1659 7782 5886 2368 807 5859 5736 7086 4188 5330 3870 4966 2708 6199 1149 7053 7080 1150 6896 3192 3672 3818 3979 7879 5965 3501 1165 7095 5214 2379 2872 3860 811 1659 7088 4227 7869 993 5019 3135 3559 1165 7095 1659 6896 1685 3044 7078 4568 5412 7848 4009 7784 1659 7810 5185 7828 3826 6228 6116 2909 7870 2708 6199 1167 7842 7095 3756 3501 1165 7095 1649 7598 6585 4075 7794 4209 981 1762 993 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-6\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] 도 널 드 ▁트 럼 프 ▁미국 ▁대통령의 ▁국가 비 상 사 태 ▁선 포 에 ▁저 항 하는 ▁시위 가 ▁일 ▁미국 ▁전역 에서 ▁열릴 ▁예정 이라고 투데이 가 ▁일 현지시간 ▁보도했다 ▁보도 에 ▁따르면 ▁무 브 온 ▁등 ▁시민 사회 단체 들은 ▁뉴욕 ▁노 스 다 코 타 ▁캘리포니아 텍 사 스 ▁등 ▁미국 ▁곳 곳 에서 ▁수십 건 의 ▁시위 를 ▁준비 하고 ▁있다 ▁트 럼 프 ▁대통령이 ▁국가 비 상 사 태 를 ▁선 포 해 ▁남부 ▁국 경 ▁지역 에 ▁국 경 장 벽 을 ▁건설 하는 ▁것에 ▁대응 하기 ▁위한 ▁성격 이다 ▁무 브 온 은 ▁트 럼 프 의 ▁위험 한 ▁국가 ▁권력 ▁사용 으로부터 ▁이민 자 ▁무 슬 림 ▁유 색 인 종 ▁커뮤니티 를 ▁지키 기 ▁위해 ▁비 폭력 적인 ▁긴급 ▁이벤트를 ▁열 게 ▁됐다 ▁고 ▁밝혔다 ▁일부 ▁시민들 은 ▁국가 비 상 사 태 ▁선 포 ▁직후 ▁주말 ▁동안 ▁소 규모 ▁시위 를 ▁열 기도 ▁했다 ▁뉴욕 ▁경찰은 ▁지난 ▁일 ▁뉴욕 ▁맨 해 튼 ▁트 럼 프 인터내셔널 ▁호텔 ▁인근 에서 ▁시위 를 ▁벌 이 던 ▁시민들 을 ▁체포 했다 ▁또 ▁캘리포니아 주 텍 사 스 ▁엘 패 소 ▁카 운 티 ▁등 ▁지방 정부 와 ▁개인 ▁단체 들은 ▁트 럼 프 ▁행정 부 를 ▁상대로 ▁줄 소송 을 ▁예고 하고 ▁있다 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 5859 5696 5920 4773 6043 7753 2150 1669 1133 6441 6527 6493 7598 2734 7728 6896 3990 7846 7794 2985 5330 3803 2150 4046 6903 3366 3413 7102 7642 5330 3803 7908 2371 2369 6896 1838 2095 6432 6971 1815 2974 6514 5791 5937 1543 1476 6664 5782 7533 7581 4647 7620 6493 6664 1815 2150 1021 5451 6903 2889 5384 7095 2985 6116 4249 7788 3862 4773 6043 7753 1670 1133 6441 6527 6493 7598 6116 2734 7728 7848 1415 1132 5424 4329 6896 1132 5424 7178 6354 7088 885 7794 908 1659 7789 3566 2782 7100 2095 6432 6971 7086 4773 6043 7753 7095 3571 7828 1133 1171 2613 7079 3695 7147 2095 6697 6136 3574 6538 7119 7268 4653 6116 4344 5561 3567 2514 7735 7206 1312 3700 3358 5400 1762 993 2261 3811 2976 7086 1133 6441 6527 6493 7598 2734 7728 4359 4223 1754 2822 5533 2985 6116 3358 5570 5019 1543 978 4304 3803 1543 2004 7848 7668 4773 6043 7753 7124 5095 3762 6903 2985 6116 2309 7096 5842 2976 7088 4498 7869 1861 4647 7276 7620 6493 6664 3295 7697 6607 4635 7010 7673 1815 4316 7230 6983 847 1594 5937 4773 6043 7753 5030 6398 6116 2665 4252 6612 7088 3397 7788 3862 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-7\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁뉴욕 시 의 원 ▁법안 ▁제출 하기로 북한 에 억 류 됐다 ▁풀 려 난 ▁지 ▁일주일 ▁만에 ▁숨진 ▁미국 ▁대학생 오토 웜 비 어 의 ▁가족 들에게 ▁북한 ▁정부가 억달러 ▁약 억원 를 ▁배 상 하라 는 ▁미국 ▁법원 ▁판결 문 이 ▁북한 에 ▁송 달 됐다 고 ▁미국의 소리 ▁방송 이 ▁일 ▁현지 ▁시각 ▁보도했다 에 ▁따르면 ▁워싱턴 ▁연방 법원 은 웜 비 어 ▁가족 에 ▁대한 ▁배 상 판 결 을 ▁담은 ▁판결 문을 ▁지난 ▁일 ▁국제 우 편 서비스 인 을 ▁통해 ▁평 양 의 ▁북한 ▁외 무 성 으로 ▁보냈다 ▁수 신 인 은 ▁리 용 호 ▁북한 ▁외 무 상 이며 ▁배 달 ▁완료 ▁시점 은 ▁이달 ▁일 이다 웜 비 어 ▁가족 은 ▁지난해 월 에도 을 ▁통해 ▁평 양 ▁소재 ▁외 무 성 으로 ▁소장 을 ▁보 냈 고 ▁당시 ▁김 이란 ▁인물 이 ▁우 편 물을 ▁받았다 고 는 ▁전했다 ▁미 ▁폭 스 뉴스 는 ▁이날 ▁미 ▁뉴욕 시 의 ▁조 ▁보 렐 리 ▁공화당 ▁시 의 원이 ▁주 유 엔 ▁북한 대표 부가 ▁있는 ▁뉴욕 ▁맨 해 튼 ▁이 스트 사이드 ▁거리 의 ▁이름을 ▁세 컨 드 ▁애 비 뉴 에서 오토 웜 비 어 길 로 ▁바꾸 는 ▁법안 을 ▁제출 할 ▁예정 이라고 ▁보도했다 ▁국제 ▁인권 단체 인 ▁휴 먼 라이 츠 워 치는 ▁이날 ▁발표한 ▁세계 인 권 보고서 ▁북한 편 에서 ▁북한 은 ▁공포 ▁정치 와 ▁주민 ▁통제 를 ▁유지 하기 ▁위해 ▁체포 와 ▁처벌 ▁처 형 을 ▁일상 적으로 ▁자 행 하는 ▁세계 에서 ▁가장 억 압 적인 ▁국가 라고 ▁했다 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 1543 6705 7095 7020 2325 4156 7791 6415 6896 6858 6107 5880 4888 6060 5663 4297 3822 1946 2921 2150 1681 6968 0 6441 6855 7095 765 5936 2465 4107 6859 3211 6861 6116 2287 6527 7804 5760 2150 2326 4806 6234 7096 2465 6896 2869 5793 5880 5439 2151 6609 2272 7096 3803 5066 2961 2371 6896 1838 3532 3346 6336 7086 0 6441 6855 765 6896 1682 2287 6527 7688 5415 7088 1614 4806 6235 4304 3803 1155 7005 7720 6555 7119 7088 4756 4841 6853 7095 2465 3468 6228 6573 7078 2365 2872 6733 7119 7086 1900 7003 7925 2465 3468 6228 6527 7108 2287 5793 3457 2997 7086 3659 3803 7100 0 6441 6855 765 7086 4306 7028 6901 7088 4756 4841 6853 2846 3468 6228 6573 7078 2845 7088 2355 5686 5439 1626 1316 7107 3768 7096 3498 7720 6242 2230 5439 5760 4061 2149 4871 6664 5754 5760 3656 2149 1543 6705 7095 4162 2355 6057 6122 1056 2959 7095 7027 4213 7063 6909 2465 5822 6399 3860 1543 2004 7848 7668 3647 6691 6509 871 7095 3688 2801 7514 5920 3194 6441 5753 6903 6968 0 6441 6855 5585 6079 2187 5760 2325 7088 4156 7836 3413 7102 2371 1155 3761 5791 7119 5191 6184 6011 7478 7018 7485 3656 2252 2802 7119 5524 6367 2465 7720 6903 2465 7086 1054 4122 6983 4228 4752 6116 3592 7789 3567 4498 6983 4466 4464 7921 7088 3812 7203 3886 7881 7794 2802 6903 760 6858 6825 7206 1133 6004 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁같은 ▁화장실 ▁같은 ▁수 법 ▁두 ▁달 ▁전 ▁범죄 와 ▁같아 ▁안 심 ▁화장실 ▁인증 ▁오히려 ▁몰 카 찍 기 ▁좋은 ▁날 힌 트 돼 ▁현실 적인 ▁대안 ▁시 급 ▁화장실 ▁앞 ▁설치 해야 ▁서울시 가 ▁몰 카 ▁범죄 를 ▁예방 한다는 ▁취지 로 ▁공공 화 장 실 을 ▁대상으로 ▁도입 한 ▁안 심 ▁화장실 에서 ▁불법 ▁촬영 ▁범죄 가 ▁발생했다 ▁안 심 ▁화장실 에서 ▁몰 래 카 메 라 를 ▁찍 고 도 망 가 는 ▁범죄 가 ▁이어 지면서 ▁실 효 성이 ▁없다는 ▁지적 이 ▁나온다 ▁일 ▁서울 ▁서 대 문 경찰서 에 ▁따르면 ▁씨는 ▁지난 ▁일 ▁오후 ▁시 분쯤 ▁지하철 호선 ▁신 촌 역 ▁인근 ▁한 ▁주 상 복합 ▁상 가 층 ▁안 심 ▁화장실 에 ▁들어갔다 ▁씨는 뚜 껑 이 닫 혀 있 던 ▁변 기 의 ▁물 을 ▁내리 고 ▁변 기를 ▁휴 지 로 ▁한 ▁번 닦 았다 ▁그때 ▁머리 ▁위 에서 ▁인기 척 을 ▁느꼈 다 ▁순간 적으로 위를 쳐 다 봤 지만 ▁아무 것 도 ▁없었다 ▁씨는 ▁변 기에 앉 으면서 도 ▁경계 를 늦 추 지 ▁않고 ▁천 장을 ▁계속 ▁응시 했다고 ▁한다 ▁일 러 스트 ▁정 다운 몇 ▁초 ▁뒤 ▁셀카 ▁모 드 로 ▁설정 된 ▁휴대전화 ▁카메라 가 ▁머리 ▁위로 ▁슬 며 시 ▁올라 왔다 ▁당황 한 ▁씨가 ▁지금 ▁뭐 하는 ▁거 냐 ▁고 ▁소리 치 자 ▁피의자 는 ▁화장실 ▁밖으로 ▁달아 났다 ▁씨는 ▁경찰에 ▁신고 한 ▁뒤 ▁건물 ▁폐쇄 회 로 를 ▁확인 하고 자 ▁했지만 ▁경찰은 ▁화장실 ▁쪽 을 ▁비 추 는 가 ▁없어 ▁드 나 든 ▁사람들 ▁모습을 ▁확인할 ▁수 ▁없다 ▁고 ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 833 5118 833 2872 6335 1773 1597 4012 2320 6983 832 3135 6745 5118 3787 3435 2081 7495 7384 5561 4209 1407 7997 7659 5876 5059 7206 1656 2959 5558 5118 3184 2779 7852 2728 5330 2081 7495 2320 6116 3401 7833 4609 6079 1032 7941 7178 6738 7088 1652 1720 7828 3135 6745 5118 6903 2496 4518 2320 5330 2246 3135 6745 5118 6903 2081 6023 7495 6190 6003 6116 4400 5439 5859 6165 5330 5760 2320 5330 3716 7331 3036 7965 6577 3275 4336 7096 1392 3803 2726 2718 5808 6234 5432 6896 1838 3090 4304 3803 3434 2959 6423 4347 7927 3010 7449 6926 3762 4955 4213 6527 6381 2658 5330 7482 3135 6745 5118 6896 1808 3090 5984 5610 7096 5792 7899 7141 5842 2339 5561 7095 2135 7088 1444 5439 2339 5573 5191 7318 6079 4955 2307 5787 6828 1194 2008 3552 6903 3763 7421 7088 1545 5782 2913 7203 7049 7443 5782 6395 7330 3111 5398 5859 3280 3090 2339 5579 6819 7084 5859 954 6116 5767 7461 7318 3149 4471 7187 984 3616 7870 4965 3803 6037 6691 4092 5785 6212 4501 1783 2820 2044 5920 6079 2778 5899 5193 4639 5330 2008 3554 2948 6197 6705 3440 6990 1632 7828 3089 4299 2145 7794 862 5689 993 2829 7483 7147 4911 5760 5118 2206 1603 5672 3090 977 3012 7828 1783 884 4854 7953 6079 6116 5130 7788 7147 5021 978 5118 4398 7088 2514 7461 5760 5330 3278 1788 5655 5928 2585 2058 5132 2872 3273 993 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁변 기 의 ▁물 을 ▁내리 고 ▁변 기를 ▁휴 지 로 ▁한 ▁번 닦 았다 ▁그때 ▁머리 ▁위 에서 ▁인기 척 을 ▁느꼈 다 ▁순간 적으로 위를 쳐 다 봤 지만 ▁아무 것 도 ▁없었다 ▁씨는 ▁변 기에 앉 으면서 도 ▁경계 를 늦 추 지 ▁않고 ▁천 장을 ▁계속 ▁응시 했다고 ▁한다 ▁일 러 스트 ▁정 다운 몇 ▁초 ▁뒤 ▁셀카 ▁모 드 로 ▁설정 된 ▁휴대전화 ▁카메라 가 ▁머리 ▁위로 ▁슬 며 시 ▁올라 왔다 ▁당황 한 ▁씨가 ▁지금 ▁뭐 하는 ▁거 냐 ▁고 ▁소리 치 자 ▁피의자 는 ▁화장실 ▁밖으로 ▁달아 났다 ▁씨는 ▁경찰에 ▁신고 한 ▁뒤 ▁건물 ▁폐쇄 회 로 를 ▁확인 하고 자 ▁했지만 ▁경찰은 ▁화장실 ▁쪽 을 ▁비 추 는 가 ▁없어 ▁드 나 든 ▁사람들 ▁모습을 ▁확인할 ▁수 ▁없다 ▁고 ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 2339 5561 7095 2135 7088 1444 5439 2339 5573 5191 7318 6079 4955 2307 5787 6828 1194 2008 3552 6903 3763 7421 7088 1545 5782 2913 7203 7049 7443 5782 6395 7330 3111 5398 5859 3280 3090 2339 5579 6819 7084 5859 954 6116 5767 7461 7318 3149 4471 7187 984 3616 7870 4965 3803 6037 6691 4092 5785 6212 4501 1783 2820 2044 5920 6079 2778 5899 5193 4639 5330 2008 3554 2948 6197 6705 3440 6990 1632 7828 3089 4299 2145 7794 862 5689 993 2829 7483 7147 4911 5760 5118 2206 1603 5672 3090 977 3012 7828 1783 884 4854 7953 6079 6116 5130 7788 7147 5021 978 5118 4398 7088 2514 7461 5760 5330 3278 1788 5655 5928 2585 2058 5132 2872 3273 993 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 2\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 ▁동 일 한 ▁사건 이 ▁발생했다 ▁지난 월 ▁일 ▁이 ▁화장실 ▁변 기에 ▁앉아 ▁있던 ▁양 은 ▁바닥 에 ▁비 친 ▁검 은 ▁그림 자를 ▁보고 ▁위 에서 ▁자신을 ▁찍 고 ▁있는 ▁휴대전화 ▁카메라 를 ▁발견 했다 ▁당시 ▁경찰은 ▁최근 ▁발생 하는 ▁몰 카 ▁범죄 는 ▁남성 이 ▁몰 래 ▁여성 ▁화장실 에 ▁들어가 ▁휴대전화 를 ▁직접 ▁들고 ▁찍은 ▁뒤 도 주 하는 ▁기 법 이 ▁대부분 이라며 ▁화장실 ▁근처 에 가 ▁없 으면 ▁용의자 를 ▁특정 하기 ▁쉽지 ▁않은 ▁것이 ▁현실 이라고 ▁했다 ▁서울 ▁관 내 ▁한 경찰서 ▁여성 청소년 과 장은 ▁휴대전화 를 ▁들고 ▁불법 으로 ▁찍은 ▁뒤 도 망 가 는 ▁경우 엔 ▁피해자 가 위를 ▁보고 ▁적발 하지 ▁않는 ▁이상 ▁피해를 ▁입은 ▁사실 도 ▁모르 는 ▁경우가 ▁많다 며 ▁전국 적으로 ▁얼마나 ▁많은 ▁몰 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 1741 7126 7828 2574 7096 2246 4304 7028 3803 3647 5118 2339 5579 3145 3865 3214 7086 2192 6896 2514 7489 895 7086 1212 7158 2358 3552 6903 3912 4400 5439 3860 5193 4639 6116 2236 7869 1626 978 4525 2243 7794 2081 7495 2320 5760 1419 7096 2081 6023 3312 5118 6896 1805 5193 6116 4358 1802 4401 1783 5859 7276 7794 1258 6335 7096 1647 7105 5118 1229 6896 5330 3270 7083 3496 6116 4786 7789 2925 3162 912 5059 7102 5019 2726 1073 5678 4955 5432 3312 7434 5468 7186 5193 6116 1802 2496 7078 4401 1783 5859 6165 5330 5760 968 6909 4915 5330 7049 2358 4001 7819 3151 3704 4914 3843 2604 5859 2049 5760 969 1951 6197 4014 7203 3253 1955 2081 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 3\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 ▁동 일 한 ▁사건 이 ▁발생했다 ▁지난 월 ▁일 ▁이 ▁화장실 ▁변 기에 ▁앉아 ▁있던 ▁양 은 ▁바닥 에 ▁비 친 ▁검 은 ▁그림 자를 ▁보고 ▁위 에서 ▁자신을 ▁찍 고 ▁있는 ▁휴대전화 ▁카메라 를 ▁발견 했다 ▁당시 ▁경찰은 ▁최근 ▁발생 하는 ▁몰 카 ▁범죄 는 ▁남성 이 ▁몰 래 ▁여성 ▁화장실 에 ▁들어가 ▁휴대전화 를 ▁직접 ▁들고 ▁찍은 ▁뒤 도 주 하는 ▁기 법 이 ▁대부분 이라며 ▁화장실 ▁근처 에 가 ▁없 으면 ▁용의자 를 ▁특정 하기 ▁쉽지 ▁않은 ▁것이 ▁현실 이라고 ▁했다 ▁서울 ▁관 내 ▁한 경찰서 ▁여성 청소년 과 장은 ▁휴대전화 를 ▁들고 ▁불법 으로 ▁찍은 ▁뒤 도 망 가 는 ▁경우 엔 ▁피해자 가 위를 ▁보고 ▁적발 하지 ▁않는 ▁이상 ▁피해를 ▁입은 ▁사실 도 ▁모르 는 ▁경우가 ▁많다 며 ▁전국 적으로 ▁얼마나 ▁많은 ▁몰 카 범 ▁이 ▁이런 ▁수 법 으로 ▁범죄 를 ▁행 하고 ▁있는 지 조차 가 늠 하기 ▁어려운 ▁실 정 이라고 ▁말했다 ▁전문가들은 ▁직접 ▁들고 ▁찍 는 ▁몰 카 가 활 개를 치는 ▁만큼 ▁실질적인 ▁조치 가 ▁시 급 하다고 ▁지적 한다 ▁곽 대 경 ▁동 국 대 ▁경찰 행정 학 부 ▁교수는 ▁피의자 가 ▁범죄 를 ▁저 지를 ▁때는 ▁쉽게 ▁범행 을 ▁할 ▁수 ▁있고 ▁잡 히 지 ▁않을 ▁수 ▁있는 ▁곳 을 찾 으려 ▁하는 ▁경 향 이 ▁있다 며 ▁안 심 ▁화장실 ▁인증 ▁시점 을 ▁오히려 ▁가리 거나 ▁화장실 ▁쪽 에 를 ▁설치 하고 ▁경비 원을 ▁배치 하는 ▁것이 ▁대안 이 ▁될 ▁수 ▁있다 ▁고 ▁했다 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 1741 7126 7828 2574 7096 2246 4304 7028 3803 3647 5118 2339 5579 3145 3865 3214 7086 2192 6896 2514 7489 895 7086 1212 7158 2358 3552 6903 3912 4400 5439 3860 5193 4639 6116 2236 7869 1626 978 4525 2243 7794 2081 7495 2320 5760 1419 7096 2081 6023 3312 5118 6896 1805 5193 6116 4358 1802 4401 1783 5859 7276 7794 1258 6335 7096 1647 7105 5118 1229 6896 5330 3270 7083 3496 6116 4786 7789 2925 3162 912 5059 7102 5019 2726 1073 5678 4955 5432 3312 7434 5468 7186 5193 6116 1802 2496 7078 4401 1783 5859 6165 5330 5760 968 6909 4915 5330 7049 2358 4001 7819 3151 3704 4914 3843 2604 5859 2049 5760 969 1951 6197 4014 7203 3253 1955 2081 7495 6333 3647 3672 2872 6335 7078 2320 6116 5022 7788 3860 7318 7261 5330 5764 7789 3226 3036 7227 7102 1966 4036 4358 1802 4400 5760 2081 7495 5330 7948 5361 7485 1948 3052 4188 5330 2959 5558 7799 4336 7831 1072 5808 5424 1741 5503 5808 975 7885 7821 6398 1108 4911 5330 2320 6116 3990 7329 1846 2924 2321 7088 4977 2872 3857 3950 7996 7318 3163 2872 3860 1021 7088 7404 7077 4930 953 7886 7096 3862 6197 3135 6745 5118 3787 2997 7088 3435 750 5378 5118 4398 6896 6116 2779 7788 966 7025 2296 7794 912 1656 7096 1772 2872 3862 993 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-9\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁그룹 ▁블랙 핑크 가 ▁해외 ▁일정 ▁참석 차 ▁일 ▁오전 ▁김 포 국제 공항 을 ▁통해 ▁일본 으로 ▁출국 하고 ▁있다 ▁블랙 핑크 ▁리 사가 ▁출국 장으로 ▁향 하고 ▁있다 ▁김 포 공항 ▁박 재 만 기자 ▁그룹 ▁블랙 핑크 가 ▁해외 ▁일정 ▁참석 차 ▁일 ▁오전 ▁김 포 국제 공항 을 ▁통해 ▁일본 으로 ▁출국 하고 ▁있다 ▁블랙 핑크 ▁리 사가 ▁출국 장으로 ▁향 하고 ▁있다 ▁김 포 공항 ▁박 재 만 기자 만원 ▁금 장 ▁골프 ▁풀 세트 ▁단독 ▁할인 만원 ▁대 ▁판매 ▁이병헌 ▁동생 ▁이 지 안 에 로 배우 ▁출신 ▁이 국 적 ▁외모 ▁때문 ▁속 옷 ▁벗 겨 ▁중요 부 위 ▁노출 ▁유명 ▁스타 ▁성추행 ▁사건 에 ▁휘 말 려 ▁마 약 ▁함께 ▁투 약 로 버 트 ▁할 리 ▁지 인 ▁임신 한 ▁여 친 과 ▁동 거 ▁중 ▁옥 주 현 ▁시 선 강 탈 ▁비 키 니 ▁몸매 쭉 뻗 은 ▁각 선 미 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 1208 2510 7781 5330 5012 3820 4431 7389 3803 3431 1316 7728 5510 5465 7088 4756 3809 7078 4570 7788 3862 2510 7781 1900 6494 4570 7185 5032 7788 3862 1316 7728 5465 2199 7191 6150 5580 1208 2510 7781 5330 5012 3820 4431 7389 3803 3431 1316 7728 5510 5465 7088 4756 3809 7078 4570 7788 3862 2510 7781 1900 6494 4570 7185 5032 7788 3862 1316 7728 5465 2199 7191 6150 5580 6153 1235 7178 1019 4888 6588 1588 4981 6153 1633 4809 3701 1750 3647 7318 6812 6896 6079 6313 4578 3647 5503 7202 3473 1848 2856 6981 2331 5411 4270 6398 7044 1489 3585 2938 2796 2574 6896 5189 6160 6060 1907 6846 4983 4762 6846 6079 6323 7659 4977 6122 4297 7119 3833 7828 3298 7489 5468 1741 5377 4257 3436 7276 7903 2959 6559 5350 7591 2514 7573 5770 2085 7380 6474 7086 773 6559 6255 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 5 (id = [5.0])\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   guid: train-10\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   tokens: [CLS] ▁이 균 재 기자 ▁이 강 인 ▁발 렌 시아 ▁이 ▁올 ▁시즌 ▁처음으로 ▁그 라운드 를 밟 아 ▁동 갑 내기 ▁구 보 ▁다 케 후 사 ▁마 요 르 카 와 ▁맞대결 을 ▁펼쳤다 ▁이 강 인 은 ▁일 ▁이하 한국시간 ▁새벽 ▁스페인 ▁발 렌 시아 의 ▁메 스타 야 ▁스타 디 움 서 ▁열린 ▁마 요 르 카 와 ▁시즌 ▁스페인 ▁프리 메 라 리 가 라운드 ▁홈경기 서 ▁후반 ▁분 ▁교체 ▁출 격 해 ▁분 간 ▁뛰 었다 ▁이 강 인 은 ▁지난달 ▁일 ▁리그 라운드 서 ▁대기 명 단 에 ▁이름을 ▁올 렸지만 ▁출 격 ▁호 출 을 ▁받지 ▁못했다 ▁이날 라운드 서 ▁시즌 ▁처음으로 ▁출전 ▁기회를 ▁잡았다 ▁이 강 인 은 으로 ▁앞선 ▁후반 ▁분 ▁케 빈 가 메이 로 를 ▁대신 해 ▁그 라운드 를 밟 았다 ▁구 보 가 ▁앞서 ▁후반 ▁분 ▁교체 ▁투입 돼 ▁미니 ▁한 일 전 이 ▁성 사 됐다 ▁구 보는 ▁올 ▁여름 ▁레알 ▁마드리드 서 ▁마 요 르 카 로 ▁임대 돼 ▁이날 ▁프리 메 라 리 가 ▁데뷔 전을 ▁치 렀다 ▁한국 과 ▁일본 ▁축구 의 ▁미래 인 ▁이 강 인 과 ▁구 보는 ▁짧은 ▁시간 ▁출전 ▁덕 에 ▁인상 적인 ▁장면 을 ▁만들 지는 ▁못했다 ▁한편 ▁발 렌 시아 는 ▁전반 ▁분 과 ▁후반 ▁분 ▁다니 ▁파 레 호 의 ▁연 이 은 ▁페널티 킥 ▁득점 으로 ▁시즌 ▁첫 ▁승 을 ▁거뒀다 [SEP]\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_ids: 2 3647 5536 7191 5580 3647 5350 7119 2235 6056 6714 3647 3439 2998 4469 1185 6010 6116 6302 6797 1741 5345 5680 1115 6364 1562 7523 7968 6493 1907 6999 6113 7495 6983 1972 7088 4838 3647 5350 7119 7086 3803 3751 7830 2701 2944 2235 6056 6714 7095 2016 6684 6844 2938 5947 7014 6553 3364 1907 6999 6113 7495 6983 2998 2944 4904 6190 6003 6122 5330 6010 5105 6553 5178 2468 1111 4568 5412 7848 2468 5337 1867 6888 3647 5350 7119 7086 4305 3803 1901 6010 6553 1638 6204 5788 6896 3688 3439 6076 4568 5412 5090 7468 7088 2234 2093 3656 6010 6553 2998 4469 4585 1308 3953 3647 5350 7119 7086 7078 3188 5178 2468 4662 6450 5330 6191 6079 6116 1655 7848 1185 6010 6116 6302 6828 1115 6364 5330 3187 5178 2468 1111 4767 5876 2152 4955 7126 7207 7096 2781 6493 5880 1115 6369 3439 3307 1886 1910 6553 1907 6999 6113 7495 6079 3829 5876 3656 4904 6190 6003 6122 5330 1707 7213 4617 6047 4958 5468 3809 4562 7095 2155 7119 3647 5350 7119 5468 1115 6369 4397 2962 4585 1701 6896 3773 7206 3960 7088 1940 7327 2093 4974 2235 6056 6714 5760 4037 2468 5468 5178 2468 1564 4799 6050 7925 7095 3332 7096 7086 4830 7575 1797 7078 2998 4481 2949 7088 865 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/26/2019 07:35:18 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 이거 캐쉬로 저장하는거 추가하면 좋을듯.. 그냥 그렇다고. qa에 있던데..ㅎㅎ\n",
    "train_examples = None\n",
    "num_train_steps = None\n",
    "if args['do_train']:\n",
    "    train_examples = processor.get_train_examples()\n",
    "#     train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'])\n",
    "    train_features = convert_examples_to_features(\n",
    "        train_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n",
    "    num_train_steps = int(\n",
    "        len(train_features) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/26/2019 07:37:04 - INFO - run_classifier_spm -   ***Now, Model is on the device!!!***\n"
     ]
    }
   ],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "model = BertForMultiLabelSequenceClassification(bert_config, num_labels = num_labels)\n",
    "model.bert.load_state_dict(torch.load(init_checkpoint))\n",
    "\n",
    "model.to(device)\n",
    "logger.info(\"***Now, Model is on the device!!!***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
    "\n",
    "class CyclicLR(object):\n",
    "    \"\"\"Sets the learning rate of each parameter group according to\n",
    "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
    "    rate between two boundaries with a constant frequency, as detailed in\n",
    "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
    "    The distance between the two boundaries can be scaled on a per-iteration\n",
    "    or per-cycle basis.\n",
    "    Cyclical learning rate policy changes the learning rate after every batch.\n",
    "    `batch_step` should be called after a batch has been used for training.\n",
    "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
    "    This class has three built-in policies, as put forth in the paper:\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
    "        cycle iteration.\n",
    "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        base_lr (float or list): Initial learning rate which is the\n",
    "            lower boundary in the cycle for eachparam groups.\n",
    "            Default: 0.001\n",
    "        max_lr (float or list): Upper boundaries in the cycle for\n",
    "            each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore\n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function. Default: 0.006\n",
    "        step_size (int): Number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch. Default: 2000\n",
    "        mode (str): One of {triangular, triangular2, exp_range}.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "            Default: 'triangular'\n",
    "        gamma (float): Constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "            Default: 1.0\n",
    "        scale_fn (function): Custom scaling policy defined by a single\n",
    "            argument lambda function, where\n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored\n",
    "            Default: None\n",
    "        scale_mode (str): {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on\n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle).\n",
    "            Default: 'cycle'\n",
    "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
    "    Example:\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
    "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
    "        >>> for epoch in range(10):\n",
    "        >>>     for batch in data_loader:\n",
    "        >>>         scheduler.batch_step()\n",
    "        >>>         train_batch(...)\n",
    "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "#         if not isinstance(optimizer, Optimizer):\n",
    "#             raise TypeError('{} is not an Optimizer'.format(\n",
    "#                 type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "if args['local_rank'] != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "if args['fp16']:\n",
    "    try:\n",
    "        from apex.contrib.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=args['learning_rate'],\n",
    "                          bias_correction=False)\n",
    "#     if args['loss_scale'] == 0:\n",
    "#         optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "#     else:\n",
    "#         optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
    "\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=args['learning_rate'],\n",
    "                         warmup=args['warmup_proportion'],\n",
    "                         t_total=t_total)\n",
    "\n",
    "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "if args['fp16']:\n",
    "    model, optimizer = amp.initialize(model, optimizer, \n",
    "                                      opt_level=args['fp16_opt_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['local_rank'] != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultiLabelSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'apex.contrib' from '/usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apex\n",
    "apex.parallel.DistributedDataParallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Default process group is not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a210638de37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_allreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, message_size, delay_allreduce, shared_param, allreduce_trigger_params, retain_allreduce_buffers, allreduce_always_fp32, num_allreduce_streams, allreduce_communicators, gradient_average, gradient_predivide_factor, gradient_average_split_factor, prof)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/commit/044d00516ccd6572c0d6ab6d54587155b02a3b86\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DistBackend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_enum_holder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mget_backend\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0m_check_default_pg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_check_default_pg\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[1;32m    190\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0m_default_pg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;34m\"Default process group is not initialized\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Default process group is not initialized"
     ]
    }
   ],
   "source": [
    "DDP(model, delay_allreduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Default process group is not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9f09c1f7ba63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_allreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, message_size, delay_allreduce, shared_param, allreduce_trigger_params, retain_allreduce_buffers, allreduce_always_fp32, num_allreduce_streams, allreduce_communicators, gradient_average, gradient_predivide_factor, gradient_average_split_factor, prof)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/commit/044d00516ccd6572c0d6ab6d54587155b02a3b86\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DistBackend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_enum_holder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mget_backend\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m     \u001b[0m_check_default_pg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_check_default_pg\u001b[0;34m()\u001b[0m\n\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[1;32m    190\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0m_default_pg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;34m\"Default process group is not initialized\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Default process group is not initialized"
     ]
    }
   ],
   "source": [
    "## 이부분은 main으로 짤때에 그때에 torch.distributed.launch.py를 source 해와서 짜자리\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# model = DDP(model, delay_allreduce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eval Fn\n",
    "# eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
    "\n",
    "def eval():\n",
    "\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.long)##민성 change\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "    \n",
    "    all_logits = None\n",
    "    all_labels = None\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = label_ids.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "#         tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
    "        if all_logits is None:\n",
    "            all_logits = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "            \n",
    "        if all_labels is None:\n",
    "            all_labels = label_ids.detach().cpu().numpy()\n",
    "        else:    \n",
    "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
    "        \n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    \n",
    "\n",
    "    result = {'eval_loss': eval_loss,\n",
    "              'eval_accuracy': eval_accuracy}#,\n",
    "#               'loss': tr_loss/nb_tr_steps,\n",
    "#               'roc_auc': roc_auc  }\n",
    "\n",
    "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Num features = %d\", len(train_features))\n",
    "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.long)\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "if args['local_rank'] == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.unfreeze_bert_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tensorboard_dir = output_dir / \"tensorboard\"\n",
    "tensorboard_dir.mkdir(exist_ok=True)\n",
    "tb_writer = SummaryWriter(tensorboard_dir)\n",
    "\n",
    "global_step = 0\n",
    "tr_loss, logging_loss, epoch_loss = 0.0, 0.0, 0.0\n",
    "model.train()\n",
    "for i_ in tqdm(range(int(args['num_train_epochs'])), desc=\"Epoch\"):\n",
    "\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if args['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "        if args['fp16']:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "#             scheduler.batch_step()\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "        if args['logging_steps']>0 and global_step % args['logging_steps']==0:\n",
    "            tb_writer.add_scalar(\"loss\",(tr_loss - logging_loss) / args['logging_steps'],global_step,)\n",
    "            tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
    "        logging_loss = tr_loss\n",
    "    logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
    "    logger.info('Eval after epoc {}'.format(i_+1))\n",
    "        \n",
    "tb_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = os.path.join(output_dir, \"finetuned_news_doc_stride_pytorch_model_d128_m512_FP16.bin\")\n",
    "torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a trained model that you have fine-tuned\n",
    "# model_state_dict = torch.load(output_model_file)\n",
    "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_examples = processor.get_test_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = convert_examples_to_features(\n",
    "    test_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input_data = [{'id':feature.guid, 'doc_index':feature.doc_span_index} for feature in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits = None\n",
    "\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
    "    input_ids, input_mask, segment_ids = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits = logits.sigmoid()## softmax\n",
    "\n",
    "    if all_logits is None:\n",
    "        all_logits = logits.detach().cpu().numpy()\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "\n",
    "    nb_eval_examples += input_ids.size(0)\n",
    "    nb_eval_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(pd.DataFrame(new_input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[:, 'pred'] = a.iloc[:,2:].apply(lambda x: x.idxmax(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/advice/notebook/jms/우리은행/data/news_te.txt', \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    lines = []\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "t = [i[1] for i in lines[1:]]\n",
    "real_val = [{'id':'test-'+str(idx+1), 'real':real}for idx, real in enumerate(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(pd.DataFrame(a.groupby('id')['pred'].max()).reset_index(),\n",
    "                 pd.DataFrame(real_val), \n",
    "                 on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[final.pred == final.real].shape[0]/final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
