{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "from torch import Tensor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import pdb\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_dir = Path('/home/advice/notebook/jms/우리은행')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(fund_dir/'pytorch-pretrained-BERT/examples/')\n",
    "sys.path.append(fund_dir/'pytorch-pretrained-BERT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_classifier_spm import *\n",
    "from  pytorch_pretrained_bert import modeling\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/advice/notebook/jms/우리은행/output_dir/ 20191225  already exists\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "today = str(today).replace('-', '')\n",
    "direc = fund_dir/'output_dir/'\n",
    "try:\n",
    "    os.mkdir(direc+today)\n",
    "    print(direc , today ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(direc , today ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "from torch import Tensor\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import pdb\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = fund_dir/\"extract_kobert\"\n",
    "\n",
    "vocab_file = '/home/advice/notebook/jms/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece'\n",
    "bert_config_file = model_dir / \"kobert_config.json\"\n",
    "init_checkpoint = model_dir / \"kobert_model.bin\"\n",
    "bert_model = 'kobert'\n",
    "PATH = fund_dir/\"data/\"\n",
    "\n",
    "output_dir = direc+today+'/'\n",
    "train_file = fund_dir/\"data/news_tr.txt\"\n",
    "eval_file = fund_dir/\"data/news_te.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_size\": -1,\n",
    "    \"val_size\": -1,\n",
    "    \"full_data_dir\": train_file,\n",
    "    \"data_dir\": PATH,\n",
    "    \"task_name\": \"news_multilabel\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": model_dir,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"tokenizer\": vocab_file,\n",
    "    \"max_seq_length\": 512,\n",
    "    \"doc_stride\": 128,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"eval_batch_size\": 32,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_train_epochs\": 4.0,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    'fp16_opt_level':'01',\n",
    "    \"loss_scale\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:10 - INFO - tokenization_spm -   loading vocabulary file /home/advice/notebook/jms/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BERTSPMTokenizer.from_pretrained(args['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁이',\n",
       " '균',\n",
       " '재',\n",
       " '기자',\n",
       " '▁이',\n",
       " '강',\n",
       " '인',\n",
       " '▁발',\n",
       " '렌',\n",
       " '시아',\n",
       " '▁이',\n",
       " '▁올',\n",
       " '▁시즌',\n",
       " '▁처음으로',\n",
       " '▁그',\n",
       " '라운드',\n",
       " '를',\n",
       " '밟',\n",
       " '아',\n",
       " '▁동',\n",
       " '갑',\n",
       " '내기',\n",
       " '▁구',\n",
       " '보',\n",
       " '▁다',\n",
       " '케',\n",
       " '후',\n",
       " '사',\n",
       " '▁마',\n",
       " '요',\n",
       " '르',\n",
       " '카',\n",
       " '와',\n",
       " '▁맞대결',\n",
       " '을',\n",
       " '▁펼쳤다',\n",
       " '▁이',\n",
       " '강',\n",
       " '인',\n",
       " '은',\n",
       " '▁일',\n",
       " '▁이하',\n",
       " '한국시간',\n",
       " '▁새벽',\n",
       " '▁스페인',\n",
       " '▁발',\n",
       " '렌',\n",
       " '시아',\n",
       " '의',\n",
       " '▁메',\n",
       " '스타',\n",
       " '야',\n",
       " '▁스타',\n",
       " '디',\n",
       " '움',\n",
       " '서',\n",
       " '▁열린',\n",
       " '▁마',\n",
       " '요',\n",
       " '르',\n",
       " '카',\n",
       " '와',\n",
       " '▁시즌',\n",
       " '▁스페인',\n",
       " '▁프리',\n",
       " '메',\n",
       " '라',\n",
       " '리',\n",
       " '가',\n",
       " '라운드',\n",
       " '▁홈경기',\n",
       " '서',\n",
       " '▁후반',\n",
       " '▁분',\n",
       " '▁교체',\n",
       " '▁출',\n",
       " '격',\n",
       " '해',\n",
       " '▁분',\n",
       " '간',\n",
       " '▁뛰',\n",
       " '었다',\n",
       " '▁이',\n",
       " '강',\n",
       " '인',\n",
       " '은',\n",
       " '▁지난달',\n",
       " '▁일',\n",
       " '▁리그',\n",
       " '라운드',\n",
       " '서',\n",
       " '▁대기',\n",
       " '명',\n",
       " '단',\n",
       " '에',\n",
       " '▁이름을',\n",
       " '▁올',\n",
       " '렸지만',\n",
       " '▁출',\n",
       " '격',\n",
       " '▁호',\n",
       " '출',\n",
       " '을',\n",
       " '▁받지',\n",
       " '▁못했다',\n",
       " '▁이날',\n",
       " '라운드',\n",
       " '서',\n",
       " '▁시즌',\n",
       " '▁처음으로',\n",
       " '▁출전',\n",
       " '▁기회를',\n",
       " '▁잡았다',\n",
       " '▁이',\n",
       " '강',\n",
       " '인',\n",
       " '은',\n",
       " '으로',\n",
       " '▁앞선',\n",
       " '▁후반',\n",
       " '▁분',\n",
       " '▁케',\n",
       " '빈',\n",
       " '가',\n",
       " '메이',\n",
       " '로',\n",
       " '를',\n",
       " '▁대신',\n",
       " '해',\n",
       " '▁그',\n",
       " '라운드',\n",
       " '를',\n",
       " '밟',\n",
       " '았다',\n",
       " '▁구',\n",
       " '보',\n",
       " '가',\n",
       " '▁앞서',\n",
       " '▁후반',\n",
       " '▁분',\n",
       " '▁교체',\n",
       " '▁투입',\n",
       " '돼',\n",
       " '▁미니',\n",
       " '▁한',\n",
       " '일',\n",
       " '전',\n",
       " '이',\n",
       " '▁성',\n",
       " '사',\n",
       " '됐다',\n",
       " '▁구',\n",
       " '보는',\n",
       " '▁올',\n",
       " '▁여름',\n",
       " '▁레알',\n",
       " '▁마드리드',\n",
       " '서',\n",
       " '▁마',\n",
       " '요',\n",
       " '르',\n",
       " '카',\n",
       " '로',\n",
       " '▁임대',\n",
       " '돼',\n",
       " '▁이날',\n",
       " '▁프리',\n",
       " '메',\n",
       " '라',\n",
       " '리',\n",
       " '가',\n",
       " '▁데뷔',\n",
       " '전을',\n",
       " '▁치',\n",
       " '렀다',\n",
       " '▁한국',\n",
       " '과',\n",
       " '▁일본',\n",
       " '▁축구',\n",
       " '의',\n",
       " '▁미래',\n",
       " '인',\n",
       " '▁이',\n",
       " '강',\n",
       " '인',\n",
       " '과',\n",
       " '▁구',\n",
       " '보는',\n",
       " '▁짧은',\n",
       " '▁시간',\n",
       " '▁출전',\n",
       " '▁덕',\n",
       " '에',\n",
       " '▁인상',\n",
       " '적인',\n",
       " '▁장면',\n",
       " '을',\n",
       " '▁만들',\n",
       " '지는',\n",
       " '▁못했다',\n",
       " '▁한편',\n",
       " '▁발',\n",
       " '렌',\n",
       " '시아',\n",
       " '는',\n",
       " '▁전반',\n",
       " '▁분',\n",
       " '과',\n",
       " '▁후반',\n",
       " '▁분',\n",
       " '▁다니',\n",
       " '▁파',\n",
       " '레',\n",
       " '호',\n",
       " '의',\n",
       " '▁연',\n",
       " '이',\n",
       " '은',\n",
       " '▁페널티',\n",
       " '킥',\n",
       " '▁득점',\n",
       " '으로',\n",
       " '▁시즌',\n",
       " '▁첫',\n",
       " '▁승',\n",
       " '을',\n",
       " '▁거뒀다']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/advice/notebook/jms/우리은행/data/news_tr.txt', \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    lines = []\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "tokenizer.tokenize(lines[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            #loss_fct = BCEWithLogitsLoss()\n",
    "            #loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None, doc_span_index = None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            labels: (Optional) [string]. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.labels = labels\n",
    "        self.doc_span_index = doc_span_index## chris changed\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self,guid, input_ids, input_mask, segment_ids, label_ids, doc_span_index):\n",
    "        self.guid = guid\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids\n",
    "        self.doc_span_index = doc_span_index## chris changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelTextProcessor(DataProcessor):\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = None\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines    \n",
    "    \n",
    "    def get_train_examples(self, data_dir, size=-1):\n",
    "        filename = 'news_tr.txt'\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"train\")\n",
    "        \n",
    "    def get_dev_examples(self, data_dir, size=-1):\n",
    "        filename = 'news_te.txt'\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"dev\")\n",
    "    \n",
    "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
    "        filename = 'news_te.txt'\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, filename)), \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        if self.labels == None:\n",
    "            self.labels = ['0', '1', '2', '3', '4', '5']\n",
    "        return self.labels\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[0]\n",
    "            text_b = None\n",
    "            label = line[1]\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, text_b=text_b, labels=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, doc_stride):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "    features_all = []\n",
    "    for (ex_index, example) in enumerate(tqdm(examples)):\n",
    "        \n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "        tokens_b = None\n",
    "\n",
    "        max_tokens_for_doc = max_seq_length  - 2\n",
    "        _DocSpan = collections.namedtuple(  \n",
    "            \"DocSpan\", [\"start\", \"length\"])\n",
    "        doc_spans = []\n",
    "        start_offset = 0\n",
    "\n",
    "        while start_offset < len(tokens_a):\n",
    "            length = len(tokens_a) - start_offset\n",
    "            if length > max_tokens_for_doc:\n",
    "                length = max_tokens_for_doc\n",
    "            doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "            if start_offset + length == len(tokens_a):\n",
    "                break\n",
    "            start_offset += min(length, doc_stride)\n",
    "\n",
    "        for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "            features = []\n",
    "            tokens = []\n",
    "            segment_ids = [0]*max_seq_length\n",
    "            tokens.append(\"[CLS]\")\n",
    "            \n",
    "            for i in range(doc_span.length):\n",
    "                split_token_index = doc_span.start + i\n",
    "                tokens.append(tokens_a[split_token_index])\n",
    "\n",
    "            tokens.append(\"[SEP]\")\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "            input_mask = [1] * len(input_ids)\n",
    "            \n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            input_mask += padding\n",
    "\n",
    "            \n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "            labels_ids = []\n",
    "            for label in example.labels:\n",
    "                labels_ids.append(float(label))\n",
    "\n",
    "#         label_id = label_map[example.label]\n",
    "#chris changed\n",
    "\n",
    "            if ex_index < 10:\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"guid: %s\" % (example.guid))\n",
    "                logger.info(\"doc_span_index: %s\" % (doc_span_index))\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\n",
    "                        \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
    "\n",
    "            features.append(\n",
    "                    InputFeatures(guid = example.guid,\n",
    "                                  input_ids=input_ids,\n",
    "                                  input_mask=input_mask,\n",
    "                                  segment_ids=segment_ids,\n",
    "                                  label_ids=labels_ids, \n",
    "                                  doc_span_index = doc_span_index))\n",
    "            features_all.extend(features)## extend가 맞남... 모르겟다링~\n",
    "    return features_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    out_cpu = out.cpu().numpy()\n",
    "    labels_cpu = labels.cpu().numpy()\n",
    "    outputs = np.argmax(out_cpu, axis=1)\n",
    "    return np.sum(outputs == labels_cpu)\n",
    "\n",
    "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "#     return ((y_pred>thresh)==y_true.byte()).float().mean().item()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup_linear(x, warmup=0.002):\n",
    "    if x < warmup:\n",
    "        return x/warmup\n",
    "    return 1.0 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:20 - INFO - run_classifier_spm -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False\n"
     ]
    }
   ],
   "source": [
    "processors = {\n",
    "    \"news_multilabel\": MultiLabelTextProcessor\n",
    "}\n",
    "\n",
    "# Setup GPU parameters\n",
    "\n",
    "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "#     n_gpu = 1\n",
    "else:\n",
    "    torch.cuda.set_device(args['local_rank'])\n",
    "    device = torch.device(\"cuda\", args['local_rank'])\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args['seed'])\n",
    "np.random.seed(args['seed'])\n",
    "torch.manual_seed(args['seed'])\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_multilabel': __main__.MultiLabelTextProcessor}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = args['task_name'].lower()\n",
    "\n",
    "if task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (task_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = processors[task_name](args['data_dir'])\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:25 - INFO - tokenization_spm -   loading vocabulary file /home/advice/notebook/jms/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BERTSPMTokenizer.from_pretrained(args['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:26 - INFO - run_classifier_spm -   LOOKING AT /home/advice/notebook/jms/우리은행/data/news_tr.txt\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4c51b6c78c4cd9beefe813d975a522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41850.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁김 예 솔 기자 ▁김 세 정 이 ▁김 시 후 의 ▁죽음 에 ▁관심을 ▁갖 기 ▁시작했다 ▁일 에 ▁방송된 ▁너 의 ▁노래 를 ▁들려 줘 에서는 ▁홍 이 영 ▁김 세 정 ▁이 ▁기억 을 잃 기 ▁전 ▁자신 과 ▁김 이 안 ▁김 시 후 ▁이 ▁연 관 이 ▁있다는 ▁사실을 ▁알게 됐다 ▁앞서 ▁홍 이 영 은 ▁유 제 니 ▁조 유 정 에게 ▁김 이 안 에 ▁대해 ▁물 었다 ▁유 제 니 는 개월 ▁전 ▁네 가 ▁어 시 스트 했던 ▁사람이 다 라고 ▁말했다 ▁하지만 ▁홍 이 영 은 ▁기억 하지 ▁못했다 ▁유 제 니 는 ▁어떻게 보 면 잊 어 버린 ▁게 ▁좋 을 ▁수도 ▁있다 ▁알 던 ▁사람이 ▁죽 으면 ▁기분 ▁나 쁘 지 ▁않 냐 ▁고 ▁말했다 ▁이날 ▁홍 이 영 은 ▁장 윤 ▁연 우 진 을 ▁만나 자 ▁반 갑 게 ▁인사 했다 ▁두 ▁사람은 ▁키스 ▁후 ▁처음 ▁마 주 친 ▁상황 ▁하지만 ▁장 윤 은 ▁홍 이 영 의 ▁눈 을 ▁피 하며 ▁인사 하지 ▁않았다 ▁홍 이 영 은 ▁영 찜 찜 했다 ▁홍 이 영 은 ▁장 윤 에게 ▁왜 ▁날 ▁피 하 냐 며 ▁그냥 ▁돌려 ▁말 하지 ▁않겠다 ▁장 윤 씨는 ▁원래 ▁여자 랑 ▁키스 하고 쌩 까 시 냐 ▁고 ▁물 었다 ▁홍 이 영 은 ▁장 윤 씨가 ▁나 에 ▁대해 ▁알고 ▁싶다 고 ▁하지 ▁않았 냐 ▁나는 ▁되 게 ▁단순 한 ▁사람이 라 ▁그냥 ▁그 렇 구나 라고 ▁생각한다 ▁그래서 ▁그 날 도 ▁마음 ▁가는 대로 솔 직 하게 ▁직 진 했던 거 다 라고 ▁말했다 ▁이어 ▁홍 이 영 은 ▁장 윤 에게 ▁나 ▁김 이 안 씨 ▁만난 ▁것 ▁같다 ▁그 ▁분 이 ▁내 한 했을 ▁때 ▁잠 깐 ▁어 시 스트 를 했다고 ▁하 더라 며 ▁그 ▁분 에 ▁대해 ▁알고 ▁싶어 졌다 ▁기억 해 내 고 ▁싶다 ▁고 ▁말했다 ▁장 윤 은 ▁괴 로운 ▁기억 일 ▁수도 ▁있다 끔 찍 한 ▁기억 일 ▁수도 ▁있는데 ▁괜찮 겠 냐 ▁고 ▁물 었다 ▁홍 이 영 은 ▁좋은 ▁기억 일 ▁수도 ▁있다 ▁무 섭 지 ▁않다 ▁고 ▁말했다 ▁이어 ▁홍 이 영 은 ▁이 브 닝 콜 도 ▁끝내 겠다 ▁고 ▁선언 했다 ▁사진 ▁너 의 ▁노래 를 ▁들려 줘 ▁방송 캡 쳐 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 1316 6957 6618 5580 1316 6579 7227 7096 1316 6705 7968 7095 4245 6896 1090 825 5561 2990 3803 6896 2274 1457 7095 1479 6116 1803 7303 6904 5108 7096 6951 1316 6579 7227 3647 1291 7088 7135 5561 4012 3909 5468 1316 7096 6812 1316 6705 7968 3647 3332 5474 7096 3864 2606 3167 5880 3187 5108 7096 6951 7086 3574 7234 5770 4162 7063 7227 6897 1316 7096 6812 6896 1685 2135 6888 3574 7234 5770 5760 5366 4012 1469 5330 3220 6705 6691 7872 2589 5782 6004 1966 4946 5108 7096 6951 7086 1291 7819 2093 3574 7234 5770 5760 3225 6364 6198 7145 6855 6325 921 4204 7088 2874 3862 3166 5842 2589 4244 7083 1282 1370 6488 7318 3146 5689 993 1966 3656 5108 7096 6951 7086 3954 7068 3332 7005 7344 7088 1933 7147 2207 5345 5400 3769 7869 1773 2587 4694 5176 4468 1907 7276 7489 2689 4946 3954 7068 7086 5108 7096 6951 7095 1535 7088 4909 7810 3769 7819 3157 5108 7096 6951 7086 3376 7387 7387 7869 5108 7096 6951 7086 3954 7068 6897 3466 1407 4909 7782 5689 6197 1189 1733 1958 7819 3148 3954 7068 6787 3537 3318 6022 4694 7788 0 5591 6705 5689 993 2135 6888 5108 7096 6951 7086 3954 7068 6786 1370 6896 1685 3168 3072 5439 4945 3156 5689 1375 1763 5400 1591 7828 2589 6003 1189 1185 6049 5496 6004 2708 1195 1185 5664 5859 1917 736 5812 6618 7342 7784 4349 7344 7872 5377 5782 6004 1966 3716 5108 7096 6951 7086 3954 7068 6897 1370 1316 7096 6812 6785 1934 905 831 1185 2468 7096 1434 7828 7879 1844 3945 5595 3220 6705 6691 6116 7870 4924 5839 6197 1185 2468 6896 1685 3168 3073 7250 1291 7848 5678 5439 3072 993 1966 3954 7068 7086 1101 6082 1291 7126 2874 3862 5646 7384 7828 1291 7126 2874 3861 1100 5405 5689 993 2135 6888 5108 7096 6951 7086 4209 1291 7126 2874 3862 2095 6570 7318 3153 993 1966 3716 5108 7096 6951 7086 3647 6432 5781 7542 5859 1367 5406 993 2758 7869 2627 1457 7095 1479 6116 1803 7303 2272 7510 7443 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 5 (id = [5.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁화 염 과 ▁분노 트 럼 프 의 ▁기 행 과 ▁러시아 스캔들 ▁주요 ▁인선 ▁뒷 이 야 기 ▁등 ▁백악관 의 ▁내 막 을 ▁공개 해 ▁출 간 ▁주 일 ▁만에 ▁만 부가 ▁팔 린 ▁화제 의 ▁책 이 ▁번 역 ▁출 간 됐다 ▁저 자인 ▁마 이 클 ▁울 프 는 ▁트 럼 프 ▁행정 부 ▁전 ▁현 직 ▁관계자 ▁여 명을 ▁인터뷰 하고 ▁백악관 ▁내부 의 ▁권력 ▁투 쟁 과 ▁격 변 의 ▁국정 ▁운영 ▁현장 을 ▁자세 히 ▁조명 한다 ▁책 ▁속에 ▁보이는 ▁트 럼 프 의 ▁행보 는 ▁향후 ▁한반도 를 ▁비롯한 ▁미국의 ▁세계 ▁전략 을 가 늠 하게 ▁한다 ▁장 경 덕 옮 김 ▁은행 나무 ▁만 ▁원 ▁미 술 책을 ▁읽 다 ▁미 술 과 ▁생활 의 ▁접 점을 ▁찾아 주 고 ▁미 술 이 ▁일상 과 ▁함께 ▁하는 ▁것 임을 ▁알려 주는 ▁국내 ▁저 자가 ▁쓴 ▁미 술 ▁대중 서 ▁권 에 ▁대한 ▁서 평 에 세 이 집 ▁미 대를 ▁졸업 하고 ▁미 술 잡 지 ▁기 자로 ▁일 하다 ▁미 술 ▁전문 ▁출판 사를 ▁설립 해 년째 ▁책 을 ▁만들고 ▁있는 ▁지 은 이 가 ▁그간 ▁자신이 ▁어떤 ▁미 술 ▁책 을 ▁어떻게 ▁읽 었 는 지 에 ▁대해 ▁기록했다 ▁미 술 이란 ▁어렵 고 ▁고 상 한 ▁것 이라는 ▁편 견 을 ▁깨 고 ▁미 술 이 ▁주는 ▁기 쁨 을 ▁독자 와 ▁함께 ▁누 리는 ▁것이 ▁책 의 ▁지 향 점 이다 ▁정 민 영 ▁지 음 아트 북 스 ▁만 ▁원 ▁생존 ▁인 테 리 어 저 자는 ▁결혼 ▁후 ▁아파트 ▁장 만 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 5112 6941 5468 2469 7659 6043 7753 7095 1258 7881 5468 1881 6678 4233 3775 1786 7096 6844 5561 1815 2299 7095 1434 6149 7088 1026 7848 4568 5337 4213 7126 1946 1931 6399 4814 6133 5121 7095 4457 7096 2307 6926 4568 5337 5880 3990 7168 1907 7096 7568 3524 7753 5760 4773 6043 7753 5030 6398 4012 5049 7342 1077 3298 6209 3795 7788 2299 1446 7095 1171 4762 7198 5468 931 6355 7095 1152 3517 5062 7088 3907 7996 4170 7831 4457 2858 2389 4773 6043 7753 7095 5024 5760 5036 4970 6116 2525 2151 2802 4025 7088 5330 5764 7784 4965 3954 5424 5841 6976 5586 3605 5660 1931 3533 2149 6645 7409 3824 5782 2149 6645 5468 2717 7095 4086 7223 4446 7276 5439 2149 6645 7096 3812 5468 4983 4930 905 7137 3169 7280 1138 3990 7148 3086 2149 6645 1661 6553 1170 6896 1682 2718 7724 6896 6579 7096 7354 2149 5813 4195 7788 2149 6645 7176 7318 1258 7156 3803 7798 2149 6645 4033 4587 6500 2772 7848 5721 4457 7088 1941 3860 4297 7086 7096 5330 1187 3914 3224 2149 6645 4457 7088 3225 3824 6885 5760 7318 6896 1685 1277 2149 6645 7107 3231 5439 993 6527 7828 905 7103 4832 5414 7088 1342 5439 2149 6645 7096 4219 1258 6491 7088 1728 6983 4983 1526 6124 912 4457 7095 4297 7886 7220 7100 4092 6263 6951 4297 7089 6808 6412 6664 1931 3533 2715 3758 7618 6122 6855 7199 7150 950 5176 3131 3954 6150 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] 고 ▁미 술 이 ▁일상 과 ▁함께 ▁하는 ▁것 임을 ▁알려 주는 ▁국내 ▁저 자가 ▁쓴 ▁미 술 ▁대중 서 ▁권 에 ▁대한 ▁서 평 에 세 이 집 ▁미 대를 ▁졸업 하고 ▁미 술 잡 지 ▁기 자로 ▁일 하다 ▁미 술 ▁전문 ▁출판 사를 ▁설립 해 년째 ▁책 을 ▁만들고 ▁있는 ▁지 은 이 가 ▁그간 ▁자신이 ▁어떤 ▁미 술 ▁책 을 ▁어떻게 ▁읽 었 는 지 에 ▁대해 ▁기록했다 ▁미 술 이란 ▁어렵 고 ▁고 상 한 ▁것 이라는 ▁편 견 을 ▁깨 고 ▁미 술 이 ▁주는 ▁기 쁨 을 ▁독자 와 ▁함께 ▁누 리는 ▁것이 ▁책 의 ▁지 향 점 이다 ▁정 민 영 ▁지 음 아트 북 스 ▁만 ▁원 ▁생존 ▁인 테 리 어 저 자는 ▁결혼 ▁후 ▁아파트 ▁장 만 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 ▁법률 ▁조항 이 ▁없다 ▁법원 도 ▁공 인 이 ▁누구 인지 ▁정 의 를 ▁내리 거나 ▁그 ▁범 주 를 ▁정 하지 ▁않고 ▁있어 ▁공 인 에 ▁대한 ▁일 관 된 ▁법적 ▁판단 도 ▁없다 ▁언론 도 ▁어떤 ▁사람이 ▁공 인 이며 ▁어느 ▁정도 까지 ▁보도 해야 ▁하는 지 ▁정확한 가 이 드 라인 이 ▁존재 하지 ▁않아 ▁문제가 ▁생긴 다 ▁언론 과 ▁공 인 ▁사이에서 ▁명예 ▁훼손 ▁사 생활 ▁침해 ▁초 상 권 ▁침해 ▁관련 ▁판 례 ▁등을 ▁자세 히 ▁소개 한다 ▁이재 진 ▁지 음 ▁한 양 대학교 출 판 부 ▁만 ▁원 ▁생각 미술관 ▁그리 기 ▁시리즈 예 쁘 고 ▁쉽게 ▁그리 는 ▁방법 을 ▁알려 주는 ▁책 은 ▁많다 ▁생각 미술관 은 ▁언 어 ▁표현 이 ▁정 확 하지 ▁않은 ▁아이들 이 ▁자신 만 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 5439 2149 6645 7096 3812 5468 4983 4930 905 7137 3169 7280 1138 3990 7148 3086 2149 6645 1661 6553 1170 6896 1682 2718 7724 6896 6579 7096 7354 2149 5813 4195 7788 2149 6645 7176 7318 1258 7156 3803 7798 2149 6645 4033 4587 6500 2772 7848 5721 4457 7088 1941 3860 4297 7086 7096 5330 1187 3914 3224 2149 6645 4457 7088 3225 3824 6885 5760 7318 6896 1685 1277 2149 6645 7107 3231 5439 993 6527 7828 905 7103 4832 5414 7088 1342 5439 2149 6645 7096 4219 1258 6491 7088 1728 6983 4983 1526 6124 912 4457 7095 4297 7886 7220 7100 4092 6263 6951 4297 7089 6808 6412 6664 1931 3533 2715 3758 7618 6122 6855 7199 7150 950 5176 3131 3954 6150 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 2323 4191 7096 3273 2326 5859 1023 7119 7096 1528 7123 4092 7095 6116 1444 5378 1185 2318 7276 6116 4092 7819 3149 3868 1023 7119 6896 1682 3803 5474 5899 2328 4807 5859 3273 3244 5859 3224 2589 1023 7119 7108 3222 4099 5592 2369 7852 4930 7318 4125 5330 7096 5920 6014 7096 4193 7819 3155 2126 2711 5782 3244 5468 1023 7119 2621 2037 5188 2573 6545 4633 4501 6527 5524 4633 1083 4805 6078 1824 3907 7996 2824 7831 3737 7344 4297 7089 4955 6853 5825 7468 7688 6398 1931 3533 2705 6259 1209 5561 2973 6957 6488 5439 2924 1209 5760 2270 7088 3169 7280 4457 7086 1951 2705 6259 7086 3241 6855 4885 7096 4092 7944 7819 3162 3123 7096 3909 6150 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-2\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 2\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] 을 ▁위해 ▁남은 ▁인생 을 ▁저 당 ▁잡 히 는 ▁집 ▁노 예 가 ▁되는 ▁대신 ▁지금 ▁사는 ▁공간 을 ▁제대로 ▁꾸 며 서 ▁살 기로 ▁한다 ▁대학 ▁시절 ▁옥 탑 방 에서 ▁시작 해 ▁마 포 ▁반 지 하 방 ▁문 래 동 ▁오피스텔 을 ▁거쳐 ▁세 입 자 ▁생활 을 ▁마감 하고 ▁신 림 동 에 ▁방 ▁개 짜리 ▁다 세대 주택 을 ▁장 만 한 ▁것 ▁이 낡 은 ▁집 을 ▁일 에 ▁걸쳐 ▁옷 방 과 ▁침 실 ▁서 재 ▁겸 ▁홈 시 어 터 룸 로 ▁구성된 ▁공간 으로 ▁꾸 미 는 ▁과정을 ▁담 았다 ▁욕 실 ▁개 조 ▁등 ▁실 전 ▁인 테 리 어 ▁노하우 가 ▁펼쳐 진다 ▁이해 리 ▁지 음 ▁마 티 ▁만 ▁원 ▁의미 의 ▁자리 한국 ▁시 단 에서 ▁활발 히 ▁활동 ▁중인 ▁저 자의 ▁네 ▁번째 ▁비 평 집 ▁의미 란 ▁무 엇 인 가 를 ▁주제로 ▁김 혜 순 ▁이제 니 ▁장 석 주 ▁등의 ▁작품 을 ▁독 해 한 ▁편 의 ▁글을 수록 했다 ▁이 론 적 ▁시 집 ▁해 설 뿐 ▁아니라 ▁독립 ▁잡 지 ▁문 예 지 ▁현황 ▁시 와 ▁자본 ▁시 인 과 ▁검 열 ▁같은 ▁문 단 ▁현실 에 ▁대한 ▁고 찰 도 ▁담겨 있다 ▁특히 ▁최근 의 ▁화 두 인 ▁번 역 을 ▁두고 ▁시 의 ▁번 역 에서 ▁발생 하는 ▁근 사 치 로서 의 ▁의미 에 ▁대해서도 ▁살 핀 다 ▁조 재 룡 ▁지 음 ▁민 음 사 ▁만 ▁원 ▁언론 과 ▁공 인 우리 나라 에는 ▁아직 ▁공 인 을 ▁규정 하는 ▁법률 ▁조항 이 ▁없다 ▁법원 도 ▁공 인 이 ▁누구 인지 ▁정 의 를 ▁내리 거나 ▁그 ▁범 주 를 ▁정 하지 ▁않고 ▁있어 ▁공 인 에 ▁대한 ▁일 관 된 ▁법적 ▁판단 도 ▁없다 ▁언론 도 ▁어떤 ▁사람이 ▁공 인 이며 ▁어느 ▁정도 까지 ▁보도 해야 ▁하는 지 ▁정확한 가 이 드 라인 이 ▁존재 하지 ▁않아 ▁문제가 ▁생긴 다 ▁언론 과 ▁공 인 ▁사이에서 ▁명예 ▁훼손 ▁사 생활 ▁침해 ▁초 상 권 ▁침해 ▁관련 ▁판 례 ▁등을 ▁자세 히 ▁소개 한다 ▁이재 진 ▁지 음 ▁한 양 대학교 출 판 부 ▁만 ▁원 ▁생각 미술관 ▁그리 기 ▁시리즈 예 쁘 고 ▁쉽게 ▁그리 는 ▁방법 을 ▁알려 주는 ▁책 은 ▁많다 ▁생각 미술관 은 ▁언 어 ▁표현 이 ▁정 확 하지 ▁않은 ▁아이들 이 ▁자신 만 의 엉 뚱 한 ▁생각을 ▁마음 껏 ▁그림 으로 ▁그려 ▁참 신 한 ▁사고 력을 ▁키 울 ▁수 ▁있게 ▁도와 준 다 ▁이야기를 ▁듣고 ▁떠오르 는 대로 ▁그려 보는 ▁이야기 ▁그리 기 ▁제시 된 ▁상황을 ▁보고 ▁그림 을 ▁완성 하는 ▁상황 ▁그리 기 ▁그림 을 ▁접 었다 펼 치 며 ▁노 는 ▁재미 ▁그리 기 도 형 ▁등을 ▁활용해 ▁생각 나는 ▁사 물을 ▁그리 는 ▁상 상 ▁그리 기 ▁등 ▁종 이다 ▁모 글 리 북 스 ▁각 ▁원 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 7088 3567 1422 3774 7088 3990 5804 3950 7996 5760 4384 1476 6957 5330 1765 1655 4299 2582 1024 7088 4136 1353 6197 6553 2643 5571 4965 1680 2996 3436 7594 6305 6903 2986 7848 1907 7728 2207 7318 7782 6305 2120 6023 5872 3433 7088 877 2801 7138 7147 2717 7088 1908 7788 3010 6136 5872 6896 2267 835 7362 1562 6583 7286 7088 3954 6150 7828 905 3647 5665 7086 4384 7088 3803 6896 894 3454 6305 5468 4630 6738 2718 7191 952 5104 6705 6855 7609 6100 6079 1121 1024 7078 1353 6255 5760 1067 1607 6828 3492 6738 835 7253 1815 3036 7207 3758 7618 6122 6855 1491 5330 4837 7345 3752 6122 4297 7089 1907 7673 1931 3533 3628 7095 3897 7829 2959 5788 6903 5143 7996 5141 4275 3990 7167 1469 2308 2514 7724 7354 3628 6016 2095 6884 7119 5330 6116 4240 1316 7922 6643 3742 5770 3954 6557 7276 1825 3940 7088 1725 7848 7828 4832 7095 1234 6632 7869 3647 6084 7202 2959 7354 4998 6566 6484 3101 1726 3950 7318 2120 6957 7318 5068 2959 6983 3902 2959 7119 5468 895 6940 833 2120 5788 5059 6896 1682 993 7397 5859 1608 7143 4792 4525 7095 5112 5907 7119 2307 6926 7088 1774 2959 7095 2307 6926 6903 2243 7794 1221 6493 7483 6081 7095 3628 6896 1688 2643 7773 5782 4162 7191 6094 4297 7089 2169 7089 6493 1931 3533 3244 5468 1023 7119 7007 5659 6900 3129 1023 7119 7088 1182 7794 2323 4191 7096 3273 2326 5859 1023 7119 7096 1528 7123 4092 7095 6116 1444 5378 1185 2318 7276 6116 4092 7819 3149 3868 1023 7119 6896 1682 3803 5474 5899 2328 4807 5859 3273 3244 5859 3224 2589 1023 7119 7108 3222 4099 5592 2369 7852 4930 7318 4125 5330 7096 5920 6014 7096 4193 7819 3155 2126 2711 5782 3244 5468 1023 7119 2621 2037 5188 2573 6545 4633 4501 6527 5524 4633 1083 4805 6078 1824 3907 7996 2824 7831 3737 7344 4297 7089 4955 6853 5825 7468 7688 6398 1931 3533 2705 6259 1209 5561 2973 6957 6488 5439 2924 1209 5760 2270 7088 3169 7280 4457 7086 1951 2705 6259 7086 3241 6855 4885 7096 4092 7944 7819 3162 3123 7096 3909 6150 7095 6894 5987 7828 2706 1917 5609 1212 7078 1206 4427 6733 7828 2576 6065 4693 7013 2872 3855 1716 7288 5782 3715 1800 1855 5760 5812 1206 6369 3714 1209 5561 4139 5899 2692 2358 1212 7088 3460 7794 2689 1209 5561 1212 7088 4086 6888 7721 7483 6197 1476 5760 3977 1209 5561 5859 7921 1824 5147 2705 5658 2573 6242 1209 5760 2658 6527 1209 5561 1815 4197 7100 2044 5547 6122 6412 6664 773 3533 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁벤 투 ▁감독이 ▁이끄는 ▁축구 대표팀 이 ▁일 ▁오후 ▁인천공항 을 ▁통해 ▁터키 ▁이 스 탄 불 로 ▁출국 했다 ▁벤 투 ▁감독이 ▁인터뷰 하고 ▁있다 ▁벤 투 호는 ▁조 지 아 와 ▁평가 전을 ▁치른 ▁후 ▁투 르 크 메 니스 탄 과 년 ▁카 타 르 ▁월드컵 ▁아시아 지역 ▁차 예 선 ▁차 전을 ▁치른 다 ▁인천공항 ▁정 재 근 기자 ▁벤 투 ▁감독이 ▁이끄는 ▁축구 대표팀 이 ▁일 ▁오후 ▁인천공항 을 ▁통해 ▁터키 ▁이 스 탄 불 로 ▁출국 했다 ▁벤 투 ▁감독이 ▁인터뷰 하고 ▁있다 ▁벤 투 호는 ▁조 지 아 와 ▁평가 전을 ▁치른 ▁후 ▁투 르 크 메 니스 탄 과 년 ▁카 타 르 ▁월드컵 ▁아시아 지역 ▁차 예 선 ▁차 전을 ▁치른 다 ▁인천공항 ▁정 재 근 기자 ▁미국 ▁대표 ▁골프 브랜드 ▁파워 빌 트 ▁풀 세트 만원 대 ▁할인 ▁이 혜 정 ▁남편 ▁외 도로 ▁상처 ▁바람 ▁피 운 ▁직접 ▁봤 더니 ▁배우 ▁곽 진영 ▁성형 수술 ▁실패 ▁집 도 한 ▁의사 ▁자살 ▁강남 ▁예비 신 부 ▁이상 화 ▁매달 ▁받는 ▁연금 은 ▁얼마 ▁조 혜 련 ▁강호동 칠 순 에 ▁낸 천만원 ▁수 표 ▁돌려 달라 고 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 2336 7641 790 3652 4562 5823 7096 3803 3434 3791 7088 4756 4730 3647 6664 7590 6424 6079 4570 7869 2336 7641 790 3795 7788 3862 2336 7641 7926 4162 7318 6797 6983 4842 7213 4622 5176 4762 6113 7565 6190 5773 7590 5468 5712 4635 7581 6113 3548 3116 7337 4402 6957 6559 4402 7213 4622 5782 3791 4092 7191 5546 5580 2336 7641 790 3652 4562 5823 7096 3803 3434 3791 7088 4756 4730 3647 6664 7590 6424 6079 4570 7869 2336 7641 790 3795 7788 3862 2336 7641 7926 4162 7318 6797 6983 4842 7213 4622 5176 4762 6113 7565 6190 5773 7590 5468 5712 4635 7581 6113 3548 3116 7337 4402 6957 6559 4402 7213 4622 5782 3791 4092 7191 5546 5580 2150 1674 1019 6434 4803 6451 7659 4888 6588 6153 5808 4981 3647 7922 7227 1425 3468 5860 2679 2195 4909 7010 4358 2421 5838 2292 1072 7346 2800 6637 3055 4384 5859 7828 3629 3906 808 3402 6733 6398 3704 7941 1989 2224 3340 7086 3252 4162 7922 6067 823 7490 6643 6896 1454 7424 2872 7741 1733 5794 5439 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-4\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁키 움 히 어 로 즈 와 ▁롯데 ▁자 이 언 츠 의 ▁리그 ▁경기가 ▁일 ▁고 척 스카 이 돔 에서 ▁열렸다 회초 ▁사 ▁루 ▁롯데 ▁전 병 우 의 ▁루 땅 볼 때 ▁홈 으로 ▁파 고 들 던 ▁루 주 자 ▁이대호 가 ▁태 그 아웃 되고 ▁있다 ▁고 척 돔 ▁허 상 욱 기자 ▁키 움 히 어 로 즈 와 ▁롯데 ▁자 이 언 츠 의 ▁리그 ▁경기가 ▁일 ▁고 척 스카 이 돔 에서 ▁열렸다 회초 ▁사 ▁루 ▁롯데 ▁전 병 우 의 ▁루 땅 볼 때 ▁홈 으로 ▁파 고 들 던 ▁루 주 자 ▁이대호 가 ▁태 그 아웃 되고 ▁있다 ▁고 척 돔 ▁허 상 욱 기자 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 4693 7014 7996 6855 6079 7310 6983 1893 3886 7096 6865 7478 7095 1901 957 3803 993 7421 6677 7096 5869 6903 3361 7961 2573 1895 1893 4012 6361 7005 7095 1895 5964 6386 5965 5104 7078 4799 5439 5931 5842 1895 7276 7147 3660 5330 4720 5538 6803 5887 3862 993 7421 5869 5037 6527 7009 5580 4693 7014 7996 6855 6079 7310 6983 1893 3886 7096 6865 7478 7095 1901 957 3803 993 7421 6677 7096 5869 6903 3361 7961 2573 1895 1893 4012 6361 7005 7095 1895 5964 6386 5965 5104 7078 4799 5439 5931 5842 1895 7276 7147 3660 5330 4720 5538 6803 5887 3862 993 7421 5869 5037 6527 7009 5580 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-5\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] 으로부터 ▁보고 받은 ▁국방 위원장 기자 들에게 ▁밝혀 안 규 백 ▁국회 ▁국방 위원장 연합 뉴스 안 규 백 ▁국회 ▁국방 위원장 이 ▁일 ▁전날 ▁중 러 ▁군 용 기 의 ▁한국 방 공 식 별 구역 ▁카 디 즈 와 ▁영 공 ▁침 범 에 ▁대해 ▁이번 ▁사건 은 ▁의도 된 ▁중 러 의 ▁합동 훈련 으로 ▁보고 ▁있다 며 ▁이는 ▁어제 ▁국방부 가 ▁초 치 한 ▁주 한 ▁중 러 ▁무 관 들도 ▁인정 했던 ▁사실 이라고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁국방부 ▁관계자들 로부터 ▁현안 ▁보고 를 ▁받은 ▁후 기자 들과 ▁만나 ▁이같이 ▁말했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기가 ▁울 릉 도 ▁북 동 쪽 에서 ▁합류 해 ▁카 디 즈 에 ▁침 범 하고 ▁조기 경 보기 까지 ▁작동 했기 ▁때문에 상당히 ▁계획 적인 ▁행동 으로 ▁보인다 ▁고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁합 참 으로부터 ▁중국 ▁러시아 ▁군 용 기 의 ▁카 디 즈 ▁침 범 과 ▁독 도 ▁영 유 권을 ▁주장 하는 ▁일본의 ▁자 위 대 ▁군 용 기 ▁긴급 발 진 ▁사건 ▁등에 ▁관 해 ▁대 면 ▁보고 를 ▁받았다 ▁하지만 ▁이날 ▁청와대 는 ▁전날 ▁러시아 ▁차 석 ▁무 관 이 ▁우리 ▁군 에 ▁이번 ▁사태 에 ▁대해 ▁깊은 ▁유감 을 ▁표명 한다 면서 ▁기기 ▁오 작 동 으로 ▁계획 되지 ▁않은 ▁지역 에 ▁진입 한 ▁것으로 ▁생각한다 ▁고 ▁밝혔다 고 ▁공개했다 ▁안 ▁위원장 이 ▁이날 ▁군 으로부터 ▁보고 받은 ▁것과 ▁다른 ▁얘기 를 ▁비슷한 ▁시각 ▁청와대 가 ▁군 을 ▁인 용 해 ▁밝힌 ▁것이다 ▁이와 ▁관련 ▁안 ▁위원장은 ▁러시아 의 ▁기기 오 작 동 ▁내용 ▁그 것 은 ▁보고 받 지 ▁못했다 면서 ▁실수 가 ▁아니라 고 ▁본다 ▁고 ▁했다 ▁그는 ▁중 러 ▁군 용 기가 ▁합류 해서 ▁내려 왔 기 ▁때문에 ▁의도 가 ▁아니었다 는 ▁것은 ▁허 언 이라며 ▁러시아 의 ▁말 은 ▁성 립 하지 ▁않는다 ▁고 도 ▁했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기 의 ▁카 디 즈 ▁영 공 ▁침 범 ▁의도 에 ▁대해 ▁사 견 을 ▁전 제 로 ▁중 러 의 ▁군사 훈련 ▁협력 ▁시도 ▁아닌 가 ▁본다 며 ▁중국 으로서 는 ▁미 ▁중 ▁간 ▁무역 분 쟁 과 ▁미국의 ▁대 ▁대만 ▁무기 수 출 ▁등에 ▁따라 ▁액션 ▁행동 을 ▁취하고 ▁싶었 을 ▁것 이라고 ▁했다 ▁안 ▁위원장은 ▁야당 에서 ▁중 러 가 ▁한 ▁미 ▁일 ▁공 조 의 ▁빈 틈 을 ▁노 린 ▁것 이라고 ▁주장 하는 ▁것과 ▁관련해 ▁전혀 ▁사실이 ▁아니다 ▁라 면서 ▁몇 ▁주 ▁전 ▁주 한 미 군 ▁사 령 관 을 ▁만 났 을 ▁때 ▁한 ▁미 연합 훈련 ▁강 도 가 ▁얼마나 ▁세 지고 ▁빈 도 가 ▁많아 졌 는 지 ▁얘기 를 ▁들었다 ▁고 ▁했다 ▁일본 이 ▁독 도 를 ▁자 국 ▁영 토 라고 ▁주장 하며 ▁한국 ▁공 군의 ▁경고 ▁사 격 에 ▁항 의 한 ▁것에 ▁대해서는 ▁우리가 ▁실 효 적으로 ▁지배 하고 ▁우리 ▁경찰 이 ▁주 둔 하면서 ▁지키 는 ▁우리 ▁영 토 를 ▁일본 이 ▁말 할 ▁자격 과 ▁여건 이 ▁안 된다 면서 ▁일본의 ▁천 민 자본 주의 적 ▁발 상 에 ▁기 인 한 ▁착 각 이라고 ▁했다 ▁그는 ▁또 ▁의도 적 ▁계획 적 ▁침 범 이 기 ▁때문에 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 7079 2358 6293 1149 7053 5580 5936 2258 6812 5532 6314 1162 1149 7053 6938 5754 6812 5532 6314 1162 1149 7053 7096 3803 4016 4257 6037 1165 7003 5561 7095 4958 6305 5452 6730 6356 5499 4635 5947 7310 6983 3376 5452 4630 6333 6896 1685 3697 2574 7086 3622 5899 4257 6037 7095 4987 7971 7078 2358 3862 6197 3658 3238 1150 5330 4501 7483 7828 4213 7828 4257 6037 2095 5474 5933 3785 7872 2604 7102 5019 3135 3559 3656 3431 1150 1079 6080 5060 2358 6116 2232 5176 5580 5932 1933 3649 1966 3135 3559 4257 6037 1165 7003 5562 3524 6120 5859 2462 5872 7376 6903 4988 7848 4635 5947 7310 6896 4630 6333 7788 4166 5424 6368 5592 3934 7866 1849 6530 990 7206 5023 7078 2392 993 5019 3135 3559 3656 3431 4984 7398 7079 4259 1881 1165 7003 5561 7095 4635 5947 7310 4630 6333 5468 1725 5859 3376 7063 5525 4236 7794 3810 3886 7044 5808 1165 7003 5561 1312 6295 7344 2574 1820 1073 7848 1633 6198 2358 6116 2230 4946 3656 4489 5760 4016 1881 4402 6557 2095 5474 7096 3501 1165 6896 3697 2630 6896 1685 1338 3576 7088 4881 7831 6199 1262 3417 7170 5872 7078 990 5898 3162 4329 6896 4366 7828 909 2708 993 2261 5439 1029 3135 3558 7096 3656 1165 7079 2358 6293 906 1567 3219 6116 2534 2961 4489 5330 1165 7088 3758 7003 7848 2264 913 3725 1083 3135 3559 1881 7095 1262 6964 7170 5872 1449 1185 5398 7086 2358 6288 7318 2093 6199 3042 5330 3101 5439 2413 993 5019 1191 4257 6037 1165 7003 5562 4988 7850 1442 6989 5561 1849 3622 5330 3103 5760 910 5037 6865 7105 1881 7095 1958 7086 2781 6137 7819 3152 993 5859 5019 3135 3559 4257 6037 1165 7003 5561 7095 4635 5947 7310 3376 5452 4630 6333 3622 6896 1685 2573 5414 7088 4012 7234 6079 4257 6037 7095 1167 7971 5073 2971 3105 5330 2413 6197 4259 7080 5760 2149 4257 777 2114 6416 7198 5468 2151 1633 1644 2097 6629 7468 1820 1835 3202 5023 7088 4610 3074 7088 905 7102 5019 3135 3559 3209 6903 4257 6037 5330 4955 2149 3803 1023 7253 7095 2547 7671 7088 1476 6133 905 7102 4236 7794 906 1087 4062 2607 3100 1875 6199 2043 4213 4012 4213 7828 6255 5512 2573 6077 5474 7088 1931 5671 7088 1844 4955 2149 6938 7971 807 5859 5330 3253 2801 7321 2547 5859 5330 1952 7248 5760 7318 3219 6116 1811 993 5019 3809 7096 1725 5859 6116 3886 5503 3376 7628 6004 4236 7810 4958 1023 5514 955 2573 5412 6896 4992 7095 7828 908 1687 3502 3036 7965 7203 4318 7788 3501 975 7096 4213 5909 7812 4344 5760 3501 3376 7628 6116 3809 7096 1958 7836 3887 5468 3300 7096 3135 5900 6199 3810 4471 6263 7161 7284 7202 2235 6527 6896 1258 7119 7828 4420 5336 7102 5019 1191 1861 3622 7202 990 7202 4630 6333 7096 5561 1849 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-5\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁계획 적인 ▁행동 으로 ▁보인다 ▁고 ▁했다 ▁안 ▁위원장은 ▁이날 ▁오전 ▁합 참 으로부터 ▁중국 ▁러시아 ▁군 용 기 의 ▁카 디 즈 ▁침 범 과 ▁독 도 ▁영 유 권을 ▁주장 하는 ▁일본의 ▁자 위 대 ▁군 용 기 ▁긴급 발 진 ▁사건 ▁등에 ▁관 해 ▁대 면 ▁보고 를 ▁받았다 ▁하지만 ▁이날 ▁청와대 는 ▁전날 ▁러시아 ▁차 석 ▁무 관 이 ▁우리 ▁군 에 ▁이번 ▁사태 에 ▁대해 ▁깊은 ▁유감 을 ▁표명 한다 면서 ▁기기 ▁오 작 동 으로 ▁계획 되지 ▁않은 ▁지역 에 ▁진입 한 ▁것으로 ▁생각한다 ▁고 ▁밝혔다 고 ▁공개했다 ▁안 ▁위원장 이 ▁이날 ▁군 으로부터 ▁보고 받은 ▁것과 ▁다른 ▁얘기 를 ▁비슷한 ▁시각 ▁청와대 가 ▁군 을 ▁인 용 해 ▁밝힌 ▁것이다 ▁이와 ▁관련 ▁안 ▁위원장은 ▁러시아 의 ▁기기 오 작 동 ▁내용 ▁그 것 은 ▁보고 받 지 ▁못했다 면서 ▁실수 가 ▁아니라 고 ▁본다 ▁고 ▁했다 ▁그는 ▁중 러 ▁군 용 기가 ▁합류 해서 ▁내려 왔 기 ▁때문에 ▁의도 가 ▁아니었다 는 ▁것은 ▁허 언 이라며 ▁러시아 의 ▁말 은 ▁성 립 하지 ▁않는다 ▁고 도 ▁했다 ▁안 ▁위원장은 ▁중 러 ▁군 용 기 의 ▁카 디 즈 ▁영 공 ▁침 범 ▁의도 에 ▁대해 ▁사 견 을 ▁전 제 로 ▁중 러 의 ▁군사 훈련 ▁협력 ▁시도 ▁아닌 가 ▁본다 며 ▁중국 으로서 는 ▁미 ▁중 ▁간 ▁무역 분 쟁 과 ▁미국의 ▁대 ▁대만 ▁무기 수 출 ▁등에 ▁따라 ▁액션 ▁행동 을 ▁취하고 ▁싶었 을 ▁것 이라고 ▁했다 ▁안 ▁위원장은 ▁야당 에서 ▁중 러 가 ▁한 ▁미 ▁일 ▁공 조 의 ▁빈 틈 을 ▁노 린 ▁것 이라고 ▁주장 하는 ▁것과 ▁관련해 ▁전혀 ▁사실이 ▁아니다 ▁라 면서 ▁몇 ▁주 ▁전 ▁주 한 미 군 ▁사 령 관 을 ▁만 났 을 ▁때 ▁한 ▁미 연합 훈련 ▁강 도 가 ▁얼마나 ▁세 지고 ▁빈 도 가 ▁많아 졌 는 지 ▁얘기 를 ▁들었다 ▁고 ▁했다 ▁일본 이 ▁독 도 를 ▁자 국 ▁영 토 라고 ▁주장 하며 ▁한국 ▁공 군의 ▁경고 ▁사 격 에 ▁항 의 한 ▁것에 ▁대해서는 ▁우리가 ▁실 효 적으로 ▁지배 하고 ▁우리 ▁경찰 이 ▁주 둔 하면서 ▁지키 는 ▁우리 ▁영 토 를 ▁일본 이 ▁말 할 ▁자격 과 ▁여건 이 ▁안 된다 면서 ▁일본의 ▁천 민 자본 주의 적 ▁발 상 에 ▁기 인 한 ▁착 각 이라고 ▁했다 ▁그는 ▁또 ▁의도 적 ▁계획 적 ▁침 범 이 기 ▁때문에 ▁메뉴 얼 에 ▁따라 ▁대응 하 되 ▁보다 ▁강 도 높 은 ▁조치 가 ▁있어야 ▁한다고 ▁생각한다 면서 ▁국방 위원장 으로서 ▁국방부 에 ▁앞으로 ▁이런 ▁일이 ▁재발 했을 때 ▁우리 ▁군 의 ▁힘을 ▁보여줄 ▁수 ▁있는 ▁강력한 ▁대응 을 ▁주문 했다 ▁고 ▁했다 ▁안 ▁위원장은 ▁군 의 ▁대응 에 ▁대해 ▁실시간 으로 ▁출 격 해 ▁적절 하게 ▁대응 하며 ▁훌륭 한 ▁임 무 를 ▁수행 했다고 ▁생각한다 면서 ▁군사 합 의 ▁이후 ▁우리 ▁군 의 ▁대비 태 세를 ▁점검 하는 ▁좋은 ▁계기가 ▁됐다 ▁고 ▁했다 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 990 7206 5023 7078 2392 993 5019 3135 3559 3656 3431 4984 7398 7079 4259 1881 1165 7003 5561 7095 4635 5947 7310 4630 6333 5468 1725 5859 3376 7063 5525 4236 7794 3810 3886 7044 5808 1165 7003 5561 1312 6295 7344 2574 1820 1073 7848 1633 6198 2358 6116 2230 4946 3656 4489 5760 4016 1881 4402 6557 2095 5474 7096 3501 1165 6896 3697 2630 6896 1685 1338 3576 7088 4881 7831 6199 1262 3417 7170 5872 7078 990 5898 3162 4329 6896 4366 7828 909 2708 993 2261 5439 1029 3135 3558 7096 3656 1165 7079 2358 6293 906 1567 3219 6116 2534 2961 4489 5330 1165 7088 3758 7003 7848 2264 913 3725 1083 3135 3559 1881 7095 1262 6964 7170 5872 1449 1185 5398 7086 2358 6288 7318 2093 6199 3042 5330 3101 5439 2413 993 5019 1191 4257 6037 1165 7003 5562 4988 7850 1442 6989 5561 1849 3622 5330 3103 5760 910 5037 6865 7105 1881 7095 1958 7086 2781 6137 7819 3152 993 5859 5019 3135 3559 4257 6037 1165 7003 5561 7095 4635 5947 7310 3376 5452 4630 6333 3622 6896 1685 2573 5414 7088 4012 7234 6079 4257 6037 7095 1167 7971 5073 2971 3105 5330 2413 6197 4259 7080 5760 2149 4257 777 2114 6416 7198 5468 2151 1633 1644 2097 6629 7468 1820 1835 3202 5023 7088 4610 3074 7088 905 7102 5019 3135 3559 3209 6903 4257 6037 5330 4955 2149 3803 1023 7253 7095 2547 7671 7088 1476 6133 905 7102 4236 7794 906 1087 4062 2607 3100 1875 6199 2043 4213 4012 4213 7828 6255 5512 2573 6077 5474 7088 1931 5671 7088 1844 4955 2149 6938 7971 807 5859 5330 3253 2801 7321 2547 5859 5330 1952 7248 5760 7318 3219 6116 1811 993 5019 3809 7096 1725 5859 6116 3886 5503 3376 7628 6004 4236 7810 4958 1023 5514 955 2573 5412 6896 4992 7095 7828 908 1687 3502 3036 7965 7203 4318 7788 3501 975 7096 4213 5909 7812 4344 5760 3501 3376 7628 6116 3809 7096 1958 7836 3887 5468 3300 7096 3135 5900 6199 3810 4471 6263 7161 7284 7202 2235 6527 6896 1258 7119 7828 4420 5336 7102 5019 1191 1861 3622 7202 990 7202 4630 6333 7096 5561 1849 2017 6870 6896 1835 1659 7782 5886 2368 807 5859 5736 7086 4188 5330 3870 4966 2708 6199 1149 7053 7080 1150 6896 3192 3672 3818 3979 7879 5965 3501 1165 7095 5214 2379 2872 3860 811 1659 7088 4227 7869 993 5019 3135 3559 1165 7095 1659 6896 1685 3044 7078 4568 5412 7848 4009 7784 1659 7810 5185 7828 3826 6228 6116 2909 7870 2708 6199 1167 7842 7095 3756 3501 1165 7095 1649 7598 6585 4075 7794 4209 981 1762 993 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-6\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] 도 널 드 ▁트 럼 프 ▁미국 ▁대통령의 ▁국가 비 상 사 태 ▁선 포 에 ▁저 항 하는 ▁시위 가 ▁일 ▁미국 ▁전역 에서 ▁열릴 ▁예정 이라고 투데이 가 ▁일 현지시간 ▁보도했다 ▁보도 에 ▁따르면 ▁무 브 온 ▁등 ▁시민 사회 단체 들은 ▁뉴욕 ▁노 스 다 코 타 ▁캘리포니아 텍 사 스 ▁등 ▁미국 ▁곳 곳 에서 ▁수십 건 의 ▁시위 를 ▁준비 하고 ▁있다 ▁트 럼 프 ▁대통령이 ▁국가 비 상 사 태 를 ▁선 포 해 ▁남부 ▁국 경 ▁지역 에 ▁국 경 장 벽 을 ▁건설 하는 ▁것에 ▁대응 하기 ▁위한 ▁성격 이다 ▁무 브 온 은 ▁트 럼 프 의 ▁위험 한 ▁국가 ▁권력 ▁사용 으로부터 ▁이민 자 ▁무 슬 림 ▁유 색 인 종 ▁커뮤니티 를 ▁지키 기 ▁위해 ▁비 폭력 적인 ▁긴급 ▁이벤트를 ▁열 게 ▁됐다 ▁고 ▁밝혔다 ▁일부 ▁시민들 은 ▁국가 비 상 사 태 ▁선 포 ▁직후 ▁주말 ▁동안 ▁소 규모 ▁시위 를 ▁열 기도 ▁했다 ▁뉴욕 ▁경찰은 ▁지난 ▁일 ▁뉴욕 ▁맨 해 튼 ▁트 럼 프 인터내셔널 ▁호텔 ▁인근 에서 ▁시위 를 ▁벌 이 던 ▁시민들 을 ▁체포 했다 ▁또 ▁캘리포니아 주 텍 사 스 ▁엘 패 소 ▁카 운 티 ▁등 ▁지방 정부 와 ▁개인 ▁단체 들은 ▁트 럼 프 ▁행정 부 를 ▁상대로 ▁줄 소송 을 ▁예고 하고 ▁있다 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 5859 5696 5920 4773 6043 7753 2150 1669 1133 6441 6527 6493 7598 2734 7728 6896 3990 7846 7794 2985 5330 3803 2150 4046 6903 3366 3413 7102 7642 5330 3803 7908 2371 2369 6896 1838 2095 6432 6971 1815 2974 6514 5791 5937 1543 1476 6664 5782 7533 7581 4647 7620 6493 6664 1815 2150 1021 5451 6903 2889 5384 7095 2985 6116 4249 7788 3862 4773 6043 7753 1670 1133 6441 6527 6493 7598 6116 2734 7728 7848 1415 1132 5424 4329 6896 1132 5424 7178 6354 7088 885 7794 908 1659 7789 3566 2782 7100 2095 6432 6971 7086 4773 6043 7753 7095 3571 7828 1133 1171 2613 7079 3695 7147 2095 6697 6136 3574 6538 7119 7268 4653 6116 4344 5561 3567 2514 7735 7206 1312 3700 3358 5400 1762 993 2261 3811 2976 7086 1133 6441 6527 6493 7598 2734 7728 4359 4223 1754 2822 5533 2985 6116 3358 5570 5019 1543 978 4304 3803 1543 2004 7848 7668 4773 6043 7753 7124 5095 3762 6903 2985 6116 2309 7096 5842 2976 7088 4498 7869 1861 4647 7276 7620 6493 6664 3295 7697 6607 4635 7010 7673 1815 4316 7230 6983 847 1594 5937 4773 6043 7753 5030 6398 6116 2665 4252 6612 7088 3397 7788 3862 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-7\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁뉴욕 시 의 원 ▁법안 ▁제출 하기로 북한 에 억 류 됐다 ▁풀 려 난 ▁지 ▁일주일 ▁만에 ▁숨진 ▁미국 ▁대학생 오토 웜 비 어 의 ▁가족 들에게 ▁북한 ▁정부가 억달러 ▁약 억원 를 ▁배 상 하라 는 ▁미국 ▁법원 ▁판결 문 이 ▁북한 에 ▁송 달 됐다 고 ▁미국의 소리 ▁방송 이 ▁일 ▁현지 ▁시각 ▁보도했다 에 ▁따르면 ▁워싱턴 ▁연방 법원 은 웜 비 어 ▁가족 에 ▁대한 ▁배 상 판 결 을 ▁담은 ▁판결 문을 ▁지난 ▁일 ▁국제 우 편 서비스 인 을 ▁통해 ▁평 양 의 ▁북한 ▁외 무 성 으로 ▁보냈다 ▁수 신 인 은 ▁리 용 호 ▁북한 ▁외 무 상 이며 ▁배 달 ▁완료 ▁시점 은 ▁이달 ▁일 이다 웜 비 어 ▁가족 은 ▁지난해 월 에도 을 ▁통해 ▁평 양 ▁소재 ▁외 무 성 으로 ▁소장 을 ▁보 냈 고 ▁당시 ▁김 이란 ▁인물 이 ▁우 편 물을 ▁받았다 고 는 ▁전했다 ▁미 ▁폭 스 뉴스 는 ▁이날 ▁미 ▁뉴욕 시 의 ▁조 ▁보 렐 리 ▁공화당 ▁시 의 원이 ▁주 유 엔 ▁북한 대표 부가 ▁있는 ▁뉴욕 ▁맨 해 튼 ▁이 스트 사이드 ▁거리 의 ▁이름을 ▁세 컨 드 ▁애 비 뉴 에서 오토 웜 비 어 길 로 ▁바꾸 는 ▁법안 을 ▁제출 할 ▁예정 이라고 ▁보도했다 ▁국제 ▁인권 단체 인 ▁휴 먼 라이 츠 워 치는 ▁이날 ▁발표한 ▁세계 인 권 보고서 ▁북한 편 에서 ▁북한 은 ▁공포 ▁정치 와 ▁주민 ▁통제 를 ▁유지 하기 ▁위해 ▁체포 와 ▁처벌 ▁처 형 을 ▁일상 적으로 ▁자 행 하는 ▁세계 에서 ▁가장 억 압 적인 ▁국가 라고 ▁했다 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 1543 6705 7095 7020 2325 4156 7791 6415 6896 6858 6107 5880 4888 6060 5663 4297 3822 1946 2921 2150 1681 6968 0 6441 6855 7095 765 5936 2465 4107 6859 3211 6861 6116 2287 6527 7804 5760 2150 2326 4806 6234 7096 2465 6896 2869 5793 5880 5439 2151 6609 2272 7096 3803 5066 2961 2371 6896 1838 3532 3346 6336 7086 0 6441 6855 765 6896 1682 2287 6527 7688 5415 7088 1614 4806 6235 4304 3803 1155 7005 7720 6555 7119 7088 4756 4841 6853 7095 2465 3468 6228 6573 7078 2365 2872 6733 7119 7086 1900 7003 7925 2465 3468 6228 6527 7108 2287 5793 3457 2997 7086 3659 3803 7100 0 6441 6855 765 7086 4306 7028 6901 7088 4756 4841 6853 2846 3468 6228 6573 7078 2845 7088 2355 5686 5439 1626 1316 7107 3768 7096 3498 7720 6242 2230 5439 5760 4061 2149 4871 6664 5754 5760 3656 2149 1543 6705 7095 4162 2355 6057 6122 1056 2959 7095 7027 4213 7063 6909 2465 5822 6399 3860 1543 2004 7848 7668 3647 6691 6509 871 7095 3688 2801 7514 5920 3194 6441 5753 6903 6968 0 6441 6855 5585 6079 2187 5760 2325 7088 4156 7836 3413 7102 2371 1155 3761 5791 7119 5191 6184 6011 7478 7018 7485 3656 2252 2802 7119 5524 6367 2465 7720 6903 2465 7086 1054 4122 6983 4228 4752 6116 3592 7789 3567 4498 6983 4466 4464 7921 7088 3812 7203 3886 7881 7794 2802 6903 760 6858 6825 7206 1133 6004 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 0 (id = [0.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁같은 ▁화장실 ▁같은 ▁수 법 ▁두 ▁달 ▁전 ▁범죄 와 ▁같아 ▁안 심 ▁화장실 ▁인증 ▁오히려 ▁몰 카 찍 기 ▁좋은 ▁날 힌 트 돼 ▁현실 적인 ▁대안 ▁시 급 ▁화장실 ▁앞 ▁설치 해야 ▁서울시 가 ▁몰 카 ▁범죄 를 ▁예방 한다는 ▁취지 로 ▁공공 화 장 실 을 ▁대상으로 ▁도입 한 ▁안 심 ▁화장실 에서 ▁불법 ▁촬영 ▁범죄 가 ▁발생했다 ▁안 심 ▁화장실 에서 ▁몰 래 카 메 라 를 ▁찍 고 도 망 가 는 ▁범죄 가 ▁이어 지면서 ▁실 효 성이 ▁없다는 ▁지적 이 ▁나온다 ▁일 ▁서울 ▁서 대 문 경찰서 에 ▁따르면 ▁씨는 ▁지난 ▁일 ▁오후 ▁시 분쯤 ▁지하철 호선 ▁신 촌 역 ▁인근 ▁한 ▁주 상 복합 ▁상 가 층 ▁안 심 ▁화장실 에 ▁들어갔다 ▁씨는 뚜 껑 이 닫 혀 있 던 ▁변 기 의 ▁물 을 ▁내리 고 ▁변 기를 ▁휴 지 로 ▁한 ▁번 닦 았다 ▁그때 ▁머리 ▁위 에서 ▁인기 척 을 ▁느꼈 다 ▁순간 적으로 위를 쳐 다 봤 지만 ▁아무 것 도 ▁없었다 ▁씨는 ▁변 기에 앉 으면서 도 ▁경계 를 늦 추 지 ▁않고 ▁천 장을 ▁계속 ▁응시 했다고 ▁한다 ▁일 러 스트 ▁정 다운 몇 ▁초 ▁뒤 ▁셀카 ▁모 드 로 ▁설정 된 ▁휴대전화 ▁카메라 가 ▁머리 ▁위로 ▁슬 며 시 ▁올라 왔다 ▁당황 한 ▁씨가 ▁지금 ▁뭐 하는 ▁거 냐 ▁고 ▁소리 치 자 ▁피의자 는 ▁화장실 ▁밖으로 ▁달아 났다 ▁씨는 ▁경찰에 ▁신고 한 ▁뒤 ▁건물 ▁폐쇄 회 로 를 ▁확인 하고 자 ▁했지만 ▁경찰은 ▁화장실 ▁쪽 을 ▁비 추 는 가 ▁없어 ▁드 나 든 ▁사람들 ▁모습을 ▁확인할 ▁수 ▁없다 ▁고 ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 833 5118 833 2872 6335 1773 1597 4012 2320 6983 832 3135 6745 5118 3787 3435 2081 7495 7384 5561 4209 1407 7997 7659 5876 5059 7206 1656 2959 5558 5118 3184 2779 7852 2728 5330 2081 7495 2320 6116 3401 7833 4609 6079 1032 7941 7178 6738 7088 1652 1720 7828 3135 6745 5118 6903 2496 4518 2320 5330 2246 3135 6745 5118 6903 2081 6023 7495 6190 6003 6116 4400 5439 5859 6165 5330 5760 2320 5330 3716 7331 3036 7965 6577 3275 4336 7096 1392 3803 2726 2718 5808 6234 5432 6896 1838 3090 4304 3803 3434 2959 6423 4347 7927 3010 7449 6926 3762 4955 4213 6527 6381 2658 5330 7482 3135 6745 5118 6896 1808 3090 5984 5610 7096 5792 7899 7141 5842 2339 5561 7095 2135 7088 1444 5439 2339 5573 5191 7318 6079 4955 2307 5787 6828 1194 2008 3552 6903 3763 7421 7088 1545 5782 2913 7203 7049 7443 5782 6395 7330 3111 5398 5859 3280 3090 2339 5579 6819 7084 5859 954 6116 5767 7461 7318 3149 4471 7187 984 3616 7870 4965 3803 6037 6691 4092 5785 6212 4501 1783 2820 2044 5920 6079 2778 5899 5193 4639 5330 2008 3554 2948 6197 6705 3440 6990 1632 7828 3089 4299 2145 7794 862 5689 993 2829 7483 7147 4911 5760 5118 2206 1603 5672 3090 977 3012 7828 1783 884 4854 7953 6079 6116 5130 7788 7147 5021 978 5118 4398 7088 2514 7461 5760 5330 3278 1788 5655 5928 2585 2058 5132 2872 3273 993 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁변 기 의 ▁물 을 ▁내리 고 ▁변 기를 ▁휴 지 로 ▁한 ▁번 닦 았다 ▁그때 ▁머리 ▁위 에서 ▁인기 척 을 ▁느꼈 다 ▁순간 적으로 위를 쳐 다 봤 지만 ▁아무 것 도 ▁없었다 ▁씨는 ▁변 기에 앉 으면서 도 ▁경계 를 늦 추 지 ▁않고 ▁천 장을 ▁계속 ▁응시 했다고 ▁한다 ▁일 러 스트 ▁정 다운 몇 ▁초 ▁뒤 ▁셀카 ▁모 드 로 ▁설정 된 ▁휴대전화 ▁카메라 가 ▁머리 ▁위로 ▁슬 며 시 ▁올라 왔다 ▁당황 한 ▁씨가 ▁지금 ▁뭐 하는 ▁거 냐 ▁고 ▁소리 치 자 ▁피의자 는 ▁화장실 ▁밖으로 ▁달아 났다 ▁씨는 ▁경찰에 ▁신고 한 ▁뒤 ▁건물 ▁폐쇄 회 로 를 ▁확인 하고 자 ▁했지만 ▁경찰은 ▁화장실 ▁쪽 을 ▁비 추 는 가 ▁없어 ▁드 나 든 ▁사람들 ▁모습을 ▁확인할 ▁수 ▁없다 ▁고 ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 2339 5561 7095 2135 7088 1444 5439 2339 5573 5191 7318 6079 4955 2307 5787 6828 1194 2008 3552 6903 3763 7421 7088 1545 5782 2913 7203 7049 7443 5782 6395 7330 3111 5398 5859 3280 3090 2339 5579 6819 7084 5859 954 6116 5767 7461 7318 3149 4471 7187 984 3616 7870 4965 3803 6037 6691 4092 5785 6212 4501 1783 2820 2044 5920 6079 2778 5899 5193 4639 5330 2008 3554 2948 6197 6705 3440 6990 1632 7828 3089 4299 2145 7794 862 5689 993 2829 7483 7147 4911 5760 5118 2206 1603 5672 3090 977 3012 7828 1783 884 4854 7953 6079 6116 5130 7788 7147 5021 978 5118 4398 7088 2514 7461 5760 5330 3278 1788 5655 5928 2585 2058 5132 2872 3273 993 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 2\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁했다 ▁이 ▁안 심 ▁화장실 은 ▁서울시 에서 ▁매달 ▁회 ▁이상 ▁불법 ▁촬영 ▁장비 ▁설치 ▁여부를 ▁점검 한다 ▁범죄 가 ▁일어나 기 ▁사흘 ▁전 인 ▁지난 ▁일 에도 ▁보안 관 이 ▁나와 ▁점검 을 ▁했다 는 ▁표시 가 ▁있었다 ▁서울시 는 ▁지난 년 월 ▁여성 ▁안 심 ▁보안 관 들을 ▁임명 해 ▁공공 ▁민간 개 방 ▁화장실 ▁등 ▁다 중 이 용 시설 에 ▁몰 래 카 메 라 ▁설치 ▁여부 ▁등을 ▁집중 ▁점검 해 ▁왔다 ▁일각에서는 ▁안 심 ▁화장실 ▁인증 이 ▁취지 와 ▁달리 ▁불법 ▁촬영 ▁범죄 에 ▁더 ▁많이 ▁노출 될 ▁수 ▁있다는 ▁지적 이 ▁나온다 ▁오 윤 성 ▁순 천 향 대 ▁경찰 행정 학과 ▁교수는 ▁몰 카 범 이 ▁안 심 ▁화장실 ▁인증 표 에 ▁적 힌 ▁점검 ▁날 짜 를 ▁보고 ▁최근 ▁날 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 ▁동 일 한 ▁사건 이 ▁발생했다 ▁지난 월 ▁일 ▁이 ▁화장실 ▁변 기에 ▁앉아 ▁있던 ▁양 은 ▁바닥 에 ▁비 친 ▁검 은 ▁그림 자를 ▁보고 ▁위 에서 ▁자신을 ▁찍 고 ▁있는 ▁휴대전화 ▁카메라 를 ▁발견 했다 ▁당시 ▁경찰은 ▁최근 ▁발생 하는 ▁몰 카 ▁범죄 는 ▁남성 이 ▁몰 래 ▁여성 ▁화장실 에 ▁들어가 ▁휴대전화 를 ▁직접 ▁들고 ▁찍은 ▁뒤 도 주 하는 ▁기 법 이 ▁대부분 이라며 ▁화장실 ▁근처 에 가 ▁없 으면 ▁용의자 를 ▁특정 하기 ▁쉽지 ▁않은 ▁것이 ▁현실 이라고 ▁했다 ▁서울 ▁관 내 ▁한 경찰서 ▁여성 청소년 과 장은 ▁휴대전화 를 ▁들고 ▁불법 으로 ▁찍은 ▁뒤 도 망 가 는 ▁경우 엔 ▁피해자 가 위를 ▁보고 ▁적발 하지 ▁않는 ▁이상 ▁피해를 ▁입은 ▁사실 도 ▁모르 는 ▁경우가 ▁많다 며 ▁전국 적으로 ▁얼마나 ▁많은 ▁몰 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 5019 3647 3135 6745 5118 7086 2728 6903 1989 5152 3704 2496 4518 3961 2779 3311 4075 7831 2320 5330 3813 5561 2637 4012 7119 4304 3803 6901 2375 5474 7096 1394 4075 7088 5019 5760 4882 5330 3873 2728 5760 4304 5712 7028 3312 3135 6745 2375 5474 5938 3830 7848 1032 2170 5357 6305 5118 1815 1562 7295 7096 7003 6712 6896 2081 6023 7495 6190 6003 2779 3310 1824 4389 4075 7848 3464 3804 3135 6745 5118 3787 7096 4609 6983 1601 2496 4518 2320 6896 1698 1956 1489 5902 2872 3864 4336 7096 1392 3417 7068 6573 2912 7422 7886 5808 975 7885 7822 1108 2081 7495 6333 7096 3135 6745 5118 3787 7741 6896 3996 7997 4075 1407 7361 6116 2358 4525 1407 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 1741 7126 7828 2574 7096 2246 4304 7028 3803 3647 5118 2339 5579 3145 3865 3214 7086 2192 6896 2514 7489 895 7086 1212 7158 2358 3552 6903 3912 4400 5439 3860 5193 4639 6116 2236 7869 1626 978 4525 2243 7794 2081 7495 2320 5760 1419 7096 2081 6023 3312 5118 6896 1805 5193 6116 4358 1802 4401 1783 5859 7276 7794 1258 6335 7096 1647 7105 5118 1229 6896 5330 3270 7083 3496 6116 4786 7789 2925 3162 912 5059 7102 5019 2726 1073 5678 4955 5432 3312 7434 5468 7186 5193 6116 1802 2496 7078 4401 1783 5859 6165 5330 5760 968 6909 4915 5330 7049 2358 4001 7819 3151 3704 4914 3843 2604 5859 2049 5760 969 1951 6197 4014 7203 3253 1955 2081 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-8\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 3\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] 짜 가 ▁적 혀 ▁있으면 ▁보안 관 이 ▁당분간 은 ▁오 지 ▁않을 ▁것으로 ▁보고 ▁불법 ▁촬영 을 ▁하는 ▁경우 도 ▁있다 며 ▁사용자 인 ▁여성 이 ▁아닌 ▁관리 자의 ▁입장 에서 ▁만든 ▁전형 적인 탁 상 행정 에 ▁해당 한다 ▁고 ▁말했다 ▁안 심 ▁화장실 의 ▁허 술 한 ▁시설 과 ▁관리 도 ▁문제 다 ▁범죄 가 ▁발생한 ▁화장실 ▁입 구 에는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 ▁있지만 ▁정 작 ▁화장실 ▁근처 에는 가 ▁없는 ▁것으로 ▁확인됐다 ▁피해가 ▁발생한 층 에는 가 ▁총 ▁대 ▁있었 으나 ▁후 미 진 ▁화장실 ▁쪽 을 ▁비 추 는 ▁건 ▁없었다 ▁피해자 ▁씨는 ▁순 식 간 에 ▁찍 힌 ▁내 ▁얼굴 과 ▁몸 ▁영상 이 ▁인터넷 에 ▁유통 되고 ▁있을 ▁수 ▁있다는 ▁생각 에 ▁소 름 이 돋 는 다 며 ▁안 심 ▁화장실 ▁인증 을 ▁할 ▁게 ▁아니라 ▁차 라 리 ▁몰 카 ▁위험 ▁화장실 이라는 ▁걸 ▁알리 고 를 ▁제대로 ▁설치 해야 ▁범죄 ▁재발 을 ▁막 을 ▁수 ▁있을 ▁것 이라고 ▁말했다 ▁지난 ▁일 ▁불법 ▁촬영 ▁범죄 가 ▁또 ▁발생한 ▁서 대 문 구 ▁신 촌 의 ▁한 ▁주 상 복합 ▁건물 ▁내 ▁여자 ▁화장실 ▁앞에 는 ▁녹화 ▁중 이라는 팻 말 이 ▁붙 어 있 었으나 ▁정 작 ▁근처 에 는 ▁전 무 했다 ▁왼쪽 ▁화장실 ▁내부 에 ▁붙 어 있는 ▁안 심 ▁화장실 ▁점검 표 엔 ▁범죄 ▁발생 ▁일 ▁전 ▁보안 관 이 ▁불법 ▁촬영 ▁장비 ▁점검 을 ▁했다 는 ▁표시 ▁빨 간 ▁원 가 ▁있었다 오른쪽 ▁최 지 희 기자 이 ▁안 심 ▁화장실 에서는 ▁두 ▁달 ▁전 에도 ▁동 일 한 ▁사건 이 ▁발생했다 ▁지난 월 ▁일 ▁이 ▁화장실 ▁변 기에 ▁앉아 ▁있던 ▁양 은 ▁바닥 에 ▁비 친 ▁검 은 ▁그림 자를 ▁보고 ▁위 에서 ▁자신을 ▁찍 고 ▁있는 ▁휴대전화 ▁카메라 를 ▁발견 했다 ▁당시 ▁경찰은 ▁최근 ▁발생 하는 ▁몰 카 ▁범죄 는 ▁남성 이 ▁몰 래 ▁여성 ▁화장실 에 ▁들어가 ▁휴대전화 를 ▁직접 ▁들고 ▁찍은 ▁뒤 도 주 하는 ▁기 법 이 ▁대부분 이라며 ▁화장실 ▁근처 에 가 ▁없 으면 ▁용의자 를 ▁특정 하기 ▁쉽지 ▁않은 ▁것이 ▁현실 이라고 ▁했다 ▁서울 ▁관 내 ▁한 경찰서 ▁여성 청소년 과 장은 ▁휴대전화 를 ▁들고 ▁불법 으로 ▁찍은 ▁뒤 도 망 가 는 ▁경우 엔 ▁피해자 가 위를 ▁보고 ▁적발 하지 ▁않는 ▁이상 ▁피해를 ▁입은 ▁사실 도 ▁모르 는 ▁경우가 ▁많다 며 ▁전국 적으로 ▁얼마나 ▁많은 ▁몰 카 범 ▁이 ▁이런 ▁수 법 으로 ▁범죄 를 ▁행 하고 ▁있는 지 조차 가 늠 하기 ▁어려운 ▁실 정 이라고 ▁말했다 ▁전문가들은 ▁직접 ▁들고 ▁찍 는 ▁몰 카 가 활 개를 치는 ▁만큼 ▁실질적인 ▁조치 가 ▁시 급 하다고 ▁지적 한다 ▁곽 대 경 ▁동 국 대 ▁경찰 행정 학 부 ▁교수는 ▁피의자 가 ▁범죄 를 ▁저 지를 ▁때는 ▁쉽게 ▁범행 을 ▁할 ▁수 ▁있고 ▁잡 히 지 ▁않을 ▁수 ▁있는 ▁곳 을 찾 으려 ▁하는 ▁경 향 이 ▁있다 며 ▁안 심 ▁화장실 ▁인증 ▁시점 을 ▁오히려 ▁가리 거나 ▁화장실 ▁쪽 에 를 ▁설치 하고 ▁경비 원을 ▁배치 하는 ▁것이 ▁대안 이 ▁될 ▁수 ▁있다 ▁고 ▁했다 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 7361 5330 3996 7899 3879 2375 5474 7096 1622 7086 3417 7318 3163 909 2358 2496 4518 7088 4930 968 5859 3862 6197 2614 7119 3312 7096 3105 1088 7167 3844 6903 1939 4063 7206 7589 6527 7885 6896 5000 7831 993 1966 3135 6745 5118 7095 5037 6645 7828 2981 5468 1088 5859 2125 5782 2320 5330 2244 5118 3836 5495 6900 1497 4257 7103 0 6160 7096 2503 6855 3885 4092 7170 5118 1229 6900 5330 3272 909 5131 4913 2244 7482 6900 5330 4512 1633 3871 7075 5176 6255 7344 5118 4398 7088 2514 7461 5760 881 3280 4915 3090 2912 6730 5337 6896 4400 7997 1434 3251 5468 2084 3380 7096 3794 6896 3595 5887 3880 2872 3864 2705 6896 2822 6117 7096 5867 5760 5782 6197 3135 6745 5118 3787 7088 4977 921 3101 4402 6003 6122 2081 7495 3571 5118 7103 889 3174 5439 6116 4136 2779 7852 2320 3979 7088 1927 7088 2872 3880 905 7102 1966 4304 3803 2496 4518 2320 5330 1861 2244 2718 5808 6234 5495 3010 7449 7095 4955 4213 6527 6381 884 1434 3318 5118 3190 5760 1497 4257 7103 0 6160 7096 2503 6855 7141 6891 4092 7170 1229 6896 5760 4012 6228 7869 3479 5118 1446 6896 2503 6855 7142 3135 6745 5118 4075 7741 6909 2320 2243 3803 4012 2375 5474 7096 2496 4518 3961 4075 7088 5019 5760 4882 2562 5337 3533 5330 3873 6967 4519 7318 7993 5580 7096 3135 6745 5118 6904 1773 1597 4012 6901 1741 7126 7828 2574 7096 2246 4304 7028 3803 3647 5118 2339 5579 3145 3865 3214 7086 2192 6896 2514 7489 895 7086 1212 7158 2358 3552 6903 3912 4400 5439 3860 5193 4639 6116 2236 7869 1626 978 4525 2243 7794 2081 7495 2320 5760 1419 7096 2081 6023 3312 5118 6896 1805 5193 6116 4358 1802 4401 1783 5859 7276 7794 1258 6335 7096 1647 7105 5118 1229 6896 5330 3270 7083 3496 6116 4786 7789 2925 3162 912 5059 7102 5019 2726 1073 5678 4955 5432 3312 7434 5468 7186 5193 6116 1802 2496 7078 4401 1783 5859 6165 5330 5760 968 6909 4915 5330 7049 2358 4001 7819 3151 3704 4914 3843 2604 5859 2049 5760 969 1951 6197 4014 7203 3253 1955 2081 7495 6333 3647 3672 2872 6335 7078 2320 6116 5022 7788 3860 7318 7261 5330 5764 7789 3226 3036 7227 7102 1966 4036 4358 1802 4400 5760 2081 7495 5330 7948 5361 7485 1948 3052 4188 5330 2959 5558 7799 4336 7831 1072 5808 5424 1741 5503 5808 975 7885 7821 6398 1108 4911 5330 2320 6116 3990 7329 1846 2924 2321 7088 4977 2872 3857 3950 7996 7318 3163 2872 3860 1021 7088 7404 7077 4930 953 7886 7096 3862 6197 3135 6745 5118 3787 2997 7088 3435 750 5378 5118 4398 6896 6116 2779 7788 966 7025 2296 7794 912 1656 7096 1772 2872 3862 993 5019 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-9\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁그룹 ▁블랙 핑크 가 ▁해외 ▁일정 ▁참석 차 ▁일 ▁오전 ▁김 포 국제 공항 을 ▁통해 ▁일본 으로 ▁출국 하고 ▁있다 ▁블랙 핑크 ▁리 사가 ▁출국 장으로 ▁향 하고 ▁있다 ▁김 포 공항 ▁박 재 만 기자 ▁그룹 ▁블랙 핑크 가 ▁해외 ▁일정 ▁참석 차 ▁일 ▁오전 ▁김 포 국제 공항 을 ▁통해 ▁일본 으로 ▁출국 하고 ▁있다 ▁블랙 핑크 ▁리 사가 ▁출국 장으로 ▁향 하고 ▁있다 ▁김 포 공항 ▁박 재 만 기자 만원 ▁금 장 ▁골프 ▁풀 세트 ▁단독 ▁할인 만원 ▁대 ▁판매 ▁이병헌 ▁동생 ▁이 지 안 에 로 배우 ▁출신 ▁이 국 적 ▁외모 ▁때문 ▁속 옷 ▁벗 겨 ▁중요 부 위 ▁노출 ▁유명 ▁스타 ▁성추행 ▁사건 에 ▁휘 말 려 ▁마 약 ▁함께 ▁투 약 로 버 트 ▁할 리 ▁지 인 ▁임신 한 ▁여 친 과 ▁동 거 ▁중 ▁옥 주 현 ▁시 선 강 탈 ▁비 키 니 ▁몸매 쭉 뻗 은 ▁각 선 미 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 1208 2510 7781 5330 5012 3820 4431 7389 3803 3431 1316 7728 5510 5465 7088 4756 3809 7078 4570 7788 3862 2510 7781 1900 6494 4570 7185 5032 7788 3862 1316 7728 5465 2199 7191 6150 5580 1208 2510 7781 5330 5012 3820 4431 7389 3803 3431 1316 7728 5510 5465 7088 4756 3809 7078 4570 7788 3862 2510 7781 1900 6494 4570 7185 5032 7788 3862 1316 7728 5465 2199 7191 6150 5580 6153 1235 7178 1019 4888 6588 1588 4981 6153 1633 4809 3701 1750 3647 7318 6812 6896 6079 6313 4578 3647 5503 7202 3473 1848 2856 6981 2331 5411 4270 6398 7044 1489 3585 2938 2796 2574 6896 5189 6160 6060 1907 6846 4983 4762 6846 6079 6323 7659 4977 6122 4297 7119 3833 7828 3298 7489 5468 1741 5377 4257 3436 7276 7903 2959 6559 5350 7591 2514 7573 5770 2085 7380 6474 7086 773 6559 6255 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 5 (id = [5.0])\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   guid: train-10\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   tokens: [CLS] ▁이 균 재 기자 ▁이 강 인 ▁발 렌 시아 ▁이 ▁올 ▁시즌 ▁처음으로 ▁그 라운드 를 밟 아 ▁동 갑 내기 ▁구 보 ▁다 케 후 사 ▁마 요 르 카 와 ▁맞대결 을 ▁펼쳤다 ▁이 강 인 은 ▁일 ▁이하 한국시간 ▁새벽 ▁스페인 ▁발 렌 시아 의 ▁메 스타 야 ▁스타 디 움 서 ▁열린 ▁마 요 르 카 와 ▁시즌 ▁스페인 ▁프리 메 라 리 가 라운드 ▁홈경기 서 ▁후반 ▁분 ▁교체 ▁출 격 해 ▁분 간 ▁뛰 었다 ▁이 강 인 은 ▁지난달 ▁일 ▁리그 라운드 서 ▁대기 명 단 에 ▁이름을 ▁올 렸지만 ▁출 격 ▁호 출 을 ▁받지 ▁못했다 ▁이날 라운드 서 ▁시즌 ▁처음으로 ▁출전 ▁기회를 ▁잡았다 ▁이 강 인 은 으로 ▁앞선 ▁후반 ▁분 ▁케 빈 가 메이 로 를 ▁대신 해 ▁그 라운드 를 밟 았다 ▁구 보 가 ▁앞서 ▁후반 ▁분 ▁교체 ▁투입 돼 ▁미니 ▁한 일 전 이 ▁성 사 됐다 ▁구 보는 ▁올 ▁여름 ▁레알 ▁마드리드 서 ▁마 요 르 카 로 ▁임대 돼 ▁이날 ▁프리 메 라 리 가 ▁데뷔 전을 ▁치 렀다 ▁한국 과 ▁일본 ▁축구 의 ▁미래 인 ▁이 강 인 과 ▁구 보는 ▁짧은 ▁시간 ▁출전 ▁덕 에 ▁인상 적인 ▁장면 을 ▁만들 지는 ▁못했다 ▁한편 ▁발 렌 시아 는 ▁전반 ▁분 과 ▁후반 ▁분 ▁다니 ▁파 레 호 의 ▁연 이 은 ▁페널티 킥 ▁득점 으로 ▁시즌 ▁첫 ▁승 을 ▁거뒀다 [SEP]\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_ids: 2 3647 5536 7191 5580 3647 5350 7119 2235 6056 6714 3647 3439 2998 4469 1185 6010 6116 6302 6797 1741 5345 5680 1115 6364 1562 7523 7968 6493 1907 6999 6113 7495 6983 1972 7088 4838 3647 5350 7119 7086 3803 3751 7830 2701 2944 2235 6056 6714 7095 2016 6684 6844 2938 5947 7014 6553 3364 1907 6999 6113 7495 6983 2998 2944 4904 6190 6003 6122 5330 6010 5105 6553 5178 2468 1111 4568 5412 7848 2468 5337 1867 6888 3647 5350 7119 7086 4305 3803 1901 6010 6553 1638 6204 5788 6896 3688 3439 6076 4568 5412 5090 7468 7088 2234 2093 3656 6010 6553 2998 4469 4585 1308 3953 3647 5350 7119 7086 7078 3188 5178 2468 4662 6450 5330 6191 6079 6116 1655 7848 1185 6010 6116 6302 6828 1115 6364 5330 3187 5178 2468 1111 4767 5876 2152 4955 7126 7207 7096 2781 6493 5880 1115 6369 3439 3307 1886 1910 6553 1907 6999 6113 7495 6079 3829 5876 3656 4904 6190 6003 6122 5330 1707 7213 4617 6047 4958 5468 3809 4562 7095 2155 7119 3647 5350 7119 5468 1115 6369 4397 2962 4585 1701 6896 3773 7206 3960 7088 1940 7327 2093 4974 2235 6056 6714 5760 4037 2468 5468 5178 2468 1564 4799 6050 7925 7095 3332 7096 7086 4830 7575 1797 7078 2998 4481 2949 7088 865 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 04:43:27 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_examples = None\n",
    "num_train_steps = None\n",
    "if args['do_train']:\n",
    "    train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'],)\n",
    "#     train_examples = processor.get_train_examples(args['data_dir'], size=args['train_size'])\n",
    "    train_features = convert_examples_to_features(\n",
    "        train_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n",
    "    num_train_steps = int(\n",
    "        len(train_features) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82805"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10350"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultiLabelSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n",
    "model = BertForMultiLabelSequenceClassification(bert_config, num_labels = num_labels)\n",
    "model.bert.load_state_dict(torch.load(init_checkpoint))\n",
    "if args['fp16']:\n",
    "    model.half()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['local_rank'] != -1:\n",
    "    try:\n",
    "        from apex.parallel import DistributedDataParallel as DDP\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    model = DDP(model)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
    "\n",
    "class CyclicLR(object):\n",
    "    \"\"\"Sets the learning rate of each parameter group according to\n",
    "    cyclical learning rate policy (CLR). The policy cycles the learning\n",
    "    rate between two boundaries with a constant frequency, as detailed in\n",
    "    the paper `Cyclical Learning Rates for Training Neural Networks`_.\n",
    "    The distance between the two boundaries can be scaled on a per-iteration\n",
    "    or per-cycle basis.\n",
    "    Cyclical learning rate policy changes the learning rate after every batch.\n",
    "    `batch_step` should be called after a batch has been used for training.\n",
    "    To resume training, save `last_batch_iteration` and use it to instantiate `CycleLR`.\n",
    "    This class has three built-in policies, as put forth in the paper:\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each\n",
    "        cycle iteration.\n",
    "    This implementation was adapted from the github repo: `bckenstler/CLR`_\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        base_lr (float or list): Initial learning rate which is the\n",
    "            lower boundary in the cycle for eachparam groups.\n",
    "            Default: 0.001\n",
    "        max_lr (float or list): Upper boundaries in the cycle for\n",
    "            each parameter group. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore\n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function. Default: 0.006\n",
    "        step_size (int): Number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch. Default: 2000\n",
    "        mode (str): One of {triangular, triangular2, exp_range}.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "            Default: 'triangular'\n",
    "        gamma (float): Constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "            Default: 1.0\n",
    "        scale_fn (function): Custom scaling policy defined by a single\n",
    "            argument lambda function, where\n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored\n",
    "            Default: None\n",
    "        scale_mode (str): {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on\n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle).\n",
    "            Default: 'cycle'\n",
    "        last_batch_iteration (int): The index of the last batch. Default: -1\n",
    "    Example:\n",
    "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "        >>> scheduler = torch.optim.CyclicLR(optimizer)\n",
    "        >>> data_loader = torch.utils.data.DataLoader(...)\n",
    "        >>> for epoch in range(10):\n",
    "        >>>     for batch in data_loader:\n",
    "        >>>         scheduler.batch_step()\n",
    "        >>>         train_batch(...)\n",
    "    .. _Cyclical Learning Rates for Training Neural Networks: https://arxiv.org/abs/1506.01186\n",
    "    .. _bckenstler/CLR: https://github.com/bckenstler/CLR\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "#         if not isinstance(optimizer, Optimizer):\n",
    "#             raise TypeError('{} is not an Optimizer'.format(\n",
    "#                 type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "t_total = num_train_steps\n",
    "if args['local_rank'] != -1:\n",
    "    t_total = t_total // torch.distributed.get_world_size()\n",
    "if args['fp16']:\n",
    "    try:\n",
    "        from apex.contrib.optimizers import FP16_Optimizer\n",
    "        from apex.optimizers import FusedAdam\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
    "\n",
    "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
    "                          lr=args['learning_rate'],\n",
    "                          bias_correction=False)\n",
    "    if args['loss_scale'] == 0:\n",
    "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "    else:\n",
    "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
    "\n",
    "else:\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                         lr=args['learning_rate'],\n",
    "                         warmup=args['warmup_proportion'],\n",
    "                         t_total=t_total)\n",
    "\n",
    "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:45:30 - INFO - run_classifier_spm -   LOOKING AT /home/advice/notebook/jms/우리은행/data/news_te.txt\n"
     ]
    }
   ],
   "source": [
    "# Eval Fn\n",
    "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
    "\n",
    "def eval():\n",
    "\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.long)##민성 change\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
    "    \n",
    "    all_logits = None\n",
    "    all_labels = None\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "#         logits = logits.detach().cpu().numpy()\n",
    "#         label_ids = label_ids.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = accuracy(logits, label_ids)\n",
    "#         tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
    "        if all_logits is None:\n",
    "            all_logits = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "            \n",
    "        if all_labels is None:\n",
    "            all_labels = label_ids.detach().cpu().numpy()\n",
    "        else:    \n",
    "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
    "        \n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    \n",
    "\n",
    "    result = {'eval_loss': eval_loss,\n",
    "              'eval_accuracy': eval_accuracy}#,\n",
    "#               'loss': tr_loss/nb_tr_steps,\n",
    "#               'roc_auc': roc_auc  }\n",
    "\n",
    "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 04:45:34 - INFO - run_classifier_spm -   ***** Running training *****\n",
      "12/25/2019 04:45:34 - INFO - run_classifier_spm -     Num examples = 41850\n",
      "12/25/2019 04:45:34 - INFO - run_classifier_spm -     Num features = 82805\n",
      "12/25/2019 04:45:34 - INFO - run_classifier_spm -     Batch size = 32\n",
      "12/25/2019 04:45:34 - INFO - run_classifier_spm -     Num steps = 10350\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Num features = %d\", len(train_features))\n",
    "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.long)\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "if args['local_rank'] == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.unfreeze_bert_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "str_path = \"my_path\"\n",
    "path = Path(str_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('my_path/advice')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '/home'\n",
    "path/'advice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c8ae1b8c344552ab139a0cc4271399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=4.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47da4003fd1e4bdf902b540e1193eb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2588.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "12/25/2019 05:14:01 - INFO - run_classifier_spm -   Loss after epoc 0.465074884896692\n",
      "12/25/2019 05:14:01 - INFO - run_classifier_spm -   Eval after epoc 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43522feb48914e7faccf2998984980e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2588.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 05:42:12 - INFO - run_classifier_spm -   Loss after epoc 0.13149601565112562\n",
      "12/25/2019 05:42:12 - INFO - run_classifier_spm -   Eval after epoc 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2748c62d40476cabb01d365a75d7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2588.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:10:20 - INFO - run_classifier_spm -   Loss after epoc 0.05756107937879976\n",
      "12/25/2019 06:10:20 - INFO - run_classifier_spm -   Eval after epoc 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a132f026fa0245ec8387d1b62b1e07e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2588.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:52 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "12/25/2019 06:38:52 - INFO - run_classifier_spm -   Loss after epoc 0.03005372973481392\n",
      "12/25/2019 06:38:52 - INFO - run_classifier_spm -   Eval after epoc 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensorboard_dir = args['output_dir'] + \"tensorboard\"\n",
    "tensorboard_dir.mkdir(exist_ok=True)\n",
    "\n",
    "global_step = 0\n",
    "model.train()\n",
    "for i_ in tqdm(range(int(args['num_train_epochs'])), desc=\"Epoch\"):\n",
    "\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        if n_gpu > 1:\n",
    "            loss = loss.mean() # mean() to average on multi-gpu.\n",
    "        if args['gradient_accumulation_steps'] > 1:\n",
    "            loss = loss / args['gradient_accumulation_steps']\n",
    "\n",
    "        if args['fp16']:\n",
    "            optimizer.backward(loss)\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
    "#             scheduler.batch_step()\n",
    "            # modify learning rate with special warm up BERT uses\n",
    "            lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr_this_step\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
    "    logger.info('Eval after epoc {}'.format(i_+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a trained model\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "output_model_file = os.path.join(output_dir, \"finetuned_news_doc_stride_pytorch_model_d128_m512.bin\")\n",
    "torch.save(model_to_save.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a trained model that you have fine-tuned\n",
    "# model_state_dict = torch.load(output_model_file)\n",
    "# model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기도 수정 해야되요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   LOOKING AT /home/advice/notebook/jms/우리은행/data/news_te.txt\n"
     ]
    }
   ],
   "source": [
    "predict_processor = MultiLabelTextProcessor(PATH)\n",
    "test_examples = predict_processor.get_test_examples(PATH, 'news_te.csv', size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920c1c7adac343c78a8656839bcce10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17936.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁죽음 베르 나 르 베르 베르 ▁지 음 ▁전 미 연 옮 김 ▁열린 책 들 각 ▁쪽 ▁각 ▁만 ▁원 자 신 이 ▁살 았 는 지 ▁죽 었 는 지 ▁확인 하는 ▁방법 ▁중 ▁하나 는 ▁주변 의 냄 새 를 ▁맡 는 ▁것이다 ▁여 느 ▁날 처럼 ▁아침 에 ▁일어나 ▁집 을 ▁나선 ▁인기 ▁추 리 소 설 ▁작가 가 브리 엘 웰 즈 는 ▁꽃 가 게 ▁앞에서 멈 칫 한다 ▁좋아 하던 ▁꽃 에 ▁얼굴 을 들이 대 고 킁킁 대 도 ▁향 기가 ▁느껴 지지 ▁않을 ▁때 ▁그는 ▁뭔가 ▁잘못 됐 음을 ▁직 감 한다 ▁병원 에서 ▁그는 ▁의사 ▁대신 ▁영 매 를 ▁만나 고 ▁당 신 은 ▁이미 ▁죽 었다 는 ▁선고 를 ▁받는다 ▁프랑스 ▁소설 가 베르 나 르 베르 베르 의 ▁신 작 은 ▁이번에 도 ▁예약 ▁판매 만으로 ▁인터넷 ▁서 점 들 에서 ▁베 스트 셀 러 위권 ▁안에 ▁진입 하며 ▁인기를 ▁증명 했다 ▁이번 ▁소설 은 ▁누가 ▁날 ▁죽 였 지 라는 ▁질문 으로 ▁시작 된다 ▁떠 돌 이 ▁영 혼 이 ▁된 ▁주인공 웰 즈 는 ▁자신이 ▁살해 당 했다고 ▁확 신 하고 ▁그의 ▁목소리 를 들을 ▁수 ▁있는 ▁영 매 ▁필 라 피 니 의 ▁도움을 ▁받아 ▁수사 에 ▁나선다 ▁진실 을 ▁파 헤 치는 ▁과정에서 웰 즈 는 ▁같은 ▁처 지 의 ▁떠 돌 이 ▁영 혼 들을 ▁만나 고 ▁이들의 ▁산 만 하고 ▁유 쾌 한 ▁수 다 가 ▁이어진 다 ▁주인공 웰 즈 는 베르 베르 와 똑 닮 았다 ▁둘 ▁다 ▁대학 에서 ▁법 학 을 ▁전 공 했고 ▁기 자로 ▁일 하다 가 ▁작가 로 ▁데뷔 한다 ▁장르 ▁소설 을 ▁무 시 하는 ▁평 론 가 들 한테 는 ▁환영 받 지 ▁못 하지만 ▁대중 적으로 ▁인기 있다 는 ▁점도 ▁공 통 점 ▁소설 ▁속에서 ▁평 론 가 ▁장 ▁무 아 지는 ▁청년 들이 웰 즈 의 ▁책 을 ▁좋아 하는 ▁건 ▁교 양 이 ▁없고 ▁옥 석 을 ▁가리 는 ▁눈 이 ▁없 기 ▁때문 이라고 ▁독 설 을 ▁퍼 붓 는 다 ▁이어지는 웰 즈 의 ▁반 격 은 베르 베르 ▁자신의 ▁목소리 처럼 ▁들 린다 ▁작가 인 ▁우리 의 ▁목표 는 ▁더 ▁많은 ▁사람이 ▁책 을 ▁읽 게 ▁만드는 ▁것 ▁이것 뿐 이 에 요 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 4245 6342 5655 6113 6342 6342 4297 7089 4012 6255 6928 6976 5586 3364 7408 5931 5336 4398 773 1931 3533 7147 6733 7096 2643 6827 5760 7318 4244 6885 5760 7318 5130 7794 2270 4257 4928 5760 4229 7095 5684 6536 6116 1980 5760 913 3298 5757 1407 7417 3130 6896 3813 4384 7088 1382 3763 4541 6122 6607 6566 3931 5330 6436 6912 7042 7310 5760 1351 5330 5400 3191 6187 7493 7831 4207 7802 1351 6896 3251 7088 5940 5808 5439 0 5808 5859 5032 5562 1544 7340 3163 1844 1191 2146 3943 5878 7092 4349 5341 7831 2353 6903 1191 3629 1655 3376 6168 6116 1933 5439 1618 6733 7086 3692 4244 6888 5760 2736 6116 2225 4896 2835 5330 6342 5655 6113 6342 6342 7095 3010 7170 7086 3698 5859 3411 4809 6156 3794 2718 7220 5931 6903 2333 6691 6596 6037 7045 3138 4366 7810 3764 4293 7869 3697 2835 7086 1527 1407 4244 6944 7318 6005 4380 7078 2986 5900 1852 5868 7096 3376 7931 7096 1770 4235 7042 7310 5760 3914 2648 5804 7870 5124 6733 7788 1214 2073 6116 5938 2872 3860 3376 6168 4916 6003 7767 5770 7095 1718 2226 2882 6896 1383 4365 7088 4799 7895 7485 1066 7042 7310 5760 833 4464 7318 7095 1852 5868 7096 3376 7931 5938 1933 5439 3667 2640 6150 7788 3574 7548 7828 2872 5782 5330 3722 5782 4235 7042 7310 5760 6342 6342 6983 5981 5797 6828 1779 1562 1680 6903 2322 7821 7088 4012 5452 7865 1258 7156 3803 7798 5330 3931 6079 1707 7831 3959 2835 7088 2095 6705 7794 4841 6084 5330 5931 7835 5760 5138 6288 7318 2086 7820 1661 7203 3763 7143 5760 4076 1023 7636 7220 2835 2859 4841 6084 5330 3954 2095 6797 7327 4485 5940 7042 7310 7095 4457 7088 4207 7794 881 1103 6853 7096 3271 3436 6557 7088 750 5760 1535 7096 3270 5561 1848 7102 1725 6566 7088 4826 6427 5760 5782 3721 7042 7310 7095 2207 5412 7086 6342 6342 3913 2073 7417 1801 6134 3931 7119 3501 7095 2078 5760 1698 1955 2589 4457 7088 3824 5400 1938 905 3650 6484 7096 6896 6999 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-2\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁경찰 이 ▁혼자 ▁사는 ▁여성 을 ▁뒤 따 라 가 ▁집 에 ▁침 입 하려 ▁했던 ▁대 ▁남성 을 ▁긴급 체 포 했다 ▁하지만 ▁강 간 미 수가 ▁아니라 ▁주거 침 입 ▁혐의로 ▁긴급 체 포 됐다 는 ▁사실이 ▁알려 지면서 ▁온라인 에서 ▁공 분 이 ▁일 고 ▁있다 ▁지난 ▁일 ▁오후 ▁이른바 ▁신 림 동 ▁강 간 미 수 범 이라며 ▁소셜 미디어 에 ▁올라 온 ▁영상 ▁트위터 ▁캡처 서울 ▁관 악 경찰서는 ▁일 ▁오전 ▁시 분쯤 ▁강 간 미 수 ▁동영상 ▁속 ▁남성 씨를 ▁신 대 방 동 ▁자택 에서 ▁주거 침 입 ▁혐의로 ▁긴급 체 포 했다고 ▁이날 ▁밝혔다 ▁긴급 체 포 의 ▁발 단 이 ▁된 ▁건 ▁전날 ▁오후 ▁시 분쯤 ▁소셜 미디어 에 ▁신 림 동 ▁강 간 범 ▁영상 ▁공개 라는 ▁제목으로 ▁분 ▁초 ▁분 량 의 ▁폐쇄 형 회 로 ▁영상 이 ▁올라 오 면서 다 ▁영상 에는 ▁여성 이 ▁현 관 문을 ▁열고 ▁집 ▁안 으로 ▁들어가 자 ▁뒤 에 숨어있 던 ▁남성 이 ▁집 ▁안 으로 ▁따라 ▁들어가 려 다 가 ▁실패 하는 ▁장면 이 ▁담 겼다 ▁남성 은 ▁여성 의 ▁집 ▁문 ▁앞 을 ▁분 간 ▁돌아 다 니 기도 ▁했다 ▁네티즌들 이 ▁청와대 ▁국민 청 원 ▁등에 ▁이 ▁남성 의 ▁체포 를 ▁요구 하면서 ▁경찰 이 ▁씨 ▁추격 을 ▁나섰 고 ▁주거 지 ▁신 대 방 동 ▁인근 에서 ▁이날 씨를 ▁긴급 체 포 하게 ▁됐다 ▁하지만 ▁혐의 가 ▁강 간 미 수가 ▁아닌 ▁주거 침 입 ▁혐의로 ▁알려 지면서 ▁온라인 에서는 ▁공 분 이 ▁일 고 ▁있다 ▁네티즌들은 ▁강 간 미 수가 ▁아니라 고 ▁이 게 ▁말이 ▁되 느냐 ▁그 럼 도 대 체 ▁어떻게 ▁해야 ▁강 간 미 수 냐 ▁바 지 라도 ▁벗 겨 야 하 냐 ▁등의 ▁반응을 ▁보였다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 975 7096 5102 2582 3312 7088 1783 5959 6003 5330 4384 6896 4630 7138 7806 5020 1633 1419 7088 1312 7436 7728 7869 4946 807 5337 6255 6630 3101 4216 7491 7138 5071 1312 7436 7728 5880 5760 2607 3169 7331 3438 6903 1023 6416 7096 3803 5439 3862 4304 3803 3434 3685 3010 6136 5872 807 5337 6255 6629 6333 7105 2836 6257 6896 3440 6971 3380 4775 4651 6556 1073 6811 5433 3803 3431 2959 6423 807 5337 6255 6629 1756 2856 1419 6788 3010 5808 6305 5872 3928 6903 4216 7491 7138 5071 1312 7436 7728 7870 3656 2261 1312 7436 7728 7095 2235 5788 7096 1770 881 4016 3434 2959 6423 2836 6257 6896 3010 6136 5872 807 5337 6333 3380 1026 6005 4138 2468 4501 2468 6035 7095 4854 7921 7953 6079 3380 7096 3440 6964 6199 5782 3380 6900 3312 7096 5049 5474 6235 3359 4384 3135 7078 1805 7147 1783 6896 6647 5842 1419 7096 4384 3135 7078 1835 1805 6060 5782 5330 3055 7794 3960 7096 1607 5423 1419 7086 3312 7095 4384 2120 3184 7088 2468 5337 1734 5782 5770 5570 5019 1473 7096 4489 1144 7431 7020 1820 3647 1419 7095 4498 6116 3481 7812 975 7096 3088 4544 7088 1385 5439 4216 7318 3010 5808 6305 5872 3762 6903 3656 6788 1312 7436 7728 7784 1762 4946 5070 5330 807 5337 6255 6630 3105 4216 7491 7138 5071 3169 7331 3438 6904 1023 6416 7096 3803 5439 3862 1474 807 5337 6255 6630 3101 5439 3647 5400 1963 1763 5758 1185 6043 5859 5808 7436 3225 5010 807 5337 6255 6629 5689 2186 7318 6006 2331 5411 6844 7782 5689 1825 2218 2381 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-3\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁정부는 ▁일 ▁이용 표 ▁부산 지방경찰청 장 ▁치 안정 감 을 ▁서울 지방경찰청 장 ▁치 안정 감 으로 ▁전 보 ▁내 정 하는 ▁등 ▁경찰 ▁고위 직 ▁승진 ▁전 보 ▁인사를 ▁단행 했다 ▁이번 ▁인사 로 ▁지난해 월 ▁임명 된 ▁원 경 환 ▁서울 경찰청 장은 개월 ▁만에 ▁옷 을 ▁벗 게 ▁됐다 ▁이용 표 ▁부산 지방경찰청 장 연합 뉴스 정부 는 ▁또 ▁부산 지방경찰청 창 에 ▁김 창 룡 ▁경남 지방경찰청 장을 ▁경기 남 부 지방경찰청 장 에 ▁배 용 주 경찰청 ▁수사 국장 을 ▁경찰 대학 장은 ▁이준 섭 경찰청 ▁보안 국장 을 ▁승진 ▁내 정 했다 ▁김 창 룡 ▁경남 청 장 ▁배 용 주 ▁수사 국장 ▁이준 섭 ▁보안 국장 은 ▁이번 ▁인사를 ▁통해 ▁치 안정 감 으로 ▁승진 했다 ▁치 안정 감 인 ▁임 호선 경찰청 ▁차 장과 ▁이상 로 ▁인천 지방경찰청 장은 ▁유 임 됐다 ▁치 안정 감 은 경찰청 장 ▁치 안 총 감 에 ▁이어 ▁경찰 ▁조직 ▁내 에서 ▁두 ▁번째 로 ▁높은 ▁계 급 으로 ▁차기 경찰청 장 의 ▁잠재 적 ▁후보 군 이다 ▁이번에 ▁치 안정 감 으로 ▁승진 ▁내 정 된 ▁명 은 ▁호 남 ▁경기 남 부 청 장 ▁대구 ▁경북 ▁경찰 대학 장 ▁경남 ▁부산 청 장 ▁출신 이다 ▁현재 ▁경찰 ▁치 안정 감 의 ▁출신 은 ▁영 남 권 ▁명 ▁서울 청 장 ▁부산 청 장 ▁경찰 대학 장 ▁충청 ▁명 ▁본 청 ▁차 장 ▁인천 청 장 ▁호 남 ▁명 ▁경기 남 부 청 장 ▁등으로 ▁분류 된다 ▁이용 표 ▁신임 ▁서울 청 장은 ▁경남 ▁남 해 ▁출신 으로 ▁경남 ▁진 주 고 와 ▁경찰 대 ▁행정 학과 ▁한국 체 대 ▁사회 체육 대학원 을 ▁졸업 했다 ▁경찰 대 ▁기 ▁출신 으로 년 ▁경찰에 ▁입 문 했다 ▁이 ▁청 장은 ▁경남 ▁산 청 서 장 경찰청 ▁정보 과 ▁과장 ▁서울 ▁노 원 서 장 경찰청 ▁생활 질서 과 장 ▁경남 지방경찰청 ▁제 부장 ▁경기 지방경찰청 ▁제 부장 ▁서울 지방경찰청 ▁정보 관리 부장 경찰청 ▁정보 국장 ▁등을 ▁역 임 했다 ▁그는 ▁정보 ▁부서 에서 ▁경험 을 ▁쌓 은 ▁정보 통 으로 ▁알려졌다 ▁왼쪽 부터 ▁김 창 룡 ▁신임 ▁부산 청 장 ▁배 용 주 ▁신임 ▁경기 남 부 청 장 ▁이준 섭 ▁신임 ▁경찰 대학 장 경찰청 ▁제공 김 창 룡 ▁신임 ▁부산 청 장은 ▁경남 ▁합 천 ▁출신 으로 ▁부산 가 야 고 ▁경찰 대 ▁기 를 ▁졸업 했다 ▁충남 ▁연기 서 장 경찰청 ▁정보 국 ▁정보 ▁과장 ▁경남 청 부장 ▁워싱턴 ▁주재 관 경찰청 ▁생활 안전 국장 ▁경남 청 장 ▁등을 ▁역 임 했다 ▁배 용 주 ▁신임 ▁경기 남 부 청 장은 ▁광주 ▁출신 으로 ▁광주 ▁정 광고 와 ▁경찰 대 ▁기 를 ▁졸업 하고 ▁보 성 서 장과 ▁서울 청 ▁제 ▁기 동 대 장 ▁광주 ▁광 산 서 장 경찰청 ▁사이버 테 러 대 응 센터 장 ▁서울 청 ▁형사 과 장 ▁경찰 수사 연구원 장 경찰청 ▁과학 수사 관리 관 경찰청 ▁수사 국장 ▁등을 ▁거쳐 왔다 ▁이준 섭 ▁신임 ▁경찰 대학 장은 ▁경북 의 성 ▁출신 으로 ▁마 산 고 와 ▁영 남 대를 ▁졸업 했다 년 월 ▁간부 후보 ▁기 로 ▁경찰에 ▁입 문 해 ▁경북 경찰청 ▁경비 교통 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 4108 3803 3726 7741 2440 7333 7178 4617 6817 5341 7088 2726 7333 7178 4617 6817 5341 7078 4012 6364 1434 7227 7794 1815 975 1011 7342 2958 4012 6364 3771 1596 7869 3697 3769 6079 4306 7028 3830 5899 3533 5424 7946 2726 5434 7186 5366 1946 3454 7088 2331 5400 1762 3726 7741 2440 7333 7178 6938 5754 7230 5760 1861 2440 7333 7402 6896 1316 7402 6094 962 7333 7187 956 5666 6398 7333 7178 6896 2287 7003 7276 5434 2882 5508 7088 975 5824 7186 3745 6570 5434 2375 5508 7088 2958 1434 7227 7869 1316 7402 6094 962 7431 7178 2287 7003 7276 2882 5508 3745 6570 2375 5508 7086 3697 3771 4756 4617 6817 5341 7078 2958 7869 4617 6817 5341 7119 3826 7927 5434 4402 7179 3704 6079 3790 7333 7186 3574 7136 5880 4617 6817 5341 7086 5434 7178 4617 6812 7452 5341 6896 3716 975 4186 1434 6903 1773 2308 6079 1520 980 5558 7078 4404 5434 7178 7095 3948 7202 5180 5512 7100 3698 4617 6817 5341 7078 2958 1434 7227 5899 2034 7086 5090 5666 956 5666 6398 7431 7178 1636 965 975 5824 7178 962 2440 7431 7178 4578 7100 5064 975 4617 6817 5341 7095 4578 7086 3376 5666 5524 2034 2726 7431 7178 2440 7431 7178 975 5824 7178 4597 2034 2408 7431 4402 7178 3790 7431 7178 5090 5666 2034 956 5666 6398 7431 7178 1822 2472 5900 3726 7741 3027 2726 7431 7186 962 1409 7848 4578 7078 962 4360 7276 5439 6983 975 5808 5030 7822 4958 7436 5808 2633 7438 5826 7088 4195 7869 975 5808 1258 4578 7078 5712 977 3836 6234 7869 3647 4483 7186 962 2640 7431 6553 7178 5434 4103 5468 1064 2726 1476 7020 6553 7178 5434 2717 7351 5468 7178 962 7333 4128 6406 956 7333 4128 6406 2726 7333 4103 5478 6406 5434 4103 5508 1824 3322 7136 7869 1191 4103 2443 6903 979 7088 3079 7086 4103 7636 7078 3171 3479 6410 1316 7402 6094 3027 2440 7431 7178 2287 7003 7276 3027 956 5666 6398 7431 7178 3745 6570 3027 975 5824 7178 5434 4130 5586 7402 6094 3027 2440 7431 7186 962 4984 7422 4578 7078 2440 5330 6844 5439 975 5808 1258 6116 4195 7869 4590 3341 6553 7178 5434 4103 5503 4103 1064 962 7431 6406 3532 4238 5474 5434 2717 6816 5508 962 7431 7178 1824 3322 7136 7869 2287 7003 7276 3027 956 5666 6398 7431 7186 1098 4578 7078 1098 4092 5482 6983 975 5808 1258 6116 4195 7788 2355 6573 6553 7179 2726 7431 4128 1258 5872 5808 7178 1098 1096 6516 6553 7178 5434 2619 7618 6037 5808 7094 6593 7178 2726 7431 5082 5468 7178 975 6634 6931 7178 5434 1071 6634 5478 5474 5434 2882 5508 1824 877 6990 3745 6570 3027 975 5824 7186 965 7095 6573 4578 7078 1907 6516 5439 6983 3376 5666 5813 4195 7869 5712 7028 779 7969 1258 6079 977 3836 6234 7848 965 5434 966 5493 3\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-3\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁임 호선 경찰청 ▁차 장과 ▁이상 로 ▁인천 지방경찰청 장은 ▁유 임 됐다 ▁치 안정 감 은 경찰청 장 ▁치 안 총 감 에 ▁이어 ▁경찰 ▁조직 ▁내 에서 ▁두 ▁번째 로 ▁높은 ▁계 급 으로 ▁차기 경찰청 장 의 ▁잠재 적 ▁후보 군 이다 ▁이번에 ▁치 안정 감 으로 ▁승진 ▁내 정 된 ▁명 은 ▁호 남 ▁경기 남 부 청 장 ▁대구 ▁경북 ▁경찰 대학 장 ▁경남 ▁부산 청 장 ▁출신 이다 ▁현재 ▁경찰 ▁치 안정 감 의 ▁출신 은 ▁영 남 권 ▁명 ▁서울 청 장 ▁부산 청 장 ▁경찰 대학 장 ▁충청 ▁명 ▁본 청 ▁차 장 ▁인천 청 장 ▁호 남 ▁명 ▁경기 남 부 청 장 ▁등으로 ▁분류 된다 ▁이용 표 ▁신임 ▁서울 청 장은 ▁경남 ▁남 해 ▁출신 으로 ▁경남 ▁진 주 고 와 ▁경찰 대 ▁행정 학과 ▁한국 체 대 ▁사회 체육 대학원 을 ▁졸업 했다 ▁경찰 대 ▁기 ▁출신 으로 년 ▁경찰에 ▁입 문 했다 ▁이 ▁청 장은 ▁경남 ▁산 청 서 장 경찰청 ▁정보 과 ▁과장 ▁서울 ▁노 원 서 장 경찰청 ▁생활 질서 과 장 ▁경남 지방경찰청 ▁제 부장 ▁경기 지방경찰청 ▁제 부장 ▁서울 지방경찰청 ▁정보 관리 부장 경찰청 ▁정보 국장 ▁등을 ▁역 임 했다 ▁그는 ▁정보 ▁부서 에서 ▁경험 을 ▁쌓 은 ▁정보 통 으로 ▁알려졌다 ▁왼쪽 부터 ▁김 창 룡 ▁신임 ▁부산 청 장 ▁배 용 주 ▁신임 ▁경기 남 부 청 장 ▁이준 섭 ▁신임 ▁경찰 대학 장 경찰청 ▁제공 김 창 룡 ▁신임 ▁부산 청 장은 ▁경남 ▁합 천 ▁출신 으로 ▁부산 가 야 고 ▁경찰 대 ▁기 를 ▁졸업 했다 ▁충남 ▁연기 서 장 경찰청 ▁정보 국 ▁정보 ▁과장 ▁경남 청 부장 ▁워싱턴 ▁주재 관 경찰청 ▁생활 안전 국장 ▁경남 청 장 ▁등을 ▁역 임 했다 ▁배 용 주 ▁신임 ▁경기 남 부 청 장은 ▁광주 ▁출신 으로 ▁광주 ▁정 광고 와 ▁경찰 대 ▁기 를 ▁졸업 하고 ▁보 성 서 장과 ▁서울 청 ▁제 ▁기 동 대 장 ▁광주 ▁광 산 서 장 경찰청 ▁사이버 테 러 대 응 센터 장 ▁서울 청 ▁형사 과 장 ▁경찰 수사 연구원 장 경찰청 ▁과학 수사 관리 관 경찰청 ▁수사 국장 ▁등을 ▁거쳐 왔다 ▁이준 섭 ▁신임 ▁경찰 대학 장은 ▁경북 의 성 ▁출신 으로 ▁마 산 고 와 ▁영 남 대를 ▁졸업 했다 년 월 ▁간부 후보 ▁기 로 ▁경찰에 ▁입 문 해 ▁경북 경찰청 ▁경비 교통 과 장 칠 곡 경찰서 장 경찰청 ▁감 찰 담당 관 ▁정보 심 의 관 ▁외 사 국장 ▁등을 ▁지 냈다 ▁경 무 관 의 ▁치 안 감 ▁승진 인사 도 ▁함께 ▁이뤄졌다 ▁이 문 수 ▁서울 지방경찰청 ▁보안 부장 ▁이 명 교 ▁서울 지방경찰청 ▁수사 부장 ▁김 남 현 경찰청 자치 경찰 추진 단 장 ▁진 교 훈 ▁서울 지방경찰청 ▁정보 관리 부장 ▁진 정 무 ▁서울 지방경찰청 ▁교통 지도 부장 ▁이 영상 ▁서울 지방경찰청 ▁생 안 부장 ▁이 규 문 경찰청 ▁수사 국 ▁김 교 태 경찰청 ▁정보 심 의 관 ▁임 용 환 ▁서울 지방경찰청 ▁경 무 부장 ▁남 구 준 경찰청 국장 기획 상황 실 이 ▁각각 ▁치 안 감 으로 ▁승진 ▁내 정 됐다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3826 7927 5434 4402 7179 3704 6079 3790 7333 7186 3574 7136 5880 4617 6817 5341 7086 5434 7178 4617 6812 7452 5341 6896 3716 975 4186 1434 6903 1773 2308 6079 1520 980 5558 7078 4404 5434 7178 7095 3948 7202 5180 5512 7100 3698 4617 6817 5341 7078 2958 1434 7227 5899 2034 7086 5090 5666 956 5666 6398 7431 7178 1636 965 975 5824 7178 962 2440 7431 7178 4578 7100 5064 975 4617 6817 5341 7095 4578 7086 3376 5666 5524 2034 2726 7431 7178 2440 7431 7178 975 5824 7178 4597 2034 2408 7431 4402 7178 3790 7431 7178 5090 5666 2034 956 5666 6398 7431 7178 1822 2472 5900 3726 7741 3027 2726 7431 7186 962 1409 7848 4578 7078 962 4360 7276 5439 6983 975 5808 5030 7822 4958 7436 5808 2633 7438 5826 7088 4195 7869 975 5808 1258 4578 7078 5712 977 3836 6234 7869 3647 4483 7186 962 2640 7431 6553 7178 5434 4103 5468 1064 2726 1476 7020 6553 7178 5434 2717 7351 5468 7178 962 7333 4128 6406 956 7333 4128 6406 2726 7333 4103 5478 6406 5434 4103 5508 1824 3322 7136 7869 1191 4103 2443 6903 979 7088 3079 7086 4103 7636 7078 3171 3479 6410 1316 7402 6094 3027 2440 7431 7178 2287 7003 7276 3027 956 5666 6398 7431 7178 3745 6570 3027 975 5824 7178 5434 4130 5586 7402 6094 3027 2440 7431 7186 962 4984 7422 4578 7078 2440 5330 6844 5439 975 5808 1258 6116 4195 7869 4590 3341 6553 7178 5434 4103 5503 4103 1064 962 7431 6406 3532 4238 5474 5434 2717 6816 5508 962 7431 7178 1824 3322 7136 7869 2287 7003 7276 3027 956 5666 6398 7431 7186 1098 4578 7078 1098 4092 5482 6983 975 5808 1258 6116 4195 7788 2355 6573 6553 7179 2726 7431 4128 1258 5872 5808 7178 1098 1096 6516 6553 7178 5434 2619 7618 6037 5808 7094 6593 7178 2726 7431 5082 5468 7178 975 6634 6931 7178 5434 1071 6634 5478 5474 5434 2882 5508 1824 877 6990 3745 6570 3027 975 5824 7186 965 7095 6573 4578 7078 1907 6516 5439 6983 3376 5666 5813 4195 7869 5712 7028 779 7969 1258 6079 977 3836 6234 7848 965 5434 966 5493 5468 7178 7490 5443 5432 7178 5434 784 7397 5799 5474 4103 6745 7095 5474 3468 6493 5508 1824 4297 5687 953 6228 5474 7095 4617 6812 5341 2958 7121 5859 4983 3678 3647 6234 6629 2726 7333 2375 6406 3647 6204 5488 2726 7333 2882 6406 1316 5666 7903 5434 7169 5431 7462 5788 7178 4360 5488 7970 2726 7333 4103 5478 6406 4360 7227 6228 2726 7333 1112 7328 6406 3647 6952 2726 7333 2704 6812 6406 3647 5532 6234 5434 2882 5503 1316 5488 7598 5434 4103 6745 7095 5474 3826 7003 7946 2726 7333 953 6228 6406 1409 5495 7288 5434 5508 5583 6534 6738 7096 774 4617 6812 5341 7078 2958 1434 7227 5880 3 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-4\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁이 장 한 ▁회장 종 근 당 은 ▁지난 ▁일 ▁서울 ▁서초구 ▁더 케이 호텔에서 ▁고 촌 ▁이종 근 ▁회장 ▁탄생 ▁주 년 ▁기념 ▁신 약 개발 ▁심 포 지 엄 을 ▁열었다 ▁이날 ▁행사에 는 ▁종 근 당 ▁이 장 한 ▁회장 과 ▁한국 제약 바이오 협회 ▁원 희 목 ▁회장 ▁등 ▁국내외 의 약 계 ▁전문가들 과 ▁종 근 당 ▁임직원 여명이 ▁참석했다 ▁이 장 한 ▁회장은 ▁이 ▁자리 가 ▁글로벌 ▁혁신 ▁신 약 ▁개발 에 ▁대한 ▁경험 과 ▁정보 ▁의견을 ▁나누 는 ▁담 론 의 ▁장 이 ▁될 ▁수 ▁있기 를 ▁기대한다 ▁고 ▁말했다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3647 7178 7828 5163 7268 5546 5804 7086 4304 3803 2726 2731 1698 7525 7929 993 7449 3743 5546 5163 4709 4213 5712 1263 3010 6846 5362 3060 7728 7318 6872 7088 3371 3656 5028 5760 4197 5546 5804 3647 7178 7828 5163 5468 4958 7237 6278 7918 3533 7993 6217 5163 1815 1140 7095 6846 5436 4035 5468 4197 5546 5804 3835 6922 4434 3647 7178 7828 5164 3647 3897 5330 1233 5048 3010 6846 839 6896 1682 979 5468 4103 3619 1373 5760 1607 6084 7095 3954 7096 1772 2872 3858 6116 1272 993 1966 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-5\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁안 녕 컨 디 션 ▁어 때 ▁파 리 ▁지하철 호선 ▁공식 ▁트위터 ▁오늘 ▁저녁 ▁한국 ▁그룹 가 ▁스타 드 ▁드 ▁프랑스 ▁경기 장 에 ▁온 대 ▁파 리 ▁지하철 호선 ▁공식 ▁트위터 ▁파 리 ▁지하철 호선 ▁공식 ▁트위터 파 리 ▁지하철 이 ▁일 ▁이하 ▁현지 ▁시각 ▁프랑스 ▁파 리 ▁북 쪽 ▁스타 드 ▁드 ▁프랑스 ▁경기 장에서 ▁열린 ▁방 탄 소 년 단 ▁공연을 ▁앞두고 ▁공식 ▁트위터에 ▁한 글 로 ▁메시지를 ▁올렸다 ▁파 리 ▁지하철 호선 은 ▁일 ▁오후 ▁시 ▁공식 ▁트위터에 ▁한 글 로 호선 ▁지하철 ▁운행 ▁원 할 해 ▁모두 ▁좋은 ▁하루 ▁보내 라고 ▁적 었다 ▁원활 을 ▁원 할 로 ▁잘못 ▁표 기 했지만 ▁완벽한 ▁한국 어 였다 ▁분 ▁뒤 ▁지하철 호선 도 ▁공식 ▁트위터에 ▁역시 ▁한 글 로 ▁우리 ▁쪽 도 ▁잘 ▁운행 되고 ▁있어 ▁좋은 ▁하루 ▁보내 고 ▁주말 도 ▁잘 ▁보내 라고 ▁답했다 ▁이들의 ▁한국 어 ▁대화 는 ▁여 분 간 ▁이어졌다 호선 은 ▁근 데 ▁아 까 부터 ▁우리 ▁정말 로 ▁한국 말 ▁하고 ▁있는 ▁거 야 라며 ▁놀라 는 ▁표정 의 ▁사진을 ▁올리 기도 ▁했다 ▁아 미 들은 ▁한국 어 로 ▁해 주 니 ▁마음 이 ▁따 뜻 해 진다 ▁감동 이다 라고 ▁답 을 ▁달 았다 호선 은 ▁한 글 로 ▁아 미 들을 ▁최선을 ▁다 해서 ▁모 시 겠습니다 ▁고 마 워 요 라고 ▁화 답 했다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3135 5724 7514 5947 6602 3220 5965 4799 6122 4347 7927 1046 4775 3419 3991 4958 1208 5330 2938 5920 1788 4896 956 7178 6896 3437 5808 4799 6122 4347 7927 1046 4775 4799 6122 4347 7927 1046 4775 7682 6122 4347 7096 3803 3751 5066 2961 4896 4799 6122 2462 7376 2938 5920 1788 4896 956 7184 3364 2267 7590 6607 5712 5788 1049 3185 1046 4776 4955 5547 6079 2019 3444 4799 6122 4347 7927 7086 3803 3434 2959 1046 4776 4955 5547 6079 7927 4347 3523 3533 7836 7848 2047 4209 4937 2363 6004 3996 6888 3546 7088 3533 7836 6079 3943 4880 5561 7880 3459 4958 6855 6946 2468 1783 4347 7927 5859 1046 4776 3327 4955 5547 6079 3501 4398 5859 3942 3523 5887 3868 4209 4937 2363 5439 4223 5859 3942 2363 6004 1617 3667 4958 6855 1692 5760 3298 6416 5337 3719 7927 7086 1221 5850 3093 5591 6410 3501 4102 6079 4958 6160 4926 3860 862 6844 6008 1505 5760 4883 7095 2628 3445 5570 5019 3093 6255 5937 4958 6855 6079 4998 7276 5770 1917 7096 1833 5997 7848 7345 791 7100 6004 1615 7088 1597 6828 7927 7086 4955 5547 6079 3093 6255 5938 4530 1562 7850 2044 6705 5409 993 6141 7018 6999 6004 5112 5801 7869 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 3 (id = [3.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-6\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] 도 널 드 ▁트 럼 프 ▁미 ▁대통령이 ▁일 ▁현지 ▁시각 이란 혁명 수 비 대의 ▁미 군 ▁무 인 항공 기 ▁드 론 ▁격 추 에 ▁대한 ▁보 복 으로 ▁공격 ▁명령 을 ▁내렸다 가 ▁갑자기 ▁취소 했다고 ▁뉴욕 타임 스 가 ▁보도했다 ▁미국 과 이란 은 ▁이날 ▁격 추 된 ▁드 론 이 이란 ▁영 공 을 ▁침 입 했는지 ▁여부를 ▁두고 ▁서로 ▁다른 ▁주장 을 ▁펼치고 ▁있다 는 ▁이날 ▁복수 의 ▁백악관 과 ▁군 ▁관계자 를 ▁인 용 ▁트 럼 프 ▁대통령이 ▁백악관 ▁참 모 진 과 ▁군 ▁관계자 와 ▁논의 한 ▁후 ▁저녁 ▁시 쯤 이란 ▁공격 ▁명령 을 ▁승인 했다고 ▁전했다 ▁레이 더 와 ▁미사일 ▁포 대 ▁등 ▁몇 몇 ▁목표 물 에 ▁대한 ▁공격 이었다 ▁공격 은 ▁일 ▁새벽 ▁동 트 기 ▁직전 에 ▁실시 될 ▁예정 이었다 이란 군 과 ▁민간 인 의 ▁피해 ▁위험 을 ▁최소화 하기 ▁위 함 이다 도 널 드 ▁트 럼 프 ▁미국 ▁대통령이 년 월 ▁일 ▁미 플 로 리 다 주 ▁올 랜 도 ▁암 웨이 센터에서 ▁열린 ▁재 선 ▁도전 ▁출 정 식 에서 ▁연 설 하고 ▁있다 로 이 터 연합 뉴스 그 러 나 ▁갑자기 ▁취소 ▁명령 이 ▁떨어졌다 ▁소식통 은 ▁비행기 가 ▁공 중 에 ▁떠 ▁있고 ▁선박 도 ▁제 ▁위치 에 ▁있었지만 ▁공격 ▁개 시 ▁명령 은 ▁없었다 ▁고 에 ▁전했다 ▁폭 격 기 와 ▁군 함 도 ▁공격 ▁태 세 에 ▁돌입 했다는 ▁이야기 다 ▁실제 ▁미국 ▁연방 항공 국 은 ▁일 ▁오후 ▁미국 에 ▁등록 된 ▁항공기 가 ▁페 르 시아 만 과 ▁오 만 만 을 ▁비 행 하는 ▁것도 ▁금지 했다 는 ▁트 럼 프 ▁대통령이 ▁단순 히 ▁공격 에 ▁관한 ▁생각을 ▁바 꾼 ▁것인지 ▁아니면 ▁다른 ▁전략 이 ▁있어 ▁트 럼 프 ▁행정 부 ▁차원에서 ▁방향 을 ▁바 꾼 ▁것인지 ▁명확 하지 ▁않다 ▁공격 ▁가능성이 ▁여전히 ▁남아 ▁있는 지도 ▁불 분 명 하다 ▁고 ▁덧붙였다 ▁마 이 크 폼 페 이 오 ▁국 무 장관 과 ▁존 ▁볼 턴 ▁백악관 ▁국가안보 회 의 ▁보 좌 관 ▁지나 ▁해 스 펠 ▁중앙 정보 국 ▁국 장은 ▁군사 적 ▁대응 을 ▁주장 한 ▁것으로 ▁알려졌다 ▁백악관 과 ▁미 ▁국방부 는 ▁보도 와 ▁관련한 ▁답변 을 ▁거부 했다 년 월 ▁미국 ▁메 릴 랜드 주 ▁패 턱 센트 강 ▁해 군 항공 기지 ▁상 공 에서 ▁시험 ▁비 행 ▁중인 ▁미 군의 ▁정 찰 용 ▁무 인 기 ▁드 론 ▁글로벌 ▁호 크 이란 혁명 수 비 대 는 년 월 ▁일 ▁호 르 무 즈 ▁해 협 과 ▁가까운 이란 ▁남부 ▁호 르 모 즈 간 ▁영 공 을 ▁침 입 해 ▁간 첩 ▁활동을 하던 ▁글로벌 ▁호 크 를 ▁대 공 ▁방 어 ▁시스템 으로 ▁격 추 했다고 ▁밝혔다 연합 뉴스 앞 서 ▁이날 ▁새벽 ▁시 쯤 이란 혁명 수 비 대 는 ▁국 영 방송 을 ▁통해 ▁미 군 ▁드 론 ▁글로벌 호 크 를 ▁호 르 무 즈 ▁해 협 과 ▁접 해 있는 ▁남부 ▁호 르 모 즈 간 ▁주 ▁영 공 에서 ▁격 추 했다고 ▁발표했다 이란 ▁측은 ▁미 군 ▁드 론 이 이란 ▁영 공 을 ▁침 입 했다고 ▁주장했다 ▁미국 ▁측은 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 5859 5696 5920 4773 6043 7753 2149 1670 3803 5066 2961 7107 7901 6629 6441 5818 2149 5512 2095 7119 7847 5561 1788 6084 931 7461 6896 1682 2355 6379 7078 1030 2036 7088 1443 5330 806 4602 7870 1543 7586 6664 5330 2371 2150 5468 7107 7086 3656 931 7461 5899 1788 6084 7096 7107 3376 5452 7088 4630 7138 7868 3311 1774 2720 1567 4236 7088 4839 3862 5760 3656 2404 7095 2299 5468 1165 1077 6116 3758 7003 4773 6043 7753 1670 2299 4427 6213 7344 5468 1165 1077 6983 1502 7828 5176 3991 2959 7382 7107 1030 2036 7088 2957 7870 4061 1887 5837 6983 2162 4856 5808 1815 2043 6212 2078 6241 6896 1682 1030 7112 1030 7086 3803 2701 1741 7659 5561 4357 6896 3043 5902 3413 7112 7107 5512 5468 2170 7119 7095 4912 3571 7088 4532 7789 3552 7837 7100 5859 5696 5920 4773 6043 7753 2150 1670 5712 7028 3803 2149 7761 6079 6122 5782 7276 3439 6025 5859 3177 7040 6594 3364 3969 6559 1721 4568 7227 6730 6903 3332 6566 7788 3862 6079 7096 7609 6938 5754 5538 6037 5655 806 4602 2036 7096 1858 2842 7086 2545 5330 1023 7295 6896 1852 3857 2741 5859 4128 3563 6896 3875 1030 835 6705 2036 7086 3280 993 6896 4061 4871 5412 5561 6983 1165 7837 5859 1030 4720 6579 6896 1738 7871 3714 5782 3049 2150 3346 7847 5503 7086 3803 3434 2150 6896 1818 5899 4994 5330 4829 6113 6714 6150 5468 3417 6150 6150 7088 2514 7881 7794 907 1248 7869 5760 4773 6043 7753 1670 1591 7996 1030 6896 1094 2706 2186 5629 918 3102 1567 4025 7096 3868 4773 6043 7753 5030 6398 4411 2285 7088 2186 5629 918 2042 7819 3153 1030 741 3320 1420 3860 7328 2485 6416 6204 7798 993 1705 1907 7096 7565 7739 7712 7096 6964 1132 6228 7180 5468 4192 2417 7612 2299 1136 7953 7095 2355 7273 5474 4303 4998 6664 7717 4269 7229 5503 1132 7186 1167 7202 1659 7088 4236 7828 909 3171 2299 5468 2149 1150 5760 2369 6983 1086 1616 7088 872 7869 5712 7028 2150 2016 6135 6026 7276 4815 7611 6595 5350 4998 5512 7847 5582 2658 5452 6903 3005 2514 7881 4275 2149 5514 4092 7397 7003 2095 7119 5561 1788 6084 1233 5090 7565 7107 7901 6629 6441 5808 5760 5712 7028 3803 5090 6113 6228 7310 4998 7911 5468 734 7107 1415 5090 6113 6213 7310 5337 3376 5452 7088 4630 7138 7848 777 7429 5142 7802 1233 5090 7565 6116 1633 5452 2267 6855 2982 7078 931 7461 7870 2261 6938 5754 6832 6553 3656 2701 2959 7382 7107 7901 6629 6441 5808 5760 1132 6951 6306 7088 4756 2149 5512 1788 6084 1233 7925 7565 6116 5090 6113 6228 7310 4998 7911 5468 4086 7848 7142 1415 5090 6113 6213 7310 5337 4213 3376 5452 6903 931 7461 7870 2253 7107 4615 2149 5512 1788 6084 7096 7107 3376 5452 7088 4630 7138 7870 4237 2150 4615 3\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-6\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁직전 에 ▁실시 될 ▁예정 이었다 이란 군 과 ▁민간 인 의 ▁피해 ▁위험 을 ▁최소화 하기 ▁위 함 이다 도 널 드 ▁트 럼 프 ▁미국 ▁대통령이 년 월 ▁일 ▁미 플 로 리 다 주 ▁올 랜 도 ▁암 웨이 센터에서 ▁열린 ▁재 선 ▁도전 ▁출 정 식 에서 ▁연 설 하고 ▁있다 로 이 터 연합 뉴스 그 러 나 ▁갑자기 ▁취소 ▁명령 이 ▁떨어졌다 ▁소식통 은 ▁비행기 가 ▁공 중 에 ▁떠 ▁있고 ▁선박 도 ▁제 ▁위치 에 ▁있었지만 ▁공격 ▁개 시 ▁명령 은 ▁없었다 ▁고 에 ▁전했다 ▁폭 격 기 와 ▁군 함 도 ▁공격 ▁태 세 에 ▁돌입 했다는 ▁이야기 다 ▁실제 ▁미국 ▁연방 항공 국 은 ▁일 ▁오후 ▁미국 에 ▁등록 된 ▁항공기 가 ▁페 르 시아 만 과 ▁오 만 만 을 ▁비 행 하는 ▁것도 ▁금지 했다 는 ▁트 럼 프 ▁대통령이 ▁단순 히 ▁공격 에 ▁관한 ▁생각을 ▁바 꾼 ▁것인지 ▁아니면 ▁다른 ▁전략 이 ▁있어 ▁트 럼 프 ▁행정 부 ▁차원에서 ▁방향 을 ▁바 꾼 ▁것인지 ▁명확 하지 ▁않다 ▁공격 ▁가능성이 ▁여전히 ▁남아 ▁있는 지도 ▁불 분 명 하다 ▁고 ▁덧붙였다 ▁마 이 크 폼 페 이 오 ▁국 무 장관 과 ▁존 ▁볼 턴 ▁백악관 ▁국가안보 회 의 ▁보 좌 관 ▁지나 ▁해 스 펠 ▁중앙 정보 국 ▁국 장은 ▁군사 적 ▁대응 을 ▁주장 한 ▁것으로 ▁알려졌다 ▁백악관 과 ▁미 ▁국방부 는 ▁보도 와 ▁관련한 ▁답변 을 ▁거부 했다 년 월 ▁미국 ▁메 릴 랜드 주 ▁패 턱 센트 강 ▁해 군 항공 기지 ▁상 공 에서 ▁시험 ▁비 행 ▁중인 ▁미 군의 ▁정 찰 용 ▁무 인 기 ▁드 론 ▁글로벌 ▁호 크 이란 혁명 수 비 대 는 년 월 ▁일 ▁호 르 무 즈 ▁해 협 과 ▁가까운 이란 ▁남부 ▁호 르 모 즈 간 ▁영 공 을 ▁침 입 해 ▁간 첩 ▁활동을 하던 ▁글로벌 ▁호 크 를 ▁대 공 ▁방 어 ▁시스템 으로 ▁격 추 했다고 ▁밝혔다 연합 뉴스 앞 서 ▁이날 ▁새벽 ▁시 쯤 이란 혁명 수 비 대 는 ▁국 영 방송 을 ▁통해 ▁미 군 ▁드 론 ▁글로벌 호 크 를 ▁호 르 무 즈 ▁해 협 과 ▁접 해 있는 ▁남부 ▁호 르 모 즈 간 ▁주 ▁영 공 에서 ▁격 추 했다고 ▁발표했다 이란 ▁측은 ▁미 군 ▁드 론 이 이란 ▁영 공 을 ▁침 입 했다고 ▁주장했다 ▁미국 ▁측은 ▁미 군 ▁드 론 이 ▁국제 ▁공 역 에서 ▁격 추 됐다 며 ▁정당 한 ▁이유 가 ▁없는 ▁공격 이라고 ▁맞 섰 다 ▁트 럼 프 ▁대통령은 이란 의 ▁드 론 ▁격 추 ▁소식에 ▁큰 ▁실수 를 ▁한 ▁것이다 ▁참 지 ▁않을 ▁것 이라고 ▁했다 ▁그는 ▁자신의 ▁트위터 ▁계 정 에도 이란 은 ▁매우 ▁큰 ▁실수 를 ▁했다 는 ▁글을 ▁남겼다 ▁그러면서 도 ▁트 럼 프 ▁대통령은 ▁미 군 ▁드 론 에 ▁대한 ▁공격 이 ▁의도 적으로 ▁이뤄졌다 고 믿 긴 ▁어렵다 얼 빠 진 멍 청 이 가 ▁실수 로 ▁그렇게 ▁한 ▁것이 ▁아 닐 까 ▁싶다 ▁고 ▁말해 ▁애 써 ▁의미 를 ▁축소 했다 이란 을 ▁공격 할 ▁것이 냐 는 ▁질문에 는 ▁곧 ▁알게 ▁될 ▁것 이라고 만 ▁했다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 4357 6896 3043 5902 3413 7112 7107 5512 5468 2170 7119 7095 4912 3571 7088 4532 7789 3552 7837 7100 5859 5696 5920 4773 6043 7753 2150 1670 5712 7028 3803 2149 7761 6079 6122 5782 7276 3439 6025 5859 3177 7040 6594 3364 3969 6559 1721 4568 7227 6730 6903 3332 6566 7788 3862 6079 7096 7609 6938 5754 5538 6037 5655 806 4602 2036 7096 1858 2842 7086 2545 5330 1023 7295 6896 1852 3857 2741 5859 4128 3563 6896 3875 1030 835 6705 2036 7086 3280 993 6896 4061 4871 5412 5561 6983 1165 7837 5859 1030 4720 6579 6896 1738 7871 3714 5782 3049 2150 3346 7847 5503 7086 3803 3434 2150 6896 1818 5899 4994 5330 4829 6113 6714 6150 5468 3417 6150 6150 7088 2514 7881 7794 907 1248 7869 5760 4773 6043 7753 1670 1591 7996 1030 6896 1094 2706 2186 5629 918 3102 1567 4025 7096 3868 4773 6043 7753 5030 6398 4411 2285 7088 2186 5629 918 2042 7819 3153 1030 741 3320 1420 3860 7328 2485 6416 6204 7798 993 1705 1907 7096 7565 7739 7712 7096 6964 1132 6228 7180 5468 4192 2417 7612 2299 1136 7953 7095 2355 7273 5474 4303 4998 6664 7717 4269 7229 5503 1132 7186 1167 7202 1659 7088 4236 7828 909 3171 2299 5468 2149 1150 5760 2369 6983 1086 1616 7088 872 7869 5712 7028 2150 2016 6135 6026 7276 4815 7611 6595 5350 4998 5512 7847 5582 2658 5452 6903 3005 2514 7881 4275 2149 5514 4092 7397 7003 2095 7119 5561 1788 6084 1233 5090 7565 7107 7901 6629 6441 5808 5760 5712 7028 3803 5090 6113 6228 7310 4998 7911 5468 734 7107 1415 5090 6113 6213 7310 5337 3376 5452 7088 4630 7138 7848 777 7429 5142 7802 1233 5090 7565 6116 1633 5452 2267 6855 2982 7078 931 7461 7870 2261 6938 5754 6832 6553 3656 2701 2959 7382 7107 7901 6629 6441 5808 5760 1132 6951 6306 7088 4756 2149 5512 1788 6084 1233 7925 7565 6116 5090 6113 6228 7310 4998 7911 5468 4086 7848 7142 1415 5090 6113 6213 7310 5337 4213 3376 5452 6903 931 7461 7870 2253 7107 4615 2149 5512 1788 6084 7096 7107 3376 5452 7088 4630 7138 7870 4237 2150 4615 2149 5512 1788 6084 7096 1155 1023 6926 6903 931 7461 5880 6197 4097 7828 3732 5330 3272 1030 7102 1970 6572 5782 4773 6043 7753 1668 7107 7095 1788 6084 931 7461 2840 4688 3042 6116 4955 913 4427 7318 3163 905 7102 5019 1191 3913 4775 980 7227 6901 7107 7086 1995 4688 3042 6116 5019 5760 1234 1411 1200 5859 4773 6043 7753 1668 2149 5512 1788 6084 6896 1682 1030 7096 3622 7203 3678 5439 6266 5584 3232 6870 6459 7344 6189 7431 7096 5330 3042 6079 1204 4955 912 3093 5777 5591 3072 993 1965 3194 6761 3628 6116 4564 7869 7107 7088 1030 7836 912 5689 5760 4381 5760 1014 3167 1772 905 7102 6150 5019 3 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-7\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁잠실 ▁박 준 형 기자 ▁일 ▁오후 ▁서울 ▁잠실 구장에서 ▁신한은행 ▁리그 ▁두산 ▁베 어 스와 ▁롯데 ▁자 이 언 츠 의 ▁경기가 ▁진행됐다 ▁롯데 ▁치 어 리 더 ▁박 기 량 과 ▁안 지 현 이 ▁멋진 ▁무대를 ▁펼치고 ▁있다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3947 2199 7288 7921 5580 3803 3434 2726 3947 5500 3032 1901 1776 2333 6855 6674 1893 3886 7096 6865 7478 7095 957 4371 1893 4617 6855 6122 5837 2199 5561 6035 5468 3135 7318 7903 7096 2015 2099 4839 3862 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 4 (id = [4.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-8\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] 월 스트 리 트 저 널 ▁이 ▁지난해 ▁싱가포르 ▁미 ▁북 ▁정상회담 ▁이후 ▁북한이 ▁핵 무 기 개를 ▁추가로 ▁생산 했을 ▁가능성이 ▁있다고 ▁보도 한 ▁지난 ▁일 자 ▁현지 ▁시각 ▁기사 와 ▁관련해 ▁부정 확 하다 며 ▁이 ▁내용을 ▁기사 에서 ▁일 ▁삭제 했다 는 ▁이날 ▁수정 기사 에서 ▁북한이 ▁핵 무 기 개를 ▁추가로 ▁생산 했을 ▁가능성 에 ▁관한 ▁내용을 ▁삭제 했다 ▁그러나 ▁이 ▁내용이 ▁왜 ▁부정 확 하게 ▁기술 됐 는 지 에 ▁관한 ▁설명 은 ▁따로 ▁없었다 ▁북한이 ▁지난해 ▁싱가포르 ▁미 ▁북 ▁정상회담 ▁이후 ▁핵 무 기 개를 ▁추가로 ▁생산 했을 ▁가능성이 ▁있다고 월 스트 리 트 저 널 ▁이 ▁일 ▁미 ▁국방부 ▁산하 ▁국방 정보 국 ▁분석 가 들을 ▁인 용 해 ▁보도했다 는 ▁일 자 ▁기사 에서 ▁이 ▁내용이 ▁부정 확 하게 ▁기술 됐다 며 ▁이 ▁부분 을 ▁삭제 했다 월 스트 리 트 저 널 ▁앞서 는 ▁트 럼 프 와 ▁김정 은 이 ▁대화 하는 ▁동안 ▁북한 은 ▁핵 무 기를 ▁늘려 왔다 는 ▁제 목 의 ▁기사 에서 ▁미 ▁국방부 ▁산하 ▁국방 정보 국 ▁분석 가 들을 ▁인 용 ▁북한이 ▁싱가포르 ▁회담 ▁이후 ▁핵 무 기 개를 ▁추가로 ▁생산 했을 ▁가능성을 ▁보도했다 ▁또 ▁북한이 ▁현재 ▁핵 무 기 ▁총 개를 ▁보유하고 ▁있을 ▁것으로 ▁추산 된다 고 ▁했다 도 널 드 ▁트 럼 프 ▁미 ▁대통령 과 ▁김정 은 ▁북한 ▁국 무 위원장 의 ▁정상회담 ▁등 ▁외교 는 ▁북한이 ▁핵 무 기를 ▁포기 할 지도 ▁모른다 는 ▁희망 을 줬 지만 ▁위 성 사진 을 ▁분석 한 ▁전문가들은 ▁북한이 ▁장 거리 ▁미사일 과 ▁핵 물질 ▁생산 을 ▁늘 린 ▁것으로 ▁보고 ▁있다고 ▁했다 는 ▁일 자 ▁수정 ▁기사 에서 ▁이 ▁내용은 ▁유지 했다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 7028 6691 6122 7659 7199 5696 3647 4306 3070 2149 2462 4115 3756 2467 5014 6228 5561 5361 4543 2714 7879 741 3863 2369 7828 4304 3803 7147 5066 2961 1283 6983 1087 2449 7944 7798 6197 3647 1451 1283 6903 3803 2639 7869 5760 3656 2901 5574 6903 2467 5014 6228 5561 5361 4543 2714 7879 738 6896 1094 1451 2639 7869 1199 3647 1453 3466 2449 7944 7784 1289 5878 5760 7318 6896 1094 2773 7086 1837 3280 2467 4306 3070 2149 2462 4115 3756 5014 6228 5561 5361 4543 2714 7879 741 3863 7028 6691 6122 7659 7199 5696 3647 3803 2149 1150 2642 1149 7229 5503 2476 5330 5938 3758 7003 7848 2371 5760 3803 7147 1283 6903 3647 1453 2449 7944 7784 1289 5880 6197 3647 2437 7088 2639 7869 7028 6691 6122 7659 7199 5696 3187 5760 4773 6043 7753 6983 1330 7086 7096 1692 7794 1754 2465 7086 5014 6228 5573 1551 6990 5760 4128 6217 7095 1283 6903 2149 1150 2642 1149 7229 5503 2476 5330 5938 3758 7003 2467 3070 5154 3756 5014 6228 5561 5361 4543 2714 7879 740 2371 1861 2467 5064 5014 6228 5561 4512 5361 2384 3880 909 4547 5900 5439 5019 5859 5696 5920 4773 6043 7753 2149 1667 5468 1330 7086 2465 1132 6228 7053 7095 4115 1815 3469 5760 2467 5014 6228 5573 4857 7836 7328 2051 5760 5208 7088 7305 7330 3552 6573 6511 7088 2476 7828 4036 2467 3954 5382 2162 5468 5014 6243 2714 7088 1550 6133 909 2358 3863 5019 5760 3803 7147 2901 1283 6903 3647 1450 3592 7869 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-9\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁일본 ▁정부는 ▁한국 과 ▁중국 에 ▁후 쿠 시 마 현 ▁등 ▁일본 산 ▁수 산 물 의 ▁수입 ▁규제 ▁철 폐 를 ▁요구했다 고 ▁일본 ▁지지 통신 ▁등이 ▁일 ▁보도했다 는 ▁요 시 타 카 ▁타 카 모 리 ▁농 림 수 산 상 이 ▁이날 ▁일본 니 가 타 현 에서 ▁열린 ▁주요 개국 ▁농업 장관 회의에서 ▁후 쿠 시 마 ▁제 ▁원 자 력 발전소 ▁사고 ▁이후 ▁일본 산 ▁수 산 물 ▁수입 ▁규제 를 ▁계속 하고 ▁있는 ▁한국 ▁중국 ▁측 ▁장관 과 ▁별도로 ▁회 동 하고 ▁규제 ▁철 폐 를 ▁요구했다 ▁고 ▁전했다 ▁한국 에선 ▁이 개 호 ▁농 림 축 산 식품 부 ▁장관 ▁중국 에선 ▁한 창 푸 ▁농업 농 촌 부장 ▁장관 ▁이 ▁이날 ▁회의 에 ▁참석한 ▁것으로 ▁알려졌다 ▁요 시 카 와 ▁장관은 ▁이 개 호 ▁장관 과 ▁만난 ▁후 기자 들에게 ▁수입 ▁규제 ▁철 폐 는 ▁피해 ▁지역 의 ▁재 건 을 ▁위한 ▁중요한 ▁과제 라는 ▁것을 ▁전했다 며 ▁한국의 ▁규제 를 ▁조 속 히 ▁철 폐 해 ▁달라 고 ▁강력 ▁요청했다 ▁고 ▁밝혔다 년 월 ▁일 는 ▁일본 이 ▁제기 한 ▁후 쿠 시 마 ▁수 산 물 ▁수입 금 지 ▁조치 ▁제 소 ▁사건 에서 ▁심 ▁격 인 ▁분쟁 해 결 기구 의 ▁판정 을 ▁뒤집 고 ▁한국의 ▁조치 가 ▁타 당 한 ▁것으로 ▁판정 했다 ▁사진 은 ▁서울 의 ▁한 ▁수 산 물 ▁시장의 ▁수 산 물 ▁원 산 지 ▁표시 연합 뉴스 또 ▁이 ▁장관은 에 ▁한국 ▁정부의 ▁입장 과 ▁한국 ▁국민 이 ▁원하는 ▁것을 ▁요 시 카 와 ▁장관 에게 ▁정확히 ▁전했다 ▁고 ▁말했다 ▁이와 ▁관련 ▁지지 통신 은 ▁이번 ▁회담 에서 ▁중국 과 는 ▁과학 적 ▁근거 에 ▁기초 한 ▁규제 ▁완화 ▁협의 를 ▁계속 하겠다는 ▁방침 을 ▁재 차 ▁확인 했지만 ▁한국 과 는 ▁구체적인 ▁진 전 이 ▁없었던 ▁것으로 ▁보인다 ▁고 ▁전했다 년 ▁동 일본 ▁지 진 에 ▁따른 ▁후 쿠 시 마 ▁원전 ▁사고 ▁이후 ▁현재 ▁일본 산 ▁수 산 물 의 ▁수입 ▁금지 ▁조치를 ▁내린 ▁국가 는 개국 이다 ▁특히 ▁중국 은 ▁도쿄 ▁지 바 ▁후 쿠 시 마 ▁등 ▁일본의 ▁모든 ▁식품 ▁수입 을 ▁중단 했다 ▁일본 은 ▁이 ▁문제로 ▁세계 무역 기구 에 ▁제 소 한 ▁건 ▁한국 ▁뿐 이다 ▁그러나 ▁지난달 ▁일 ▁최종 심 ▁격 인 ▁상 소 기구 는 ▁한국 ▁정부의 ▁후 쿠 시 마 ▁주변 산 ▁식품 ▁수입 규제 ▁조치 가 ▁타 당 하다고 ▁최종 ▁판정 했다 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3809 4108 4958 5468 4259 6896 5176 7550 6705 6141 7903 1815 3809 6516 2872 6516 6241 7095 2900 1183 4473 7727 6116 3483 5439 3809 4340 7637 1826 3803 2371 5760 3480 6705 7581 7495 4698 7495 6213 6122 1507 6136 6629 6516 6527 7096 3656 3809 5770 5330 7581 7903 6903 3364 4233 5358 1508 7180 7959 5176 7550 6705 6141 4128 3533 7147 6064 6299 2576 3756 3809 6516 2872 6516 6241 2900 1183 6116 984 7788 3860 4958 4259 4611 3955 5468 2349 5152 5872 7788 1183 4473 7727 6116 3483 993 4061 4958 6906 3647 5357 7925 1507 6136 7463 6516 6732 6398 3955 4259 6906 4955 7402 7743 1508 5734 7449 6406 3955 3647 3656 5160 6896 4432 909 3171 3480 6705 7495 6983 3956 3647 5357 7925 3955 5468 1934 5176 5580 5936 2900 1183 4473 7727 5760 4912 4329 7095 3969 5384 7088 3566 4273 1068 6005 911 4061 6197 4962 1183 6116 4162 6615 7996 4473 7727 7848 1598 5439 810 3491 993 2261 5712 7028 3803 5760 3809 7096 4134 7828 5176 7550 6705 6141 2872 6516 6241 2900 5550 7318 4188 4128 6607 2574 6903 3060 931 7119 2484 7848 5415 5565 7095 4813 7088 1785 5439 4962 4188 5330 4698 5804 7828 909 4813 7869 2627 7086 2726 7095 4955 2872 6516 6241 2995 2872 6516 6241 3533 6516 7318 4882 6938 5754 5980 3647 3956 6896 4958 4110 3844 5468 4958 1144 7096 3544 911 3480 6705 7495 6983 3955 6897 4126 4061 993 1966 3725 1083 4340 7637 7086 3697 5154 6903 4259 5468 5760 1071 7202 1222 6896 1304 7828 1183 3463 5079 6116 984 7787 2282 7088 3969 7389 5130 7880 4958 5468 5760 1129 4360 7207 7096 3281 909 2392 993 4061 5712 1741 7131 4297 7344 6896 1839 5176 7550 6705 6141 3540 2576 3756 5064 3809 6516 2872 6516 6241 7095 2900 1248 4189 1445 1133 5760 5358 7100 4792 4259 7086 1724 4297 6273 5176 7550 6705 6141 1815 3810 2048 3009 2900 7088 4261 7869 3809 7086 3647 2128 2802 6230 5565 6896 4128 6607 7828 881 4958 2571 7100 1199 4305 3803 4538 6745 931 7119 2658 6607 5565 5760 4958 4110 5176 7550 6705 6141 4229 6516 3009 2900 5534 4188 5330 4698 5804 7799 4538 4813 7869 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 2 (id = [2.0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-10\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] ▁울산 ▁공사 현장 에 ▁투입 하려 ▁하자 ▁차량 ▁앞에 ▁드 러 눕 고 ▁욕 설 ▁퍼 부 어 운 송 비 ▁인상 을 ▁요구 하며 ▁지난달 일부터 ▁파 업 ▁중인 ▁민 노 총 ▁건설 기 계 노조 ▁소속 ▁울산 ▁레 미 콘 ▁노조 가 ▁일 ▁경북 ▁경 주 에서 ▁원정 ▁시위 를 ▁벌였다 ▁울산 에서 ▁레 미 콘 ▁조달 이 ▁어려워 진 ▁건설사 들이 ▁경 주 에서 ▁레 미 콘 을 ▁운송 해 가 려 ▁하자 ▁몸 으로 ▁이 송 을 ▁막아 선 ▁것이다 ▁울산 은 ▁민 노 총 ▁레 미 콘 ▁노조 의 ▁파 업 으로 ▁학교 ▁곳 과 ▁각종 ▁관 공 서 ▁등의 ▁신 축 ▁공사 가 ▁전면 ▁중 지 된 ▁상태다 ▁민 노 총 ▁건설 기 계 노조 ▁소속 ▁울산 ▁레 미 콘 ▁차 주 여명이 ▁일 ▁오전 ▁경북 ▁경 주 시 ▁외 동 읍 ▁영 진 레 미 콘 ▁사업 장에서 ▁울산 ▁북 구 의 ▁공사 장으로 ▁출발 하려 던 ▁레 미 콘 ▁차량 을 ▁막아 서 고 ▁있다 ▁김 주 영 기자 울 산 ▁건설 기 계 노조 ▁소속 ▁레 미 콘 ▁차 주 ▁여 명은 ▁이날 ▁오전 ▁시 쯤 ▁경 주 시 ▁외 동 읍 ▁영 진 레 미 콘 ▁사업 장에서 ▁울산 ▁북 구 ▁제 ▁호 계 중 학교 ▁공사 장으로 ▁출발 하려 던 ▁레 미 콘 ▁차량 ▁대 를 ▁막아 섰 다 ▁차량 이 ▁사업 장을 ▁빠져 나 가 려고 ▁하자 ▁노조 원 ▁명이 ▁순 식 간 에 ▁차량 ▁앞 바퀴 ▁밑 으로 ▁들어가 ▁누 웠다 ▁시위 ▁중 이 던 ▁노조 원 ▁여 명은 ▁빠 꾸 해 라 ▁뒤 로 가 라 ▁어 차 피 굶 어 ▁죽 게 ▁생 겼 는데 ▁여기 서 ▁죽 자 며 ▁고 성을 ▁질 렀다 ▁일부 는 ▁욕 설 을 ▁하며 ▁레 미 콘 ▁차량 을 ▁향해 ▁생 수 병 을 ▁집 어 던 졌다 ▁앞서 ▁이들은 ▁이날 ▁오전 시부터 ▁사업 장 ▁앞에서 ▁시위 를 ▁벌였다 ▁노조 의 ▁육 탄 ▁저 지가 ▁이어 지 자 ▁오전 ▁시 쯤 ▁업체 ▁측 이 ▁앞으로 ▁레 미 콘 ▁공급 은 ▁노조 와 ▁협의 해 ▁결정 하겠다 며 ▁설득 했다 ▁노조 는 ▁그 제 야 ▁시위 를 ▁풀 었다 ▁업체 ▁관계자는 ▁조달 청 ▁계약을 ▁통해 ▁정식 으로 ▁공사 를 ▁체결 했는데 ▁노조 에서 ▁불법 으로 ▁저 지 하고 ▁있다 며 ▁관 할 ▁행정 ▁당국 도 ▁이를 ▁알 지만 ▁민 노 총 이 ▁워낙 ▁강 하니 ▁아무 ▁제재 도 ▁하지 ▁않는다 ▁고 ▁말했다 ▁울산 시 교육청 에 ▁따르면 ▁애초 ▁해당 ▁업체 는 ▁이날 ▁제 ▁호 계 중 학교 ▁공사 ▁현장 에 ▁레 미 콘 ▁차량 ▁대 ▁운 반 분 인 를 ▁공급 해 층 ▁옥 상 ▁바닥 ▁공사 를 ▁마무리 할 ▁계획 이었다 ▁그러나 ▁노조 ▁반발 로 ▁이날 ▁레 미 콘 은 ▁차량 ▁대 인 ▁만 ▁운 반 이 ▁가능 했다 ▁해당 ▁학교 ▁공사 의 ▁현재 ▁공정 률 은 ▁다 ▁울산 시 교육청 은 ▁지난 월 ▁말까지 ▁골 조 ▁공사 를 ▁끝 낼 ▁계획 이 었으나 ▁노조 가 ▁파 업 에 ▁돌입 하면서 ▁공사 가 ▁중단 됐다 ▁시 교육청 ▁관계자는 ▁추 석 ▁전 까지 ▁양측 ▁간 ▁협상 ▁타 결 이 ▁안 ▁되면 월 ▁개 교 가 ▁불가능 하다 며 ▁곳 의 [SEP]\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 3525 1043 7905 6896 4767 7806 4943 4406 3190 1788 6037 5748 5439 3492 6566 4826 6398 6855 7010 6621 6441 3773 7088 3481 7810 4305 7132 4799 6873 4275 2169 5725 7452 885 5561 5436 5727 2837 3525 1884 6255 7539 1488 5330 3803 965 953 7276 6903 3541 2985 6116 2314 3525 6903 1884 6255 7539 4167 7096 3230 7344 886 5940 953 7276 6903 1884 6255 7539 7088 3516 7848 5330 6060 4943 2084 7078 3647 6621 7088 1929 6559 913 3525 7086 2169 5725 7452 1884 6255 7539 1488 7095 4799 6873 7078 4949 1021 5468 776 1073 5452 6553 1825 3010 7463 1043 5330 4032 4257 7318 5899 2681 2169 5725 7452 885 5561 5436 5727 2837 3525 1884 6255 7539 4402 7276 6922 3803 3431 965 953 7276 6705 3468 5872 7093 3376 7344 6050 6255 7539 2609 7184 3525 2462 5495 7095 1043 7185 4573 7806 5842 1884 6255 7539 4406 7088 1929 6553 5439 3862 1316 7276 6951 5580 7013 6516 885 5561 5436 5727 2837 1884 6255 7539 4402 7276 3298 6208 3656 3431 2959 7382 953 7276 6705 3468 5872 7093 3376 7344 6050 6255 7539 2609 7184 3525 2462 5495 4128 5090 5436 7295 7823 1043 7185 4573 7806 5842 1884 6255 7539 4406 1633 6116 1929 6572 5782 4406 7096 2609 7187 2558 5655 5330 6061 4943 1488 7020 2039 2912 6730 5337 6896 4406 3184 6279 2185 7078 1805 1526 7037 2985 4257 7096 5842 1488 7020 3298 6208 2554 5628 7848 6003 1783 6079 5330 6003 3220 7389 7767 5518 6855 4244 5400 2704 5422 5761 3301 6553 4244 7147 6197 993 6576 4379 6047 3811 5760 3492 6566 7088 4938 1884 6255 7539 4406 7088 5035 2704 6629 6361 7088 4384 6855 5842 7250 3187 3666 3656 3431 6711 2609 7178 3191 2985 6116 2314 1488 7095 3597 7590 3990 7319 3716 7318 7147 3431 2959 7382 3268 4611 7096 3192 1884 6255 7539 1034 7086 1488 6983 5079 7848 945 7785 6197 2771 7869 1488 5760 1185 7234 6844 2985 6116 4888 6888 3268 1078 4167 7431 986 4756 4116 7078 1043 6116 4492 7867 1488 6903 2496 7078 3990 7318 7788 3862 6197 1073 7836 5030 1619 5859 3686 3166 7330 2169 5725 7452 7096 3531 807 7797 3111 4150 5859 4945 3152 993 1966 3525 6705 5492 6896 1838 3199 5000 3268 5760 3656 4128 5090 5436 7295 7823 1043 5062 6896 1884 6255 7539 4406 1633 3513 6286 6416 7119 6116 1034 7848 7482 3436 6527 2192 1043 6116 1914 7836 990 7112 1199 1488 2214 6079 3656 1884 6255 7539 7086 4406 1633 7119 1931 3513 6286 7096 737 7869 5000 4949 1043 7095 5064 1052 6110 7086 1562 3525 6705 5492 7086 4304 7028 1959 1016 7253 1043 6116 1363 5683 990 7096 6891 1488 5330 4799 6873 6896 1738 7812 1043 5330 4261 5880 2959 5492 1078 4541 6557 4012 5592 3218 777 5076 4698 5415 7096 3135 1766 7028 835 5488 5330 2486 7798 6197 1021 7095 3\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   *** Example ***\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   guid: test-10\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   doc_span_index: 1\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   tokens: [CLS] 여명이 ▁일 ▁오전 ▁경북 ▁경 주 시 ▁외 동 읍 ▁영 진 레 미 콘 ▁사업 장에서 ▁울산 ▁북 구 의 ▁공사 장으로 ▁출발 하려 던 ▁레 미 콘 ▁차량 을 ▁막아 서 고 ▁있다 ▁김 주 영 기자 울 산 ▁건설 기 계 노조 ▁소속 ▁레 미 콘 ▁차 주 ▁여 명은 ▁이날 ▁오전 ▁시 쯤 ▁경 주 시 ▁외 동 읍 ▁영 진 레 미 콘 ▁사업 장에서 ▁울산 ▁북 구 ▁제 ▁호 계 중 학교 ▁공사 장으로 ▁출발 하려 던 ▁레 미 콘 ▁차량 ▁대 를 ▁막아 섰 다 ▁차량 이 ▁사업 장을 ▁빠져 나 가 려고 ▁하자 ▁노조 원 ▁명이 ▁순 식 간 에 ▁차량 ▁앞 바퀴 ▁밑 으로 ▁들어가 ▁누 웠다 ▁시위 ▁중 이 던 ▁노조 원 ▁여 명은 ▁빠 꾸 해 라 ▁뒤 로 가 라 ▁어 차 피 굶 어 ▁죽 게 ▁생 겼 는데 ▁여기 서 ▁죽 자 며 ▁고 성을 ▁질 렀다 ▁일부 는 ▁욕 설 을 ▁하며 ▁레 미 콘 ▁차량 을 ▁향해 ▁생 수 병 을 ▁집 어 던 졌다 ▁앞서 ▁이들은 ▁이날 ▁오전 시부터 ▁사업 장 ▁앞에서 ▁시위 를 ▁벌였다 ▁노조 의 ▁육 탄 ▁저 지가 ▁이어 지 자 ▁오전 ▁시 쯤 ▁업체 ▁측 이 ▁앞으로 ▁레 미 콘 ▁공급 은 ▁노조 와 ▁협의 해 ▁결정 하겠다 며 ▁설득 했다 ▁노조 는 ▁그 제 야 ▁시위 를 ▁풀 었다 ▁업체 ▁관계자는 ▁조달 청 ▁계약을 ▁통해 ▁정식 으로 ▁공사 를 ▁체결 했는데 ▁노조 에서 ▁불법 으로 ▁저 지 하고 ▁있다 며 ▁관 할 ▁행정 ▁당국 도 ▁이를 ▁알 지만 ▁민 노 총 이 ▁워낙 ▁강 하니 ▁아무 ▁제재 도 ▁하지 ▁않는다 ▁고 ▁말했다 ▁울산 시 교육청 에 ▁따르면 ▁애초 ▁해당 ▁업체 는 ▁이날 ▁제 ▁호 계 중 학교 ▁공사 ▁현장 에 ▁레 미 콘 ▁차량 ▁대 ▁운 반 분 인 를 ▁공급 해 층 ▁옥 상 ▁바닥 ▁공사 를 ▁마무리 할 ▁계획 이었다 ▁그러나 ▁노조 ▁반발 로 ▁이날 ▁레 미 콘 은 ▁차량 ▁대 인 ▁만 ▁운 반 이 ▁가능 했다 ▁해당 ▁학교 ▁공사 의 ▁현재 ▁공정 률 은 ▁다 ▁울산 시 교육청 은 ▁지난 월 ▁말까지 ▁골 조 ▁공사 를 ▁끝 낼 ▁계획 이 었으나 ▁노조 가 ▁파 업 에 ▁돌입 하면서 ▁공사 가 ▁중단 됐다 ▁시 교육청 ▁관계자는 ▁추 석 ▁전 까지 ▁양측 ▁간 ▁협상 ▁타 결 이 ▁안 ▁되면 월 ▁개 교 가 ▁불가능 하다 며 ▁곳 의 ▁신 축 ▁학교 ▁중 ▁일부 는 ▁주변 에 ▁학생들 을 ▁수용 할 ▁학교 도 ▁없어 ▁난 감 하다 ▁고 ▁말했다 ▁울산 에서는 ▁제 ▁호 계 중 학교 ▁등 ▁개 교 ▁공사 ▁외에도 ▁울산 전 시 컨 벤 션 센터 ▁제 ▁실내 체육 관 ▁상 개 ▁매 암 ▁혼 잡 도로 ▁개설 공사 ▁동 천 제 방 겸 용 도로 ▁개설 공사 ▁상 방 지 하 차 도 ▁침수 개선 사업 ▁울산 미 포 국가 산업단지 ▁완 충 저 류 시설 ▁설치 사업 ▁옥 동 ▁농 소 ▁도로 개 설 공사 ▁등이 멈 춰 ▁있다 ▁울산 시 ▁관계자는 ▁사실상 ▁울산 ▁지역 ▁공사 ▁현장 ▁전체 가 ▁차질 을 ▁빚 고 ▁있다 ▁고 ▁말했다 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_ids: 2 6922 3803 3431 965 953 7276 6705 3468 5872 7093 3376 7344 6050 6255 7539 2609 7184 3525 2462 5495 7095 1043 7185 4573 7806 5842 1884 6255 7539 4406 7088 1929 6553 5439 3862 1316 7276 6951 5580 7013 6516 885 5561 5436 5727 2837 1884 6255 7539 4402 7276 3298 6208 3656 3431 2959 7382 953 7276 6705 3468 5872 7093 3376 7344 6050 6255 7539 2609 7184 3525 2462 5495 4128 5090 5436 7295 7823 1043 7185 4573 7806 5842 1884 6255 7539 4406 1633 6116 1929 6572 5782 4406 7096 2609 7187 2558 5655 5330 6061 4943 1488 7020 2039 2912 6730 5337 6896 4406 3184 6279 2185 7078 1805 1526 7037 2985 4257 7096 5842 1488 7020 3298 6208 2554 5628 7848 6003 1783 6079 5330 6003 3220 7389 7767 5518 6855 4244 5400 2704 5422 5761 3301 6553 4244 7147 6197 993 6576 4379 6047 3811 5760 3492 6566 7088 4938 1884 6255 7539 4406 7088 5035 2704 6629 6361 7088 4384 6855 5842 7250 3187 3666 3656 3431 6711 2609 7178 3191 2985 6116 2314 1488 7095 3597 7590 3990 7319 3716 7318 7147 3431 2959 7382 3268 4611 7096 3192 1884 6255 7539 1034 7086 1488 6983 5079 7848 945 7785 6197 2771 7869 1488 5760 1185 7234 6844 2985 6116 4888 6888 3268 1078 4167 7431 986 4756 4116 7078 1043 6116 4492 7867 1488 6903 2496 7078 3990 7318 7788 3862 6197 1073 7836 5030 1619 5859 3686 3166 7330 2169 5725 7452 7096 3531 807 7797 3111 4150 5859 4945 3152 993 1966 3525 6705 5492 6896 1838 3199 5000 3268 5760 3656 4128 5090 5436 7295 7823 1043 5062 6896 1884 6255 7539 4406 1633 3513 6286 6416 7119 6116 1034 7848 7482 3436 6527 2192 1043 6116 1914 7836 990 7112 1199 1488 2214 6079 3656 1884 6255 7539 7086 4406 1633 7119 1931 3513 6286 7096 737 7869 5000 4949 1043 7095 5064 1052 6110 7086 1562 3525 6705 5492 7086 4304 7028 1959 1016 7253 1043 6116 1363 5683 990 7096 6891 1488 5330 4799 6873 6896 1738 7812 1043 5330 4261 5880 2959 5492 1078 4541 6557 4012 5592 3218 777 5076 4698 5415 7096 3135 1766 7028 835 5488 5330 2486 7798 6197 1021 7095 3010 7463 4949 4257 3811 5760 4229 6896 4953 7088 2894 7836 4949 5859 3278 1406 5341 7798 993 1966 3525 6904 4128 5090 5436 7295 7823 1815 835 5488 1043 3476 3525 7207 6705 7514 6347 6602 6593 4128 3037 7438 5474 2658 5357 1986 6824 5100 7176 5860 844 5459 1741 7422 7234 6305 5420 7003 5860 844 5459 2658 6305 7318 7782 7389 5859 4631 5364 6503 3525 6255 7728 5504 6518 3455 7472 7199 6107 6712 2779 6503 3436 5872 1507 6607 1711 5357 6566 5459 1826 6187 7473 3862 3525 6705 1078 2605 3525 4329 1043 5062 4054 5330 4419 7088 2552 5439 3862 993 1966 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "12/25/2019 06:38:53 - INFO - run_classifier_spm -   label: 1 (id = [1.0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_features = convert_examples_to_features(\n",
    "    test_examples, label_list, args['max_seq_length'], tokenizer, doc_stride=args['doc_stride'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input_data = [{'id':feature.guid, 'doc_index':feature.doc_span_index} for feature in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5336a83dcfa142f39a9b82082df30049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction Iteration', max=1112.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_logits = None\n",
    "\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
    "    input_ids, input_mask, segment_ids = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "        logits = logits.sigmoid()## softmax\n",
    "\n",
    "    if all_logits is None:\n",
    "        all_logits = logits.detach().cpu().numpy()\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "\n",
    "    nb_eval_examples += input_ids.size(0)\n",
    "    nb_eval_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(pd.DataFrame(new_input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[:, 'pred'] = a.iloc[:,2:].apply(lambda x: x.idxmax(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/advice/notebook/jms/우리은행/data/news_te.txt', \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    lines = []\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "t = [i[1] for i in lines[1:]]\n",
    "real_val = [{'id':'test-'+str(idx+1), 'real':real}for idx, real in enumerate(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(pd.DataFrame(a.groupby('id')['pred'].max()).reset_index(),\n",
    "                 pd.DataFrame(real_val), \n",
    "                 on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421833184656556"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final.pred == final.real].shape[0]/final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229237c4fa0742e5b9c014ba9ddc7548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Prediction Iteration', max=1112.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_logits = None\n",
    "\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
    "    input_ids, input_mask, segment_ids = batch\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "#         logits = logits.softmax(dim = num_labels)## softmax\n",
    "\n",
    "    if all_logits is None:\n",
    "        all_logits = logits.detach().cpu().numpy()\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "\n",
    "    nb_eval_examples += input_ids.size(0)\n",
    "    nb_eval_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.merge(pd.DataFrame(new_input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.loc[:, 'pred'] = a.iloc[:,2:].apply(lambda x: x.idxmax(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/advice/notebook/jms/우리은행/data/news_te.txt', \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n",
    "    lines = []\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "t = [i[1] for i in lines[1:]]\n",
    "real_val = [{'id':'test-'+str(idx+1), 'real':real}for idx, real in enumerate(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(pd.DataFrame(a.groupby('id')['pred'].max()).reset_index(),\n",
    "                 pd.DataFrame(real_val), \n",
    "                 on = ['id'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9421833184656556"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final.pred == final.real].shape[0]/final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = list(a.id.value_counts()[:5000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_1 = final[final.id.isin(xxx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test-10002</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test-10006</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test-10013</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test-10016</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17922</th>\n",
       "      <td>test-9987</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17927</th>\n",
       "      <td>test-9991</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17928</th>\n",
       "      <td>test-9992</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17929</th>\n",
       "      <td>test-9993</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17930</th>\n",
       "      <td>test-9994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id pred real\n",
       "1         test-10    1    1\n",
       "6      test-10002    3    3\n",
       "10     test-10006    5    5\n",
       "18     test-10013    3    3\n",
       "21     test-10016    3    3\n",
       "...           ...  ...  ...\n",
       "17922   test-9987    2    2\n",
       "17927   test-9991    3    3\n",
       "17928   test-9992    4    4\n",
       "17929   test-9993    3    3\n",
       "17930   test-9994    0    0\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_1[final_1.pred == final_1.real].shape[0]/final_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12325"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(a.id.value_counts()==1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
